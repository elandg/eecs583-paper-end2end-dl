{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCL Thread Coarsening\n",
    "\n",
    "This notebook contains the experiments for Case Study B - using deep learning to predict thread coarsening factor for OpenCL kernels, without hand engineered features.\n",
    "\n",
    "## 1. Runtime Data\n",
    "\n",
    "We use author-provided runtime data from the PACT'14 paper that we compare against [1].\n",
    "\n",
    "> [1] Magni, A., Dubach, C., & O’Boyle, M. (2014). [Automatic Optimization of Thread-Coarsening for Graphics Processors](http://www.research.ed.ac.uk/portal/files/19958629/magni14pact.pdf). In PACT. ACM.\n",
    "\n",
    "The data consists of runtimes from 17 benchmarks accross 4 experimental platforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>cf</th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "      <th>PCA3</th>\n",
       "      <th>PCA4</th>\n",
       "      <th>PCA5</th>\n",
       "      <th>PCA6</th>\n",
       "      <th>PCA7</th>\n",
       "      <th>runtime_Fermi</th>\n",
       "      <th>runtime_Kepler</th>\n",
       "      <th>runtime_Cypress</th>\n",
       "      <th>runtime_Tahiti</th>\n",
       "      <th>src</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>1</td>\n",
       "      <td>1.994918</td>\n",
       "      <td>-0.810402</td>\n",
       "      <td>-2.206370</td>\n",
       "      <td>3.217486</td>\n",
       "      <td>-2.193143</td>\n",
       "      <td>2.374925</td>\n",
       "      <td>0.174607</td>\n",
       "      <td>1321696.0</td>\n",
       "      <td>1381120.0</td>\n",
       "      <td>1783889.0</td>\n",
       "      <td>975555.0</td>\n",
       "      <td>__kernel void A(__global float* a, __global fl...</td>\n",
       "      <td>[ 59   1 118   1  31   7  58   1  80   9   1  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>2</td>\n",
       "      <td>2.133716</td>\n",
       "      <td>-1.493068</td>\n",
       "      <td>-1.286520</td>\n",
       "      <td>3.075195</td>\n",
       "      <td>-0.381715</td>\n",
       "      <td>0.677804</td>\n",
       "      <td>0.960159</td>\n",
       "      <td>1238176.0</td>\n",
       "      <td>1222336.0</td>\n",
       "      <td>1849444.0</td>\n",
       "      <td>962963.0</td>\n",
       "      <td>__kernel void A(__global float* a, __global fl...</td>\n",
       "      <td>[ 59   1 118   1  31   7  58   1  80   9   1  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>nbody</td>\n",
       "      <td>8</td>\n",
       "      <td>-1.753095</td>\n",
       "      <td>-0.428577</td>\n",
       "      <td>-4.534866</td>\n",
       "      <td>-1.279360</td>\n",
       "      <td>0.941490</td>\n",
       "      <td>1.106185</td>\n",
       "      <td>-0.531706</td>\n",
       "      <td>332913280.0</td>\n",
       "      <td>30859456.0</td>\n",
       "      <td>35734111.0</td>\n",
       "      <td>36427408.0</td>\n",
       "      <td>__kernel void A(__global float4* a, __global f...</td>\n",
       "      <td>[ 59   1 118   1  31   7  58   1  80  19   9  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>nbody</td>\n",
       "      <td>16</td>\n",
       "      <td>-4.279616</td>\n",
       "      <td>-1.328454</td>\n",
       "      <td>-6.529448</td>\n",
       "      <td>-1.415595</td>\n",
       "      <td>2.290164</td>\n",
       "      <td>-0.138573</td>\n",
       "      <td>0.294633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42521556.0</td>\n",
       "      <td>65451704.0</td>\n",
       "      <td>__kernel void A(__global float4* a, __global f...</td>\n",
       "      <td>[ 59   1 118   1  31   7  58   1  80  19   9  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          kernel  cf      PCA1      PCA2      PCA3      PCA4      PCA5  \\\n",
       "0   blackscholes   1  1.994918 -0.810402 -2.206370  3.217486 -2.193143   \n",
       "1   blackscholes   2  2.133716 -1.493068 -1.286520  3.075195 -0.381715   \n",
       "..           ...  ..       ...       ...       ...       ...       ...   \n",
       "87         nbody   8 -1.753095 -0.428577 -4.534866 -1.279360  0.941490   \n",
       "88         nbody  16 -4.279616 -1.328454 -6.529448 -1.415595  2.290164   \n",
       "\n",
       "        PCA6      PCA7  runtime_Fermi  runtime_Kepler  runtime_Cypress  \\\n",
       "0   2.374925  0.174607      1321696.0       1381120.0        1783889.0   \n",
       "1   0.677804  0.960159      1238176.0       1222336.0        1849444.0   \n",
       "..       ...       ...            ...             ...              ...   \n",
       "87  1.106185 -0.531706    332913280.0      30859456.0       35734111.0   \n",
       "88 -0.138573  0.294633            NaN             NaN       42521556.0   \n",
       "\n",
       "    runtime_Tahiti                                                src  \\\n",
       "0         975555.0  __kernel void A(__global float* a, __global fl...   \n",
       "1         962963.0  __kernel void A(__global float* a, __global fl...   \n",
       "..             ...                                                ...   \n",
       "87      36427408.0  __kernel void A(__global float4* a, __global f...   \n",
       "88      65451704.0  __kernel void A(__global float4* a, __global f...   \n",
       "\n",
       "                                                  seq  \n",
       "0   [ 59   1 118   1  31   7  58   1  80   9   1  ...  \n",
       "1   [ 59   1 118   1  31   7  58   1  80   9   1  ...  \n",
       "..                                                ...  \n",
       "87  [ 59   1 118   1  31   7  58   1  80  19   9  ...  \n",
       "88  [ 59   1 118   1  31   7  58   1  80  19   9  ...  \n",
       "\n",
       "[89 rows x 15 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 5)\n",
    "\n",
    "df = pd.read_csv(\"../data/case-study-b/pact-2014-runtimes.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can derive the \"oracle\" thread coarsening factors, i.e. the thread coarsening factors which provided the lowest runtime on each of the four architectures, for each of the 17 benchmarks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>cf_Fermi</th>\n",
       "      <th>runtime_Fermi</th>\n",
       "      <th>cf_Kepler</th>\n",
       "      <th>runtime_Kepler</th>\n",
       "      <th>cf_Cypress</th>\n",
       "      <th>runtime_Cypress</th>\n",
       "      <th>cf_Tahiti</th>\n",
       "      <th>runtime_Tahiti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>binarySearch</td>\n",
       "      <td>1.0</td>\n",
       "      <td>213216.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>165248.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>290889.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>178518.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1148128.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1179008.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1783889.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>962963.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spmv</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36224.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52896.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>stencil</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4295104.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4330912.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10420555.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5200148.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          kernel  cf_Fermi  runtime_Fermi  cf_Kepler  runtime_Kepler  \\\n",
       "0   binarySearch       1.0       213216.0       16.0        165248.0   \n",
       "1   blackscholes       8.0      1148128.0        4.0       1179008.0   \n",
       "..           ...       ...            ...        ...             ...   \n",
       "15          spmv       1.0        36224.0        1.0         52896.0   \n",
       "16       stencil       2.0      4295104.0        1.0       4330912.0   \n",
       "\n",
       "    cf_Cypress  runtime_Cypress  cf_Tahiti  runtime_Tahiti  \n",
       "0          2.0         290889.0        4.0        178518.0  \n",
       "1          1.0        1783889.0        2.0        962963.0  \n",
       "..         ...              ...        ...             ...  \n",
       "15         1.0          82000.0        1.0         64592.0  \n",
       "16         1.0       10420555.0        1.0       5200148.0  \n",
       "\n",
       "[17 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracles = pd.read_csv(\"../data/case-study-b/pact-2014-oracles.csv\")\n",
    "oracles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predictive Models\n",
    "\n",
    "We define a base class for implementing predictive models for thread coarsening:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from clgen import _atomizer as clgen\n",
    "\n",
    "class ThreadCoarseningModel(object):\n",
    "    \"\"\"\n",
    "    A model for predicting OpenCL thread coarsening factors.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    __name__ : str\n",
    "        Model name\n",
    "    __basename__ : str\n",
    "        Shortened name, used for files\n",
    "    \"\"\"\n",
    "    __name__ = None\n",
    "    __basename__ = None\n",
    "\n",
    "    def init(self, seed: int) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the model.\n",
    "\n",
    "        Do whatever is required to setup a new thread coarsening model here.\n",
    "        This method is called prior to training and predicting.\n",
    "        This method may be omitted if no initial setup is required.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        seed : int\n",
    "            The seed value used to reproducible results. May be 'None',\n",
    "            indicating that no seed is to be used.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def save(self, outpath: str) -> None:\n",
    "        \"\"\"\n",
    "        Save model state.\n",
    "\n",
    "        This must capture all of the relevant state of the model. It is up\n",
    "        to implementing classes to determine how best to save the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        outpath : str\n",
    "            The path to save the model state to.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def restore(self, inpath: str) -> None:\n",
    "        \"\"\"\n",
    "        Load a trained model from file.\n",
    "\n",
    "        This is called in place of init() if a saved model file exists. It\n",
    "        must restore all of the required model state.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inpath : str\n",
    "            The path to load the model from. This is the same path as\n",
    "            was passed to save() to create the file.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def train(self, cascading_features: np.array, cascading_y: np.array,\n",
    "              sequences: np.array, y_1hot: np.array, verbose: bool=False) -> None:\n",
    "        \"\"\"\n",
    "        Train a model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cascading_features : np.array\n",
    "            An array of feature vectors of shape (n,7,7). Used for the cascading\n",
    "            model, there are 7 vectors of 7 features for each benchmark, one for\n",
    "            each coarsening factor.\n",
    "\n",
    "        cascading_y : np.array\n",
    "            An array of classification labels of shape(n,7). Used for the cascading\n",
    "            model.\n",
    "\n",
    "        sequences : np.array\n",
    "            An array of encoded source code sequences of shape (n,seq_length).\n",
    "\n",
    "        y_1hot : np.array\n",
    "            An array of optimal coarsening factors of shape (n,6), in 1-hot encoding.\n",
    "\n",
    "        verbose: bool, optional\n",
    "            Whether to print verbose status messages during training.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self, cascading_features: np.array, sequences: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        Make predictions for programs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cascading_features : np.array\n",
    "            An array of feature vectors of shape (n,7,7). Used for the cascading\n",
    "            model, there are 7 vectors of 7 features for each benchmark, one for\n",
    "            each coarsening factor.\n",
    "\n",
    "        sequences : np.array\n",
    "            An array of encoded source code sequences of shape (n,seq_length).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array\n",
    "            Predicted 'y' values (optimal thread coarsening factors) with shape (n,1).\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define some utility code which we will use later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfs = [1, 2, 4, 8, 16, 32]  # thread coarsening factors\n",
    "\n",
    "def get_onehot(df, platform):\n",
    "    hot = np.zeros((len(df), len(cfs)), dtype=np.int32)\n",
    "    for i, cf in enumerate(df[f\"cf_{platform}\"]):\n",
    "        hot[i][cfs.index(cf)] = 1\n",
    "\n",
    "    return hot\n",
    "\n",
    "\n",
    "def get_magni_features(df, oracles, platform):\n",
    "    \"\"\"\n",
    "    Assemble cascading data.\n",
    "    \"\"\"\n",
    "    X_cc, y_cc, = [], []\n",
    "    for kernel in sorted(set(df[\"kernel\"])):\n",
    "        _df = df[df[\"kernel\"] == kernel]\n",
    "\n",
    "        oracle_cf = int(oracles[oracles[\"kernel\"] == kernel][f\"cf_{platform}\"].values[0])\n",
    "\n",
    "        feature_vectors = np.asarray([\n",
    "            _df['PCA1'].values,\n",
    "            _df['PCA2'].values,\n",
    "            _df['PCA3'].values,\n",
    "            _df['PCA4'].values,\n",
    "            _df['PCA5'].values,\n",
    "            _df['PCA6'].values,\n",
    "            _df['PCA7'].values,\n",
    "        ]).T\n",
    "                \n",
    "        X_cc.append(feature_vectors)\n",
    "        y = []\n",
    "        cfs__ = []\n",
    "        for i, cf in enumerate(cfs[:len(feature_vectors)]):\n",
    "            y_ = 1 if cf < oracle_cf else 0\n",
    "            y.append(y_)\n",
    "        y_cc.append(y)\n",
    "    \n",
    "        assert len(feature_vectors) == len(y)\n",
    "        \n",
    "    assert len(X_cc) == len(y_cc) == 17\n",
    "    \n",
    "    return np.asarray(X_cc), np.asarray(y_cc)\n",
    "\n",
    "\n",
    "def encode_srcs(srcs):\n",
    "    \"\"\" encode and pad source code for learning \"\"\"\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "    \n",
    "    seqs = [atomizer.atomize(src) for src in srcs]\n",
    "    pad_val = atomizer.vocab_size\n",
    "    encoded = np.array(pad_sequences(seqs, maxlen=1024, value=pad_val))\n",
    "    return np.vstack([np.expand_dims(x, axis=0) for x in encoded])\n",
    "\n",
    "\n",
    "def platform2str(platform):\n",
    "    if platform == \"Fermi\":\n",
    "        return \"NVIDIA GTX 480\"\n",
    "    elif platform == \"Kepler\":\n",
    "        return \"NVIDIA Tesla K20c\"\n",
    "    elif platform == \"Cypress\":\n",
    "        return \"AMD Radeon HD 5900\"\n",
    "    elif platform == \"Tahiti\":\n",
    "        return \"AMD Tahiti 7970\"\n",
    "    else:\n",
    "        raise LookupError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experimental Methodology\n",
    "\n",
    "For reproducible results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 204"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source encoder (see the *'Language Model.ipynb'* notebook for details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GreedyAtomizer[128 tokens]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from clgen import Language\n",
    "\n",
    "srcs = '\\n'.join(pd.read_csv(\"../data/case-study-a/cgo17-amd.csv\")['src'].values)\n",
    "atomizer = clgen.GreedyAtomizer.from_text(lang=Language.from_str(\"opencl\"), text=srcs)\n",
    "atomizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "from labm8 import fs\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "def evaluate(model):\n",
    "    # report progress:\n",
    "    from progressbar import ProgressBar\n",
    "    progressbar = [0, ProgressBar(max_value=68)]\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    X_seq = None  # defer sequence encoding (it's expensive)\n",
    "    \n",
    "    for i, platform in enumerate([\"Cypress\", \"Tahiti\", \"Fermi\", \"Kepler\"]):\n",
    "        platform_name = platform2str(platform)\n",
    "                \n",
    "        # load data\n",
    "        oracle_runtimes = np.array([float(x) for x in oracles[\"runtime_\" + platform]])\n",
    "        y = np.array([int(x) for x in oracles[\"cf_\" + platform]], dtype=np.int32)\n",
    "        y_1hot = get_onehot(oracles, platform)\n",
    "        X_cc, y_cc = get_magni_features(df, oracles, platform)\n",
    "        \n",
    "        # LOOCV\n",
    "        kf = KFold(n_splits=len(y), shuffle=False)\n",
    "    \n",
    "        for j, (train_index, test_index) in enumerate(kf.split(y)):\n",
    "        # indices = np.arange(len(y))\n",
    "        # train_index, test_index = train_test_split(indices, shuffle=True, random_state=seed, test_size=0.25)\n",
    "            kernel = sorted(set(df[\"kernel\"]))[test_index[0]]\n",
    "\n",
    "            model_name = model.__name__\n",
    "            model_basename = model.__basename__\n",
    "            \n",
    "            model_path = f\"../data/case-study-b/models/{model_basename}-{platform}-new-test.model\"\n",
    "            predictions_path = f\"../data/case-study-b/predictions/{model_basename}-{platform}-new-test.result\"  \n",
    "\n",
    "            if False:\n",
    "            # if fs.exists(predictions_path):\n",
    "                # load result from cache\n",
    "                with open(predictions_path, 'rb') as infile:\n",
    "                    p = pickle.load(infile)\n",
    "            else:\n",
    "                if False:\n",
    "                # if fs.exists(model_path):\n",
    "                    # load a trained model from cache\n",
    "                    model.restore(model_path)\n",
    "                else:\n",
    "                    # encode source codes\n",
    "                    if X_seq is None:\n",
    "                        X_seq = encode_srcs(df[\"src\"].values)\n",
    "\n",
    "                    # create a new model and train it\n",
    "                    model.init(seed=seed)\n",
    "                    model.train(cascading_features=np.concatenate(X_cc[train_index]),\n",
    "                                cascading_y=np.concatenate(y_cc[train_index]),\n",
    "                                sequences=X_seq[train_index],\n",
    "                                verbose=True, # TODO\n",
    "                                y_1hot=y_1hot[train_index])\n",
    "\n",
    "                    # cache the model\n",
    "                    fs.mkdir(fs.dirname(model_path))\n",
    "                    model.save(model_path)\n",
    "\n",
    "                # make prediction\n",
    "                p = model.predict(cascading_features=X_cc[test_index[0]], sequences=X_seq[test_index])[0]\n",
    "                p = min(p, 2 ** (len(X_cc[test_index[0]]) - 1))\n",
    "                \n",
    "                # cache the prediction\n",
    "                fs.mkdir(fs.dirname(predictions_path))\n",
    "                with open(predictions_path, 'wb') as outfile:\n",
    "                    pickle.dump(p, outfile)\n",
    "                    \n",
    "            # oracle prediction\n",
    "            o = y[test_index[0]]\n",
    "            correct = p == o\n",
    "\n",
    "            # get runtime without thread coarsening\n",
    "            row = df[(df[\"kernel\"] == kernel) & (df[\"cf\"] == 1)]\n",
    "            assert(len(row) == 1)  # sanity check\n",
    "            nocf_runtime = float(row[\"runtime_\" + platform])\n",
    "\n",
    "            # get runtime of prediction\n",
    "            row = df[(df[\"kernel\"] == kernel) & (df[\"cf\"] == p)]\n",
    "            assert(len(row) == 1)  # sanity check\n",
    "            p_runtime = float(row[\"runtime_\" + platform])\n",
    "            \n",
    "            # get runtime of oracle coarsening factor\n",
    "            o_runtime = oracle_runtimes[test_index[0]]\n",
    "\n",
    "            # speedup and % oracle\n",
    "            s_oracle = nocf_runtime / o_runtime\n",
    "            p_speedup = nocf_runtime / p_runtime\n",
    "            p_oracle = o_runtime / p_runtime\n",
    "\n",
    "            # record result\n",
    "            data.append({\n",
    "                \"Model\": model_name,\n",
    "                \"Platform\": platform_name,\n",
    "                \"Kernel\": kernel,\n",
    "                \"Oracle-CF\": o,\n",
    "                \"Predicted-CF\": p,\n",
    "                \"Speedup\": p_speedup,\n",
    "                \"Oracle\": p_oracle\n",
    "            })\n",
    "            \n",
    "            progressbar[0] += 1  # update progress bar\n",
    "            progressbar[1].update(progressbar[0])\n",
    "\n",
    "    return pd.DataFrame(data, columns=[\n",
    "        \"Model\", \"Platform\", \"Kernel\", \"Oracle-CF\", \"Predicted-CF\", \"Speedup\", \"Oracle\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Magni et al. Model\n",
    "\n",
    "The Magni et al. predictive model.\n",
    "\n",
    "Described in publication:\n",
    "\n",
    "> [1] Magni, A., Dubach, C., & O’Boyle, M. (2014). [Automatic Optimization of Thread-Coarsening for Graphics Processors](http://www.research.ed.ac.uk/portal/files/19958629/magni14pact.pdf). In PACT. ACM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "# during grid search, not all parameters will converge. Ignore these warnings\n",
    "from warnings import filterwarnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "class Magni(ThreadCoarseningModel):\n",
    "    __name__ = \"Magni et al.\"\n",
    "    __basename__ = \"magni\"\n",
    "\n",
    "    def init(self, seed: int=None):\n",
    "        # the neural network\n",
    "        nn = MLPClassifier(random_state=seed, shuffle=True)\n",
    "\n",
    "        # cross-validation over the training set. We train on 16 programs,\n",
    "        # so with k=16 and no shuffling of the data, we're performing\n",
    "        # nested leave-one-out cross-validation\n",
    "        inner_cv = KFold(n_splits=16, shuffle=False)\n",
    "\n",
    "        # hyper-parameter combinations to try\n",
    "        params = {\n",
    "            \"max_iter\": [200, 500, 1000, 2000],\n",
    "            \"hidden_layer_sizes\": [\n",
    "                (32,),\n",
    "                (32, 32),\n",
    "                (32, 32, 32),\n",
    "                (64,),\n",
    "                (64, 64),\n",
    "                (64, 64, 64),\n",
    "                (128,),\n",
    "                (128, 128),\n",
    "                (128, 128, 128),\n",
    "                (256,),\n",
    "                (256, 256),\n",
    "                (256, 256, 256),\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        self.model = GridSearchCV(nn, cv=inner_cv, param_grid=params, n_jobs=-1)\n",
    "\n",
    "    def save(self, outpath):\n",
    "        with open(outpath, 'wb') as outfile:\n",
    "            pickle.dump(self.model, outfile)\n",
    "\n",
    "    def restore(self, inpath):\n",
    "        with open(inpath, 'rb') as infile:\n",
    "            self.model = pickle.load(infile)\n",
    "\n",
    "    def train(self, cascading_features: np.array, cascading_y: np.array,\n",
    "              sequences: np.array, y_1hot: np.array, verbose: bool=False) -> None:\n",
    "        self.model.fit(cascading_features, cascading_y)\n",
    "\n",
    "    def predict(self, cascading_features: np.array, sequences: np.array) -> np.array:\n",
    "        # we only support leave-one-out cross-validation (implementation detail):\n",
    "        assert(len(sequences) == 1)\n",
    "\n",
    "        # The binary cascading model:\n",
    "        #\n",
    "        # iteratively apply thread coarsening, using a new feature vector\n",
    "        # every time coarsening is applied\n",
    "        for i in range(len(cascading_features)):\n",
    "            # predict whether to coarsen, using the program features of\n",
    "            # the current coarsening level:\n",
    "            should_coarsen = self.model.predict([cascading_features[i]])[0]\n",
    "            if not should_coarsen:\n",
    "                break\n",
    "        p = cfs[i]\n",
    "        return [cfs[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Evaluating Magni et al. ...\", file=sys.stderr)\n",
    "# magni = evaluate(Magni())\n",
    "# magni.groupby('Platform')['Platform', 'Speedup', 'Oracle'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. DeepTune\n",
    "\n",
    "We predict thread coarsening factor directly from raw source code inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DeepTune(ThreadCoarseningModel):\n",
    "    __name__ = \"DeepTune\"\n",
    "    __basename__ = \"deeptune\"\n",
    "\n",
    "    def init(self, seed: int=None):\n",
    "        from keras.layers import Input, Dropout, Embedding, merge, LSTM, Dense, Conv1D, GlobalMaxPooling1D\n",
    "        from keras.layers.normalization import BatchNormalization\n",
    "        from keras.models import Model, Sequential, load_model\n",
    "    \n",
    "        np.random.seed(seed)\n",
    "    \n",
    "        # Vocabulary has a padding character\n",
    "        vocab_size = atomizer.vocab_size + 1\n",
    "\n",
    "        # Language model. Takes as inputs source code sequences.\n",
    "        seq_inputs = Input(shape=(1024,), dtype=\"int32\")\n",
    "        x = Embedding(input_dim=vocab_size, input_length=1024,\n",
    "                      output_dim=64, name=\"embedding\")(seq_inputs)\n",
    "        x = LSTM(64, return_sequences=True, implementation=1, name=\"lstm_1\")(x)\n",
    "        x = LSTM(64, implementation=1, name=\"lstm_2\")(x)\n",
    "        # x = Conv1D(32, 9, name=\"conv_1\")(x)\n",
    "        # x = Conv1D(32, 9, name=\"conv_2\")(x)\n",
    "        # x = GlobalMaxPooling1D()(x)\n",
    "        # Heuristic model. Takes as inputs the language model,\n",
    "        #   outputs 1-of-6 thread coarsening factor\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dense(32, activation=\"relu\")(x)\n",
    "        outputs = Dense(6, activation=\"sigmoid\")(x)\n",
    "\n",
    "        self.model = Model(inputs=seq_inputs, outputs=outputs)\n",
    "        self.model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "    def save(self, outpath: str):\n",
    "        self.model.save(outpath)\n",
    "\n",
    "    def restore(self, inpath: str):\n",
    "        self.model = load_model(inpath)\n",
    "        \n",
    "    def train(self, cascading_features: np.array, cascading_y: np.array,\n",
    "              sequences: np.array, y_1hot: np.array, verbose: bool=False) -> None:\n",
    "        self.model.fit(sequences, y_1hot, epochs=50, batch_size=64, verbose=verbose, shuffle=True)\n",
    "\n",
    "    def predict(self, cascading_features: np.array, sequences: np.array) -> np.array:\n",
    "        # directly predict optimal thread coarsening factor from source sequences:\n",
    "        p = np.array(self.model.predict(sequences, batch_size=64, verbose=0))\n",
    "        indices = [np.argmax(x) for x in p]\n",
    "        return [cfs[x] for x in indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview of the DeepTune model, showing the number of parameters in each layer, used to construct Table 5 in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:63: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:492: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3630: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1242: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2884: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 1024, 64)          8256      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1024, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 76,838\n",
      "Trainable params: 76,710\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deeptune_model = DeepTune()\n",
    "deeptune_model.init(seed)\n",
    "deeptune_model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<svg height=\"553pt\" viewBox=\"0.00 0.00 500.00 553.00\" width=\"500pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 549)\">\n<title>G</title>\n<polygon fill=\"white\" points=\"-4,4 -4,-549 496,-549 496,4 -4,4\" stroke=\"none\"/>\n<!-- 140074520633104 -->\n<g class=\"node\" id=\"node1\"><title>140074520633104</title>\n<polygon fill=\"none\" points=\"77,-498.5 77,-544.5 415,-544.5 415,-498.5 77,-498.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"157\" y=\"-517.8\">input_1: InputLayer</text>\n<polyline fill=\"none\" points=\"237,-498.5 237,-544.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"237,-521.5 305,-521.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"305,-498.5 305,-544.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"360\" y=\"-529.3\">(None, 1024)</text>\n<polyline fill=\"none\" points=\"305,-521.5 415,-521.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"360\" y=\"-506.3\">(None, 1024)</text>\n</g>\n<!-- 140073461649232 -->\n<g class=\"node\" id=\"node2\"><title>140073461649232</title>\n<polygon fill=\"none\" points=\"50,-415.5 50,-461.5 442,-461.5 442,-415.5 50,-415.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.5\" y=\"-434.8\">embedding: Embedding</text>\n<polyline fill=\"none\" points=\"237,-415.5 237,-461.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"237,-438.5 305,-438.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"305,-415.5 305,-461.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373.5\" y=\"-446.3\">(None, 1024)</text>\n<polyline fill=\"none\" points=\"305,-438.5 442,-438.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373.5\" y=\"-423.3\">(None, 1024, 64)</text>\n</g>\n<!-- 140074520633104&#45;&gt;140073461649232 -->\n<g class=\"edge\" id=\"edge1\"><title>140074520633104-&gt;140073461649232</title>\n<path d=\"M246,-498.366C246,-490.152 246,-480.658 246,-471.725\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"249.5,-471.607 246,-461.607 242.5,-471.607 249.5,-471.607\" stroke=\"black\"/>\n</g>\n<!-- 140073461855760 -->\n<g class=\"node\" id=\"node3\"><title>140073461855760</title>\n<polygon fill=\"none\" points=\"85.5,-332.5 85.5,-378.5 406.5,-378.5 406.5,-332.5 85.5,-332.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.5\" y=\"-351.8\">lstm_1: LSTM</text>\n<polyline fill=\"none\" points=\"201.5,-332.5 201.5,-378.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"201.5,-355.5 269.5,-355.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"269.5,-332.5 269.5,-378.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338\" y=\"-363.3\">(None, 1024, 64)</text>\n<polyline fill=\"none\" points=\"269.5,-355.5 406.5,-355.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338\" y=\"-340.3\">(None, 1024, 64)</text>\n</g>\n<!-- 140073461649232&#45;&gt;140073461855760 -->\n<g class=\"edge\" id=\"edge2\"><title>140073461649232-&gt;140073461855760</title>\n<path d=\"M246,-415.366C246,-407.152 246,-397.658 246,-388.725\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"249.5,-388.607 246,-378.607 242.5,-388.607 249.5,-388.607\" stroke=\"black\"/>\n</g>\n<!-- 140073460411792 -->\n<g class=\"node\" id=\"node4\"><title>140073460411792</title>\n<polygon fill=\"none\" points=\"85.5,-249.5 85.5,-295.5 406.5,-295.5 406.5,-249.5 85.5,-249.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.5\" y=\"-268.8\">lstm_2: LSTM</text>\n<polyline fill=\"none\" points=\"201.5,-249.5 201.5,-295.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"201.5,-272.5 269.5,-272.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"269.5,-249.5 269.5,-295.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338\" y=\"-280.3\">(None, 1024, 64)</text>\n<polyline fill=\"none\" points=\"269.5,-272.5 406.5,-272.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338\" y=\"-257.3\">(None, 64)</text>\n</g>\n<!-- 140073461855760&#45;&gt;140073460411792 -->\n<g class=\"edge\" id=\"edge3\"><title>140073461855760-&gt;140073460411792</title>\n<path d=\"M246,-332.366C246,-324.152 246,-314.658 246,-305.725\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"249.5,-305.607 246,-295.607 242.5,-305.607 249.5,-305.607\" stroke=\"black\"/>\n</g>\n<!-- 140073459947088 -->\n<g class=\"node\" id=\"node5\"><title>140073459947088</title>\n<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 492,-212.5 492,-166.5 0,-166.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166\" y=\"-185.8\">batch_normalization_1: BatchNormalization</text>\n<polyline fill=\"none\" points=\"332,-166.5 332,-212.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"332,-189.5 400,-189.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"400,-166.5 400,-212.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"446\" y=\"-197.3\">(None, 64)</text>\n<polyline fill=\"none\" points=\"400,-189.5 492,-189.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"446\" y=\"-174.3\">(None, 64)</text>\n</g>\n<!-- 140073460411792&#45;&gt;140073459947088 -->\n<g class=\"edge\" id=\"edge4\"><title>140073460411792-&gt;140073459947088</title>\n<path d=\"M246,-249.366C246,-241.152 246,-231.658 246,-222.725\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"249.5,-222.607 246,-212.607 242.5,-222.607 249.5,-222.607\" stroke=\"black\"/>\n</g>\n<!-- 140073448226640 -->\n<g class=\"node\" id=\"node6\"><title>140073448226640</title>\n<polygon fill=\"none\" points=\"102,-83.5 102,-129.5 390,-129.5 390,-83.5 102,-83.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166\" y=\"-102.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"230,-83.5 230,-129.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"230,-106.5 298,-106.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"298,-83.5 298,-129.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"344\" y=\"-114.3\">(None, 64)</text>\n<polyline fill=\"none\" points=\"298,-106.5 390,-106.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"344\" y=\"-91.3\">(None, 32)</text>\n</g>\n<!-- 140073459947088&#45;&gt;140073448226640 -->\n<g class=\"edge\" id=\"edge5\"><title>140073459947088-&gt;140073448226640</title>\n<path d=\"M246,-166.366C246,-158.152 246,-148.658 246,-139.725\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"249.5,-139.607 246,-129.607 242.5,-139.607 249.5,-139.607\" stroke=\"black\"/>\n</g>\n<!-- 140073446817680 -->\n<g class=\"node\" id=\"node7\"><title>140073446817680</title>\n<polygon fill=\"none\" points=\"102,-0.5 102,-46.5 390,-46.5 390,-0.5 102,-0.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166\" y=\"-19.8\">dense_2: Dense</text>\n<polyline fill=\"none\" points=\"230,-0.5 230,-46.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"230,-23.5 298,-23.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"298,-0.5 298,-46.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"344\" y=\"-31.3\">(None, 32)</text>\n<polyline fill=\"none\" points=\"298,-23.5 390,-23.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"344\" y=\"-8.3\">(None, 6)</text>\n</g>\n<!-- 140073448226640&#45;&gt;140073446817680 -->\n<g class=\"edge\" id=\"edge6\"><title>140073448226640-&gt;140073446817680</title>\n<path d=\"M246,-83.3664C246,-75.1516 246,-65.6579 246,-56.7252\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"249.5,-56.6068 246,-46.6068 242.5,-56.6069 249.5,-56.6068\" stroke=\"black\"/>\n</g>\n</g>\n</svg>",
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def isnotebook():\n",
    "    # written by @mtd http://stackoverflow.com/a/39662359\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':  # Jupyter notebook or qtconsole?\n",
    "            return True\n",
    "        elif shell == 'TerminalInteractiveShell':  # Terminal running IPython?\n",
    "            return False\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "\n",
    "\n",
    "img = None\n",
    "if isnotebook():\n",
    "    from keras.utils.vis_utils import model_to_dot\n",
    "    from IPython.display import SVG\n",
    "    img = SVG(model_to_dot(deeptune_model.model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DeepTune ...\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/ipykernel_launcher.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:953: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:675: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 11:19:28.469299: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-12-14 11:19:28.488592: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz\n",
      "2022-12-14 11:19:28.494172: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x73efa90 executing computations on platform Host. Devices:\n",
      "2022-12-14 11:19:28.494331: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2022-12-14 11:19:30.474439: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 20s 2s/step - loss: 1.7951 - acc: 0.2500\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 11s 915ms/step - loss: 1.7711 - acc: 0.2500\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 11s 939ms/step - loss: 1.7500 - acc: 0.4167\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 11s 877ms/step - loss: 1.7266 - acc: 0.4167\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 10s 839ms/step - loss: 1.6994 - acc: 0.4167\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 10s 803ms/step - loss: 1.6683 - acc: 0.4167\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 9s 788ms/step - loss: 1.6337 - acc: 0.4167\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 10s 824ms/step - loss: 1.5934 - acc: 0.4167\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 10s 842ms/step - loss: 1.5476 - acc: 0.4167\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 10s 799ms/step - loss: 1.4991 - acc: 0.4167\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 10s 834ms/step - loss: 1.4476 - acc: 0.4167\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 10s 868ms/step - loss: 1.3946 - acc: 0.4167\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 11s 877ms/step - loss: 1.3418 - acc: 0.4167\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 10s 807ms/step - loss: 1.2965 - acc: 0.4167\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 10s 842ms/step - loss: 1.2592 - acc: 0.4167\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 10s 794ms/step - loss: 1.2351 - acc: 0.4167\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 10s 811ms/step - loss: 1.2162 - acc: 0.4167\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 10s 793ms/step - loss: 1.2016 - acc: 0.4167\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 10s 810ms/step - loss: 1.1886 - acc: 0.4167\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 9s 752ms/step - loss: 1.1747 - acc: 0.4167\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 10s 868ms/step - loss: 1.1584 - acc: 0.4167\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 10s 805ms/step - loss: 1.1507 - acc: 0.4167\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 9s 732ms/step - loss: 1.1332 - acc: 0.4167\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 9s 737ms/step - loss: 1.1219 - acc: 0.4167\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 10s 857ms/step - loss: 1.1107 - acc: 0.4167\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 12s 968ms/step - loss: 1.0992 - acc: 0.4167\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 9s 736ms/step - loss: 1.0899 - acc: 0.4167\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 9s 745ms/step - loss: 1.0820 - acc: 0.4167\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 8s 694ms/step - loss: 1.0743 - acc: 0.4167\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 8s 689ms/step - loss: 1.0669 - acc: 0.4167\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 9s 729ms/step - loss: 1.0598 - acc: 0.4167\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 9s 721ms/step - loss: 1.0535 - acc: 0.4167\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 9s 721ms/step - loss: 1.0483 - acc: 0.4167\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 8s 689ms/step - loss: 1.0437 - acc: 0.4167\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 10s 794ms/step - loss: 1.0394 - acc: 0.4167\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 11s 876ms/step - loss: 1.0356 - acc: 0.4167\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 10s 799ms/step - loss: 1.0321 - acc: 0.4167\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 10s 834ms/step - loss: 1.0289 - acc: 0.4167\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.0264 - acc: 0.4167\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 11s 927ms/step - loss: 1.0243 - acc: 0.4167\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 10s 834ms/step - loss: 1.0221 - acc: 0.4167\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 1.0199 - acc: 0.4167\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 12s 965ms/step - loss: 1.0181 - acc: 0.4167\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 10s 835ms/step - loss: 1.0167 - acc: 0.4167\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 9s 762ms/step - loss: 1.0153 - acc: 0.4167\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 10s 836ms/step - loss: 1.0139 - acc: 0.4167\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 11s 942ms/step - loss: 1.0126 - acc: 0.4167\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 11s 955ms/step - loss: 1.0116 - acc: 0.4167\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 11s 904ms/step - loss: 1.0107 - acc: 0.4167\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 9s 780ms/step - loss: 1.0098 - acc: 0.4167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 68) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/ipykernel_launcher.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 21s 2s/step - loss: 1.8040 - acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 1.7888 - acc: 0.3333\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.7742 - acc: 0.3333\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 981ms/step - loss: 1.7620 - acc: 0.4167\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 16s 1s/step - loss: 1.7514 - acc: 0.4167\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 10s 853ms/step - loss: 1.7375 - acc: 0.4167\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 21s 2s/step - loss: 1.7200 - acc: 0.4167\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.6993 - acc: 0.4167\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 974ms/step - loss: 1.6749 - acc: 0.4167\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.6471 - acc: 0.4167\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 970ms/step - loss: 1.6145 - acc: 0.4167\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.5781 - acc: 0.4167\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.5380 - acc: 0.4167\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 10s 850ms/step - loss: 1.4946 - acc: 0.4167\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.4540 - acc: 0.4167\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 9s 775ms/step - loss: 1.4153 - acc: 0.4167\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 965ms/step - loss: 1.3825 - acc: 0.4167\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.3604 - acc: 0.4167\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 12s 984ms/step - loss: 1.3439 - acc: 0.4167\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.3258 - acc: 0.4167\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.3072 - acc: 0.4167\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 10s 860ms/step - loss: 1.2896 - acc: 0.4167\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.2751 - acc: 0.4167\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 12s 998ms/step - loss: 1.2643 - acc: 0.4167\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 9s 784ms/step - loss: 1.2554 - acc: 0.4167\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 12s 983ms/step - loss: 1.2454 - acc: 0.4167\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.2412 - acc: 0.4167\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 10s 793ms/step - loss: 1.2337 - acc: 0.4167\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 9s 772ms/step - loss: 1.2205 - acc: 0.4167\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.2125 - acc: 0.4167\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 11s 958ms/step - loss: 1.2045 - acc: 0.4167\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 11s 909ms/step - loss: 1.1952 - acc: 0.4167\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 11s 893ms/step - loss: 1.1902 - acc: 0.4167\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 11s 923ms/step - loss: 1.1837 - acc: 0.4167\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 9s 781ms/step - loss: 1.1768 - acc: 0.4167\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 9s 730ms/step - loss: 1.1725 - acc: 0.4167\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 12s 970ms/step - loss: 1.1683 - acc: 0.4167\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 9s 728ms/step - loss: 1.1626 - acc: 0.4167\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 9s 718ms/step - loss: 1.1578 - acc: 0.4167\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 11s 915ms/step - loss: 1.1540 - acc: 0.4167\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 16s 1s/step - loss: 1.1503 - acc: 0.4167\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 11s 888ms/step - loss: 1.1465 - acc: 0.4167\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 15s 1s/step - loss: 1.1431 - acc: 0.4167\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 9s 770ms/step - loss: 1.1407 - acc: 0.4167\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 1.1386 - acc: 0.4167\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 11s 884ms/step - loss: 1.1361 - acc: 0.4167\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 9s 760ms/step - loss: 1.1339 - acc: 0.4167\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 11s 905ms/step - loss: 1.1321 - acc: 0.4167\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 15s 1s/step - loss: 1.1306 - acc: 0.4167\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 12s 994ms/step - loss: 1.1291 - acc: 0.4167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2% (2 of 68) |                         | Elapsed Time: 0:10:24 ETA:   5:43:14/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/ipykernel_launcher.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 27s 2s/step - loss: 1.7902 - acc: 0.0833\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 9s 733ms/step - loss: 1.7682 - acc: 0.3333\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 9s 735ms/step - loss: 1.7496 - acc: 0.4167\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 11s 952ms/step - loss: 1.7290 - acc: 0.4167\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 8s 664ms/step - loss: 1.7047 - acc: 0.4167\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 8s 676ms/step - loss: 1.6769 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 8s 675ms/step - loss: 1.6457 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 11s 953ms/step - loss: 1.6112 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 9s 717ms/step - loss: 1.5739 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 8s 678ms/step - loss: 1.5358 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 8s 628ms/step - loss: 1.4977 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 11s 903ms/step - loss: 1.4614 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 8s 702ms/step - loss: 1.4287 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 8s 697ms/step - loss: 1.4007 - acc: 0.5000\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 8s 666ms/step - loss: 1.3763 - acc: 0.5000\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 10s 822ms/step - loss: 1.3532 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 10s 853ms/step - loss: 1.3317 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 8s 637ms/step - loss: 1.3118 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 8s 644ms/step - loss: 1.2970 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 8s 660ms/step - loss: 1.2920 - acc: 0.4167\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.2820 - acc: 0.4167\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 9s 719ms/step - loss: 1.2741 - acc: 0.4167\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 10s 803ms/step - loss: 1.2656 - acc: 0.4167\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 1.2561 - acc: 0.4167\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 11s 958ms/step - loss: 1.2474 - acc: 0.4167\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 1.2407 - acc: 0.4167\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 15s 1s/step - loss: 1.2354 - acc: 0.4167\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 9s 740ms/step - loss: 1.2316 - acc: 0.4167\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 8s 701ms/step - loss: 1.2269 - acc: 0.4167\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 9s 768ms/step - loss: 1.2218 - acc: 0.4167\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 9s 770ms/step - loss: 1.2168 - acc: 0.4167\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 1.2129 - acc: 0.4167\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 9s 731ms/step - loss: 1.2092 - acc: 0.4167\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 8s 700ms/step - loss: 1.2058 - acc: 0.4167\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 9s 710ms/step - loss: 1.2026 - acc: 0.4167\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 8s 688ms/step - loss: 1.1996 - acc: 0.4167\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.1969 - acc: 0.4167\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 9s 767ms/step - loss: 1.1947 - acc: 0.4167\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 8s 690ms/step - loss: 1.1927 - acc: 0.4167\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 9s 760ms/step - loss: 1.1908 - acc: 0.4167\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 9s 719ms/step - loss: 1.1892 - acc: 0.4167\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 12s 987ms/step - loss: 1.1877 - acc: 0.4167\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 10s 854ms/step - loss: 1.1863 - acc: 0.4167\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 9s 775ms/step - loss: 1.1851 - acc: 0.4167\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 8s 693ms/step - loss: 1.1841 - acc: 0.4167\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 11s 917ms/step - loss: 1.1832 - acc: 0.4167\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 9s 752ms/step - loss: 1.1823 - acc: 0.4167\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.1814 - acc: 0.4167\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 10s 867ms/step - loss: 1.1806 - acc: 0.4167\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 9s 729ms/step - loss: 1.1799 - acc: 0.4167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4% (3 of 68) |#                        | Elapsed Time: 0:19:05 ETA:   9:24:46/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/ipykernel_launcher.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 1.7938 - acc: 0.0833\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 11s 914ms/step - loss: 1.7726 - acc: 0.1667\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 11s 905ms/step - loss: 1.7542 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 11s 939ms/step - loss: 1.7342 - acc: 0.5833\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 16s 1s/step - loss: 1.7118 - acc: 0.5833\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 11s 886ms/step - loss: 1.6860 - acc: 0.5833\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 12s 964ms/step - loss: 1.6560 - acc: 0.5833\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 11s 915ms/step - loss: 1.6223 - acc: 0.5833\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 990ms/step - loss: 1.5853 - acc: 0.5833\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 10s 864ms/step - loss: 1.5471 - acc: 0.5833\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 17s 1s/step - loss: 1.5087 - acc: 0.5833\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 16s 1s/step - loss: 1.4709 - acc: 0.5833\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 10s 865ms/step - loss: 1.4336 - acc: 0.5833\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 11s 917ms/step - loss: 1.3969 - acc: 0.5833\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 1.3612 - acc: 0.5833\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 10s 813ms/step - loss: 1.3282 - acc: 0.5833\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 11s 891ms/step - loss: 1.2965 - acc: 0.5833\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 15s 1s/step - loss: 1.2663 - acc: 0.5833\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 9s 791ms/step - loss: 1.2383 - acc: 0.5833\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 10s 865ms/step - loss: 1.2135 - acc: 0.5833\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 10s 839ms/step - loss: 1.1924 - acc: 0.5833\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 10s 806ms/step - loss: 1.1713 - acc: 0.5833\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 10s 792ms/step - loss: 1.1516 - acc: 0.5833\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 17s 1s/step - loss: 1.1347 - acc: 0.5833\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 10s 861ms/step - loss: 1.1202 - acc: 0.5833\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 9s 787ms/step - loss: 1.1078 - acc: 0.5833\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 11s 891ms/step - loss: 1.0972 - acc: 0.5833\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 11s 904ms/step - loss: 1.0888 - acc: 0.5833\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 11s 917ms/step - loss: 1.0813 - acc: 0.5833\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.0744 - acc: 0.5833\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.0678 - acc: 0.5833\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 10s 806ms/step - loss: 1.0613 - acc: 0.5833\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 10s 843ms/step - loss: 1.0553 - acc: 0.5833\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 10s 858ms/step - loss: 1.0496 - acc: 0.5833\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 10s 859ms/step - loss: 1.0445 - acc: 0.5833\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 11s 930ms/step - loss: 1.0395 - acc: 0.5833\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 16s 1s/step - loss: 1.0348 - acc: 0.5833\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 11s 879ms/step - loss: 1.0304 - acc: 0.5833\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 10s 821ms/step - loss: 1.0264 - acc: 0.5833\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 10s 827ms/step - loss: 1.0226 - acc: 0.5833\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 11s 891ms/step - loss: 1.0188 - acc: 0.5833\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 10s 871ms/step - loss: 1.0150 - acc: 0.5833\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 10s 814ms/step - loss: 1.0116 - acc: 0.5833\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 17s 1s/step - loss: 1.0083 - acc: 0.5833\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 11s 907ms/step - loss: 1.0052 - acc: 0.5833\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 10s 823ms/step - loss: 1.0023 - acc: 0.5833\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 10s 839ms/step - loss: 0.9996 - acc: 0.5833\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9972 - acc: 0.5833\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 10s 808ms/step - loss: 0.9950 - acc: 0.5833\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 9s 789ms/step - loss: 0.9929 - acc: 0.5833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5% (4 of 68) |#                        | Elapsed Time: 0:29:18 ETA:  10:54:30/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speedup</th>\n",
       "      <th>Oracle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platform</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AMD Radeon HD 5900</th>\n",
       "      <td>1.769493</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMD Tahiti 7970</th>\n",
       "      <td>1.385804</td>\n",
       "      <td>0.637469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVIDIA GTX 480</th>\n",
       "      <td>1.121572</td>\n",
       "      <td>0.964789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVIDIA Tesla K20c</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.901163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Speedup    Oracle\n",
       "Platform                              \n",
       "AMD Radeon HD 5900  1.769493  1.000000\n",
       "AMD Tahiti 7970     1.385804  0.637469\n",
       "NVIDIA GTX 480      1.121572  0.964789\n",
       "NVIDIA Tesla K20c   1.000000  0.901163"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Evaluating DeepTune ...\", file=sys.stderr)\n",
    "deeptune = evaluate(DeepTune())\n",
    "deeptune.groupby('Platform')['Platform', 'Speedup', 'Oracle'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. DeepTune-TL\n",
    "\n",
    "As described in Section 4.3. of the paper, we use *Transfer Learning* to leverage information gained from one optimization problem for another. To do this, we simply initialize the language model with the weights learned for Case Study A. See '*Case Study A.ipynb*' for the code to produce these weights. Apart from initializing the weights from the other optimization task, the model remains unchanged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DeepTune_TL(DeepTune):\n",
    "    __name__ = \"DeepTune-TL\"\n",
    "    __basename__ = \"deeptune_tl\"\n",
    "\n",
    "    starting_weights = \"../data/case-study-b/case-study-a-weights.h5\"\n",
    "\n",
    "    def init(self, *args, **kwargs):\n",
    "        super(DeepTune_TL, self).init(*args, **kwargs)\n",
    "        self.model.load_weights(self.starting_weights, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DeepTune-TL ...\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/ipykernel_launcher.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 20s 2s/step - loss: 1.7965 - acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.7706 - acc: 0.3333\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 9s 775ms/step - loss: 1.7478 - acc: 0.4167\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 8s 702ms/step - loss: 1.7246 - acc: 0.4167\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 8s 696ms/step - loss: 1.6980 - acc: 0.4167\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 9s 739ms/step - loss: 1.6675 - acc: 0.4167\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 8s 679ms/step - loss: 1.6328 - acc: 0.4167\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 11s 947ms/step - loss: 1.5944 - acc: 0.4167\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 10s 844ms/step - loss: 1.5525 - acc: 0.4167\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 8s 697ms/step - loss: 1.5083 - acc: 0.4167\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 8s 668ms/step - loss: 1.4623 - acc: 0.4167\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 9s 723ms/step - loss: 1.4195 - acc: 0.4167\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 10s 797ms/step - loss: 1.3771 - acc: 0.4167\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 9s 763ms/step - loss: 1.3377 - acc: 0.4167\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 1.3006 - acc: 0.4167\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 10s 813ms/step - loss: 1.2693 - acc: 0.4167\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 8s 687ms/step - loss: 1.2445 - acc: 0.4167\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 9s 726ms/step - loss: 1.2233 - acc: 0.4167\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 9s 715ms/step - loss: 1.2066 - acc: 0.4167\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 9s 752ms/step - loss: 1.1966 - acc: 0.4167\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 9s 710ms/step - loss: 1.1780 - acc: 0.4167\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.1657 - acc: 0.4167\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 9s 712ms/step - loss: 1.1514 - acc: 0.4167\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 9s 757ms/step - loss: 1.1378 - acc: 0.4167\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 8s 683ms/step - loss: 1.1246 - acc: 0.4167\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 9s 737ms/step - loss: 1.1134 - acc: 0.4167\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 9s 763ms/step - loss: 1.1033 - acc: 0.4167\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 9s 738ms/step - loss: 1.0934 - acc: 0.4167\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.0862 - acc: 0.4167\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 9s 725ms/step - loss: 1.0781 - acc: 0.4167\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 9s 711ms/step - loss: 1.0715 - acc: 0.4167\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 8s 688ms/step - loss: 1.0655 - acc: 0.4167\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 8s 698ms/step - loss: 1.0599 - acc: 0.4167\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 9s 711ms/step - loss: 1.0546 - acc: 0.4167\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 9s 768ms/step - loss: 1.0497 - acc: 0.4167\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 15s 1s/step - loss: 1.0454 - acc: 0.4167\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 10s 862ms/step - loss: 1.0415 - acc: 0.4167\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 9s 773ms/step - loss: 1.0380 - acc: 0.4167\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 8s 707ms/step - loss: 1.0348 - acc: 0.4167\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3011/1820007527.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating DeepTune-TL ...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdeeptune_tl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDeepTune_TL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdeeptune_tl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Platform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Platform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Speedup'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Oracle'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3011/3437668523.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     57\u001b[0m                             \u001b[0msequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                             y_1hot=y_1hot[train_index])\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0;31m# cache the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3011/4201039237.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, cascading_features, cascading_y, sequences, y_1hot, verbose)\u001b[0m\n\u001b[1;32m     39\u001b[0m     def train(self, cascading_features: np.array, cascading_y: np.array,\n\u001b[1;32m     40\u001b[0m               sequences: np.array, y_1hot: np.array, verbose: bool=False) -> None:\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_1hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcascading_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2352\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Evaluating DeepTune-TL ...\", file=sys.stderr)\n",
    "deeptune_tl = evaluate(DeepTune_TL())\n",
    "deeptune_tl.groupby('Platform')['Platform', 'Speedup', 'Oracle'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Average Speedup and Oracle of each model across all platforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array([\n",
    "    # magni[['Speedup', 'Oracle']].mean(),\n",
    "    deeptune[['Speedup', 'Oracle']].mean(),\n",
    "    deeptune_tl[['Speedup', 'Oracle']].mean(),\n",
    "]).T\n",
    "\n",
    "pd.DataFrame(d, columns=[\"DeepTune\", \"DeepTune-TL\"], index=[\"Speedup\", \"Oracle\"])\n",
    "# pd.DataFrame(d, columns=[\"Magni et al.\", \"DeepTune\", \"DeepTune-TL\"], index=[\"Speedup\", \"Oracle\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation\n",
    "\n",
    "### 4.1. Speedups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "# d.append(np.append(magni.groupby(['Platform'])['Speedup'].mean().values,\n",
    "#                    magni['Speedup'].mean()))\n",
    "d.append(np.append(deeptune.groupby(['Platform'])['Speedup'].mean().values,\n",
    "                   deeptune['Speedup'].mean()))\n",
    "d.append(np.append(deeptune_tl.groupby(['Platform'])['Speedup'].mean().values,\n",
    "                   deeptune_tl['Speedup'].mean()))\n",
    "d = np.array(d).T.reshape(5, 3)\n",
    "\n",
    "pd.DataFrame(d, columns=['DeepTune', 'DeepTune-TL'],\n",
    "             index=['AMD Radeon HD 5900', 'AMD Tahiti 7970', \n",
    "                    'NVIDIA GTX 480', 'NVIDIA Tesla K20c', 'Average'])\n",
    "# pd.DataFrame(d, columns=['Magni et al.', 'DeepTune', 'DeepTune-TL'],\n",
    "#              index=['AMD Radeon HD 5900', 'AMD Tahiti 7970', \n",
    "#                     'NVIDIA GTX 480', 'NVIDIA Tesla K20c', 'Average'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 8 of the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isnotebook():\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    from matplotlib.ticker import FormatStrFormatter\n",
    "    from labm8 import viz\n",
    "\n",
    "    # Plotting configuration\n",
    "    %matplotlib inline\n",
    "    sns.set(style=\"ticks\", color_codes=True)\n",
    "    plt.style.use([\"seaborn-white\", \"seaborn-paper\"])\n",
    "    matplotlib.rcParams['figure.dpi'] = 120\n",
    "\n",
    "    for i, platform in enumerate([\"AMD Radeon HD 5900\", \"AMD Tahiti 7970\", \"NVIDIA GTX 480\", \"NVIDIA Tesla K20c\"]):\n",
    "\n",
    "        def get_speedups(df, platform):\n",
    "            \"\"\" get % accuracies for platform, aggregated by benchmark suite \"\"\"\n",
    "            r = df[df[\"Platform\"] == platform]\n",
    "            d = pd.DataFrame(r[\"Speedup\"].values, columns=['Speedup'], index=r['Kernel'])\n",
    "            avg = pd.Series([d.mean(),], index=[\"Speedup\"], name=\"Average\")\n",
    "            return d.append(avg)\n",
    "\n",
    "        # Aggregate data\n",
    "        models, results = (Magni, DeepTune, DeepTune_TL), (magni, deeptune, deeptune_tl)\n",
    "        dfs = [get_speedups(r, platform) for r in results]\n",
    "\n",
    "        speedups    = np.concatenate([dfs[i]['Speedup'].values for i in range(len(dfs))])\n",
    "        kernels     = np.concatenate([dfs[i].index.values for i in range(len(dfs))])\n",
    "        model_names = np.concatenate([np.array([m().__name__] * len(dfs[0])) for m in models])\n",
    "\n",
    "        df = pd.DataFrame([{\"Kernel\": k, \"Speedup\": s - 1, \"Model\": m}\n",
    "                           for k, s, m in zip(kernels, speedups, model_names)])\n",
    "\n",
    "        # Plot\n",
    "        palette = sns.cubehelix_palette(3, rot=.5, light=.85, dark=.35)\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        ax = sns.barplot(x=\"Kernel\", y=\"Speedup\", hue=\"Model\", palette=palette, data=df)\n",
    "        plt.title(platform)\n",
    "\n",
    "        # y axis\n",
    "        plt.axhline(y=0, color=\"k\", lw=.5)\n",
    "        plt.ylim((-1, 1.5))\n",
    "        ax.set_yticklabels([\"{:.1f}x\".format(float(i) + 1.0) for i in ax.get_yticks()])  # negative offset\n",
    "        if i % 2:\n",
    "            plt.ylabel(\"\")  \n",
    "        else:\n",
    "            plt.ylabel(\"Speedup\")\n",
    "\n",
    "        # x axis\n",
    "        plt.setp(ax.get_xticklabels(), rotation=90)  # rotate x ticks\n",
    "        plt.xlabel(\"\")\n",
    "        plt.axvline(x=plt.xlim()[1] - 1, color=\"k\", lw=1, linestyle=\"--\")  # average line\n",
    "\n",
    "        # legend\n",
    "        ax.get_legend().set_title(\"\")\n",
    "        plt.legend(loc='upper left', ncol=1)    \n",
    "        ax.get_legend().draw_frame(True)\n",
    "\n",
    "    viz.finalise(figsize=(9, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geometric means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from labm8 import math as labmath\n",
    "\n",
    "magni_geomean = labmath.geomean(magni['Speedup'].values)\n",
    "deeptune_geomean = labmath.geomean(deeptune['Speedup'].values)\n",
    "deeptune_tl_geomean = labmath.geomean(deeptune_tl['Speedup'].values)\n",
    "\n",
    "print(f\"Geometric mean of Magni et al. {magni_geomean:.2f}x\")\n",
    "print(f\"Geometric mean of DeepTune {deeptune_geomean:.2f}x\")\n",
    "print(f\"Geometric mean of DeepTune-TL {deeptune_tl_geomean:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Influence of Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_platform_speedups = deeptune.groupby(\"Platform\").mean()[\"Speedup\"].iteritems()\n",
    "dt_tl_platform_speedups = deeptune_tl.groupby(\"Platform\").mean()[\"Speedup\"].iteritems()\n",
    "\n",
    "num_improvements = 0\n",
    "tl_speedups = []\n",
    "for (platform, speedup), (_, speedup_tl) in zip(dt_platform_speedups, dt_tl_platform_speedups):\n",
    "    if speedup_tl > speedup:\n",
    "        num_improvements += 1\n",
    "    tl_speedup = (speedup_tl / speedup) - 1\n",
    "    tl_speedups.append({\"Platform\": platform, \"TL-speedup\": tl_speedup})\n",
    "\n",
    "max_tl_speedup = max(tl_speedups, key=lambda x: x[\"TL-speedup\"])\n",
    "print(f\"Transfer Learning improved performance on {num_improvements} of the 4 platforms\")\n",
    "print(\"The greatest per-platform performance improvement was \"\n",
    "      f\"{max_tl_speedup['TL-speedup']:.1%} on {max_tl_speedup['Platform']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Comparison to State-of-the-art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeptune_speedup = deeptune[\"Speedup\"].mean()\n",
    "deeptune_tl_speedup = deeptune_tl[\"Speedup\"].mean()\n",
    "magni_speedup = magni[\"Speedup\"].mean()\n",
    "\n",
    "performance_improvement = (deeptune_speedup / magni_speedup) - 1\n",
    "performance_improvement_tl = (deeptune_tl_speedup / magni_speedup) - 1\n",
    "\n",
    "print(f\"DeepTune outperforms state-of-the-art by {performance_improvement:.0%}\")\n",
    "print(f\"DeepTune-TL outperforms state-of-the-art by {performance_improvement_tl:.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cases = len(deeptune_tl)\n",
    "num_better = sum(1 for d, m in zip(deeptune_tl[\"Speedup\"], magni[\"Speedup\"]) if d >= m)\n",
    "ratio_better = num_better / num_cases\n",
    "print(\"DeepTune-TL matched or improved performance of state-of-the-art in \"\n",
    "      f\"{num_better} of {num_cases} cases ({ratio_better:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of experiments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6 (default, Dec 19 2019, 23:49:42) \n[GCC 5.4.0 20160609]"
  },
  "vscode": {
   "interpreter": {
    "hash": "cbac100c1e935252d359d825fd3ac71dfe3b9a8ec214ef04a342f5b5ae0ac34d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
