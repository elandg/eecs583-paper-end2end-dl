{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCL Heterogeneous Mapping\n",
    "\n",
    "This notebook contains the experiments for Case Study A - using deep learning to predict the optimal device mapping for OpenCL kernels, without hand engineered features.\n",
    "\n",
    "## 1. Runtime Data\n",
    "\n",
    "We use the runtime data from our CGO'17 paper [1]. The code to reproduce those experiments can be found in this, artifact evaluated [GitHub repository](https://github.com/ChrisCummins/paper-synthesizing-benchmarks).\n",
    "\n",
    "> [1] Cummins, C., Petoumenos, P., Zang, W., & Leather, H. (2017). [Synthesizing Benchmarks for Predictive Modeling](http://chriscummins.cc/pub/2017-cgo.pdf). In CGO. IEEE.\n",
    "\n",
    "The runtime data comes from two plaforms. AMD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>dataset</th>\n",
       "      <th>comp</th>\n",
       "      <th>rational</th>\n",
       "      <th>mem</th>\n",
       "      <th>localmem</th>\n",
       "      <th>coalesced</th>\n",
       "      <th>atomic</th>\n",
       "      <th>transfer</th>\n",
       "      <th>wgsize</th>\n",
       "      <th>oracle</th>\n",
       "      <th>runtime_cpu</th>\n",
       "      <th>runtime_gpu</th>\n",
       "      <th>src</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>amd-app-sdk-3.0-BinomialOption-binomial_options</td>\n",
       "      <td>default</td>\n",
       "      <td>98</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2048</td>\n",
       "      <td>255</td>\n",
       "      <td>GPU</td>\n",
       "      <td>3.291073</td>\n",
       "      <td>1.443983</td>\n",
       "      <td>__kernel void A(int a, const __global float4* ...</td>\n",
       "      <td>[129 129 129 ...,   0 127   0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>amd-app-sdk-3.0-BitonicSort-bitonicSort</td>\n",
       "      <td>default</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>131072</td>\n",
       "      <td>256</td>\n",
       "      <td>CPU</td>\n",
       "      <td>0.121940</td>\n",
       "      <td>0.279521</td>\n",
       "      <td>__kernel void A(__global uint* a, const uint b...</td>\n",
       "      <td>[129 129 129 ...,   0 127   0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>678</td>\n",
       "      <td>shoc-1.1.5-Stencil2D-StencilKernel</td>\n",
       "      <td>default</td>\n",
       "      <td>144</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>71647488</td>\n",
       "      <td>256</td>\n",
       "      <td>GPU</td>\n",
       "      <td>17.866730</td>\n",
       "      <td>16.666380</td>\n",
       "      <td>__kernel void A(__global float* a, __global fl...</td>\n",
       "      <td>[  1  96   1 ..., 127   0 127]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>679</td>\n",
       "      <td>shoc-1.1.5-Triad-Triad</td>\n",
       "      <td>default</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>117440512</td>\n",
       "      <td>128</td>\n",
       "      <td>CPU</td>\n",
       "      <td>876.457180</td>\n",
       "      <td>968.494606</td>\n",
       "      <td>__kernel void A(__global const float* a, __glo...</td>\n",
       "      <td>[129 129 129 ...,   0 127   0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>680 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                        benchmark  dataset  \\\n",
       "0             0  amd-app-sdk-3.0-BinomialOption-binomial_options  default   \n",
       "1             1          amd-app-sdk-3.0-BitonicSort-bitonicSort  default   \n",
       "..          ...                                              ...      ...   \n",
       "678         678               shoc-1.1.5-Stencil2D-StencilKernel  default   \n",
       "679         679                           shoc-1.1.5-Triad-Triad  default   \n",
       "\n",
       "     comp  rational  mem  localmem  coalesced  atomic   transfer  wgsize  \\\n",
       "0      98         8   13        11          2       0       2048     255   \n",
       "1      12         2    6         0          6       0     131072     256   \n",
       "..    ...       ...  ...       ...        ...     ...        ...     ...   \n",
       "678   144         7   16        12          3       0   71647488     256   \n",
       "679     2         0    3         0          3       0  117440512     128   \n",
       "\n",
       "    oracle  runtime_cpu  runtime_gpu  \\\n",
       "0      GPU     3.291073     1.443983   \n",
       "1      CPU     0.121940     0.279521   \n",
       "..     ...          ...          ...   \n",
       "678    GPU    17.866730    16.666380   \n",
       "679    CPU   876.457180   968.494606   \n",
       "\n",
       "                                                   src  \\\n",
       "0    __kernel void A(int a, const __global float4* ...   \n",
       "1    __kernel void A(__global uint* a, const uint b...   \n",
       "..                                                 ...   \n",
       "678  __kernel void A(__global float* a, __global fl...   \n",
       "679  __kernel void A(__global const float* a, __glo...   \n",
       "\n",
       "                                seq  \n",
       "0    [129 129 129 ...,   0 127   0]  \n",
       "1    [129 129 129 ...,   0 127   0]  \n",
       "..                              ...  \n",
       "678  [  1  96   1 ..., 127   0 127]  \n",
       "679  [129 129 129 ...,   0 127   0]  \n",
       "\n",
       "[680 rows x 16 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 5)\n",
    "\n",
    "pd.read_csv(\"../data/case-study-a/cgo17-amd.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and NVIDIA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>dataset</th>\n",
       "      <th>comp</th>\n",
       "      <th>rational</th>\n",
       "      <th>mem</th>\n",
       "      <th>localmem</th>\n",
       "      <th>coalesced</th>\n",
       "      <th>atomic</th>\n",
       "      <th>transfer</th>\n",
       "      <th>wgsize</th>\n",
       "      <th>oracle</th>\n",
       "      <th>runtime_cpu</th>\n",
       "      <th>runtime_gpu</th>\n",
       "      <th>src</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>amd-app-sdk-3.0-BinomialOption-binomial_options</td>\n",
       "      <td>default</td>\n",
       "      <td>98</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2048</td>\n",
       "      <td>255</td>\n",
       "      <td>GPU</td>\n",
       "      <td>3.291073</td>\n",
       "      <td>0.152038</td>\n",
       "      <td>__kernel void A(int a, const __global float4* ...</td>\n",
       "      <td>[129 129 129 ...,   0 127   0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>amd-app-sdk-3.0-BitonicSort-bitonicSort</td>\n",
       "      <td>default</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>131072</td>\n",
       "      <td>256</td>\n",
       "      <td>GPU</td>\n",
       "      <td>0.121940</td>\n",
       "      <td>0.057834</td>\n",
       "      <td>__kernel void A(__global uint* a, const uint b...</td>\n",
       "      <td>[129 129 129 ...,   0 127   0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>678</td>\n",
       "      <td>shoc-1.1.5-Stencil2D-StencilKernel</td>\n",
       "      <td>default</td>\n",
       "      <td>144</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>71647488</td>\n",
       "      <td>256</td>\n",
       "      <td>CPU</td>\n",
       "      <td>17.866730</td>\n",
       "      <td>48.047807</td>\n",
       "      <td>__kernel void A(__global float* a, __global fl...</td>\n",
       "      <td>[  1  96   1 ..., 127   0 127]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>679</td>\n",
       "      <td>shoc-1.1.5-Triad-Triad</td>\n",
       "      <td>default</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>117440512</td>\n",
       "      <td>128</td>\n",
       "      <td>CPU</td>\n",
       "      <td>876.457180</td>\n",
       "      <td>3184.516221</td>\n",
       "      <td>__kernel void A(__global const float* a, __glo...</td>\n",
       "      <td>[129 129 129 ...,   0 127   0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>680 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                        benchmark  dataset  \\\n",
       "0             0  amd-app-sdk-3.0-BinomialOption-binomial_options  default   \n",
       "1             1          amd-app-sdk-3.0-BitonicSort-bitonicSort  default   \n",
       "..          ...                                              ...      ...   \n",
       "678         678               shoc-1.1.5-Stencil2D-StencilKernel  default   \n",
       "679         679                           shoc-1.1.5-Triad-Triad  default   \n",
       "\n",
       "     comp  rational  mem  localmem  coalesced  atomic   transfer  wgsize  \\\n",
       "0      98         8   13        11          2       0       2048     255   \n",
       "1      12         2    6         0          6       0     131072     256   \n",
       "..    ...       ...  ...       ...        ...     ...        ...     ...   \n",
       "678   144         7   16        12          3       0   71647488     256   \n",
       "679     2         0    3         0          3       0  117440512     128   \n",
       "\n",
       "    oracle  runtime_cpu  runtime_gpu  \\\n",
       "0      GPU     3.291073     0.152038   \n",
       "1      GPU     0.121940     0.057834   \n",
       "..     ...          ...          ...   \n",
       "678    CPU    17.866730    48.047807   \n",
       "679    CPU   876.457180  3184.516221   \n",
       "\n",
       "                                                   src  \\\n",
       "0    __kernel void A(int a, const __global float4* ...   \n",
       "1    __kernel void A(__global uint* a, const uint b...   \n",
       "..                                                 ...   \n",
       "678  __kernel void A(__global float* a, __global fl...   \n",
       "679  __kernel void A(__global const float* a, __glo...   \n",
       "\n",
       "                                seq  \n",
       "0    [129 129 129 ...,   0 127   0]  \n",
       "1    [129 129 129 ...,   0 127   0]  \n",
       "..                              ...  \n",
       "678  [  1  96   1 ..., 127   0 127]  \n",
       "679  [129 129 129 ...,   0 127   0]  \n",
       "\n",
       "[680 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../data/case-study-a/cgo17-nvidia.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predictive Models\n",
    "\n",
    "We define a base class for implementing predictive models for heterogeneous mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from clgen import _atomizer as clgen\n",
    "\n",
    "class HeterogemeousMappingModel(object):\n",
    "    \"\"\"\n",
    "    A model for predicting OpenCL heterogeneous device mappings.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    __name__ : str\n",
    "        Model name\n",
    "    __basename__ : str\n",
    "        Shortened name, used for files\n",
    "    \"\"\"\n",
    "    __name__ = None\n",
    "    __basename__ = None\n",
    "    \n",
    "    def init(self, seed: int) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the model.\n",
    "        \n",
    "        Do whatever is required to setup a new heterogeneous model here.\n",
    "        This method is called prior to training and predicting.\n",
    "        This method may be omitted if no initial setup is required.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        seed : int\n",
    "            The seed value used to reproducible results. May be 'None',\n",
    "            indicating that no seed is to be used.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def save(self, outpath: str) -> None:\n",
    "        \"\"\"\n",
    "        Save model state.\n",
    "        \n",
    "        This must capture all of the relevant state of the model. It is up\n",
    "        to implementing classes to determine how best to save the model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        outpath : str\n",
    "            The path to save the model state to.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def restore(self, inpath: str) -> None:\n",
    "        \"\"\"\n",
    "        Load a trained model from file.\n",
    "        \n",
    "        This is called in place of init() if a saved model file exists. It\n",
    "        must restore all of the required model state.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        inpath : str\n",
    "            The path to load the model from. This is the same path as\n",
    "            was passed to save() to create the file.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def train(self, df: pd.DataFrame, features: np.array, sequences: np.array,\n",
    "              y: np.array, y_1hot: np.array, verbose: bool=False) -> None:\n",
    "        \"\"\"\n",
    "        Train a model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            The platform dataframe.\n",
    "        \n",
    "        features : np.array\n",
    "            An array of feature vectors of shape (n,4).\n",
    "        \n",
    "        sequences : np.array\n",
    "            An array of encoded source code sequences of shape (n,seq_length).\n",
    "\n",
    "        y : np.array\n",
    "            An array of optimal device mappings of shape (n,1).\n",
    "        \n",
    "        y_1hot : np.array\n",
    "            An array of optimal device mappings of shape (n,2), in 1-hot encoding.\n",
    "            \n",
    "        verbose: bool, optional\n",
    "            Whether to print verbose status messages during training.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self, features: np.array, sequences: np.array, y: np.array,\n",
    "                y_1hot: np.array, verbose: bool=False) -> np.array:\n",
    "        \"\"\"\n",
    "        Make predictions for programs.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        features : np.array\n",
    "            An array of feature vectors of shape (n,4).\n",
    "        \n",
    "        sequences : np.array\n",
    "            An array of encoded source code sequences of shape (n,seq_length).\n",
    "\n",
    "        y : np.array\n",
    "            An array of optimal device mappings of shape (n,1).\n",
    "        \n",
    "        y_1hot : np.array\n",
    "            An array of optimal device mappings of shape (n,2), in 1-hot encoding.\n",
    "            \n",
    "        verbose: bool, optional\n",
    "            Whether to print verbose status messages.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        np.array\n",
    "            Predicted 'y' values (optimal device mappings) with shape (n,1).\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define some utility code which we will use later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def platform2str(platform: str) -> str:\n",
    "    \"\"\" get full platform name \"\"\"\n",
    "    if platform == \"amd\":\n",
    "        return \"AMD Tahiti 7970\"\n",
    "    elif platform == \"nvidia\":\n",
    "        return \"NVIDIA GTX 970\"\n",
    "    else:\n",
    "        raise LookupException\n",
    "        \n",
    "def escape_suite_name(g: str) -> str:\n",
    "    \"\"\" format benchmark suite name for display \"\"\"\n",
    "    c = g.split('-')\n",
    "    if c[0] == \"amd\" or c[0] == \"nvidia\":\n",
    "        return c[0].upper() + \" SDK\"\n",
    "    if c[0] == \"npb\" or c[0] == \"shoc\":\n",
    "        return c[0].upper()\n",
    "    elif c[0] == \"parboil\" or c[0] == \"polybench\" or c[0] == \"rodinia\":\n",
    "        return c[0].capitalize()\n",
    "    else:\n",
    "        raise LookupError\n",
    "\n",
    "\n",
    "def escape_benchmark_name(g: str) -> str:\n",
    "    \"\"\"escape benchmark name for display\"\"\"\n",
    "    c = g.split('-')\n",
    "    return escape_suite_name(c[0]).split()[0] + \".\" + c[-2]\n",
    "\n",
    "    \n",
    "def grewe_features(df: pd.DataFrame) -> np.array:\n",
    "    \"\"\" extract Grewe et al. feature vector from runtime data \"\"\"\n",
    "    return np.array([\n",
    "            (df[\"transfer\"].values / (df[\"comp\"].values + df[\"mem\"].values)),  # F1\n",
    "            (df[\"coalesced\"].values / df[\"mem\"].values),  # F2\n",
    "            ((df[\"localmem\"].values / df[\"mem\"].values) * df[\"wgsize\"].values),  # F3\n",
    "            (df[\"comp\"].values / df[\"mem\"].values),  # F4\n",
    "        ]).T\n",
    "\n",
    "def auxiliary_inputs(df: pd.DataFrame) -> np.array:\n",
    "    \"\"\" get dsize and wgsize auxiliary inputs \"\"\"\n",
    "    return np.array([\n",
    "        df[\"transfer\"].values,\n",
    "        df[\"wgsize\"].values,\n",
    "    ]).T\n",
    "\n",
    "def encode_1hot(y: np.array) -> np.array:\n",
    "    \"\"\" 1-hot encode labels \"\"\"\n",
    "    labels = np.vstack([np.expand_dims(x, axis=0) for x in y])\n",
    "    l2 = [x[0] for x in labels]\n",
    "    l1 = [not x for x in l2]\n",
    "    return np.array(list(zip(l1, l2)), dtype=np.int32)\n",
    "\n",
    "def encode_srcs(srcs: List[str]) -> np.array:\n",
    "    \"\"\" encode and pad source code for learning \"\"\"\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "    \n",
    "    seqs = [atomizer.atomize(src) for src in srcs]\n",
    "    pad_val = atomizer.vocab_size\n",
    "    encoded = np.array(pad_sequences(seqs, maxlen=1024, value=pad_val))\n",
    "    return np.vstack([np.expand_dims(x, axis=0) for x in encoded])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experimental Methodology\n",
    "\n",
    "Random seed for reproducible results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 204"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source encoder (see the *'Language Model.ipynb'* notebook for details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GreedyAtomizer[101 tokens]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from clgen import Language\n",
    "\n",
    "srcs = '\\n'.join(pd.read_csv(\"../data/case-study-a/cgo17-amd.csv\")['src'].values)\n",
    "atomizer = clgen.GreedyAtomizer.from_text(lang=Language.from_str(\"opencl\"), text=srcs)\n",
    "atomizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our method to evaluate a predictive model using 10-fold cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from labm8 import fs\n",
    "\n",
    "def evaluate(model: HeterogemeousMappingModel) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluate a model.\n",
    "    \n",
    "    Performs 10-fold cross-validation of the model's effectiveness at predicting\n",
    "    OpenCL device mappings. Results are cached.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : HeterogeneousMappingModel\n",
    "        The predictive model to evaluate.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.Dataframe\n",
    "        Evaluation results.\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from progressbar import ProgressBar\n",
    "    \n",
    "    progressbar = [0, ProgressBar(max_value=10*2)]\n",
    "\n",
    "    data = []\n",
    "    for i, platform in enumerate([\"amd\", \"nvidia\"]):\n",
    "        platform_name = platform2str(platform)\n",
    "\n",
    "        # load runtime data\n",
    "        df = pd.read_csv(f\"../data/case-study-a/cgo17-{platform}.csv\")\n",
    "        \n",
    "        sequences = None  # defer sequence encoding until needed (it's expensive)\n",
    "        \n",
    "        # values used for training & predictions\n",
    "        features = grewe_features(df)\n",
    "        aux_in = auxiliary_inputs(df)\n",
    "        \n",
    "        # optimal mappings\n",
    "        y = np.array([1 if x == \"GPU\" else 0 for x in df[\"oracle\"].values])\n",
    "        y_1hot = encode_1hot(y)\n",
    "        \n",
    "        # 10-fold cross-validation\n",
    "        # kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        # for j, (train_index, test_index) in enumerate(kf.split(features, y)):\n",
    "        indices = np.arange(len(features))\n",
    "        train_index, test_index = train_test_split(indices, shuffle=True, random_state=seed, test_size=0.25)\n",
    "\n",
    "        model_path = f\"../data/case-study-a/models/{model.__basename__}-{platform}-cnn-non-kfold.model\"\n",
    "        predictions_path = f\"../data/case-study-a/predictions/{model.__basename__}-{platform}-cnn-non-kfold.result\"\n",
    "        \n",
    "        if fs.exists(predictions_path):\n",
    "            # load result from cache\n",
    "            with open(predictions_path, 'rb') as infile:\n",
    "                p = pickle.load(infile)\n",
    "        else:\n",
    "            if sequences is None:  # encode source codes if needed\n",
    "                sequences = encode_srcs(df[\"src\"].values)\n",
    "\n",
    "            if fs.exists(model_path):\n",
    "                # restore trained model from cache\n",
    "                model.restore(model_path)\n",
    "            else:\n",
    "                # train and cache a model\n",
    "                model.init(seed=seed)                   \n",
    "                model.train(df=df,\n",
    "                            features=features[train_index],\n",
    "                            aux_in=aux_in[train_index],\n",
    "                            sequences=sequences[train_index],\n",
    "                            y=y[train_index],\n",
    "                            y_1hot=y_1hot[train_index],\n",
    "                            verbose=True)\n",
    "                fs.mkdir(fs.dirname(model_path))\n",
    "                model.save(model_path)\n",
    "\n",
    "            # test model\n",
    "            p = model.predict(\n",
    "                features=features[test_index],\n",
    "                aux_in=aux_in[test_index],\n",
    "                sequences=sequences[test_index],\n",
    "                y=y[test_index],\n",
    "                y_1hot=y_1hot[test_index],\n",
    "                verbose=True)\n",
    "\n",
    "        # cache results\n",
    "        fs.mkdir(fs.dirname(predictions_path))\n",
    "        with open(predictions_path, 'wb') as outfile:\n",
    "            pickle.dump(p, outfile)\n",
    "\n",
    "        # benchmarks\n",
    "        benchmarks = df['benchmark'].values[test_index]\n",
    "        # oracle device mappings\n",
    "        o = y[test_index]\n",
    "        # whether predictions were correct or not\n",
    "        correct = p == o\n",
    "        # runtimes of baseline mapping (CPU on AMD, GPU on NVIDIA)\n",
    "        zero_r_dev = \"runtime_cpu\" if platform == \"amd\" else \"runtime_gpu\"\n",
    "        zer_r_runtimes = df[zero_r_dev][test_index]\n",
    "        # speedups of predictions\n",
    "        runtimes = df[['runtime_cpu', 'runtime_gpu']].values[test_index]\n",
    "        p_runtimes = [r[p_] for p_, r in zip(p, runtimes)]\n",
    "        p_speedup = zer_r_runtimes / p_runtimes\n",
    "\n",
    "        # sanity check\n",
    "        assert(len(benchmarks) == len(o) == len(correct) == len(p) == len(p_speedup))\n",
    "\n",
    "        # record results\n",
    "        for benchmark_, o_, p_, correct_, p_speedup_ in zip(benchmarks, o, p, correct, p_speedup):\n",
    "            data.append({\n",
    "                \"Model\": model.__name__,\n",
    "                \"Platform\": platform_name,\n",
    "                'Benchmark': escape_benchmark_name(benchmark_),\n",
    "                'Benchmark Suite': escape_suite_name(benchmark_),\n",
    "                \"Oracle Mapping\": o_,\n",
    "                \"Predicted Mapping\": p_,\n",
    "                \"Correct?\": correct_,\n",
    "                \"Speedup\": p_speedup_,\n",
    "            })\n",
    "        \n",
    "        # update progress bar\n",
    "        progressbar[0] += 1\n",
    "        progressbar[1].update(progressbar[0])\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        data, index=range(1, len(data)+1), columns=[\n",
    "            \"Model\",\n",
    "            \"Platform\",\n",
    "            \"Benchmark\",\n",
    "            \"Benchmark Suite\", \n",
    "            \"Oracle Mapping\", \n",
    "            \"Predicted Mapping\", \n",
    "            \"Correct?\", \n",
    "            \"Speedup\"\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Static Mapping\n",
    "\n",
    "A static mapping selects the device which is most frequently optimal for that platform, i.e. it is the upper bound of performance which can be achieved without a heuristic. We use this as a baseline to compare predictive models against:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class StaticMapping(HeterogemeousMappingModel):\n",
    "    __name__ = \"Static mapping\"\n",
    "    __basename__ = \"static\"\n",
    "    \n",
    "    def init(self, seed: int): return self\n",
    "    \n",
    "    def save(self, outpath):\n",
    "        with open(outpath, \"wb\") as outfile:\n",
    "            pickle.dump(self.model, outfile)\n",
    "\n",
    "    def restore(self, inpath):\n",
    "        with open(inpath, \"rb\") as infile:\n",
    "            self.model = pickle.load(infile)\n",
    "\n",
    "    def train(self, df=None, **train):\n",
    "        from collections import Counter\n",
    "        \n",
    "        # select the Zero-R device: the most frequently optimal device\n",
    "        zero_r_device = Counter(df['oracle']).most_common(1)[0][0]\n",
    "        self.model = 1 if zero_r_device == \"GPU\" else 0\n",
    "\n",
    "    def predict(self, **test):\n",
    "        if self.model:\n",
    "            return np.ones(len(test[\"y\"])).astype(np.int32)\n",
    "        else:\n",
    "            return np.zeros(len(test[\"y\"])).astype(dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating static mapping ...\n",
      "Using TensorFlow backend.\n",
      " 10% (2 of 20) |##                       | Elapsed Time: 0:00:01 ETA:   0:00:14/mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Correct?</th>\n",
       "      <th>Speedup</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platform</th>\n",
       "      <th>Benchmark Suite</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">AMD Tahiti 7970</th>\n",
       "      <th>AMD SDK</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPB</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVIDIA SDK</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parboil</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polybench</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rodinia</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHOC</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">NVIDIA GTX 970</th>\n",
       "      <th>AMD SDK</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPB</th>\n",
       "      <td>0.613636</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVIDIA SDK</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parboil</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polybench</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rodinia</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHOC</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Correct?  Speedup\n",
       "Platform        Benchmark Suite                   \n",
       "AMD Tahiti 7970 AMD SDK          0.428571      1.0\n",
       "                NPB              0.583333      1.0\n",
       "                NVIDIA SDK       0.250000      1.0\n",
       "                Parboil          0.333333      1.0\n",
       "                Polybench        0.000000      1.0\n",
       "                Rodinia          0.714286      1.0\n",
       "                SHOC             0.666667      1.0\n",
       "NVIDIA GTX 970  AMD SDK          1.000000      1.0\n",
       "                NPB              0.613636      1.0\n",
       "                NVIDIA SDK       0.750000      1.0\n",
       "                Parboil          0.500000      1.0\n",
       "                Polybench        0.600000      1.0\n",
       "                Rodinia          0.285714      1.0\n",
       "                SHOC             0.111111      1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "pd.set_option('display.max_rows', 14)\n",
    "\n",
    "print(\"Evaluating static mapping ...\", file=sys.stderr)\n",
    "baseline = evaluate(StaticMapping())\n",
    "baseline.groupby(['Platform', 'Benchmark Suite'])['Platform', 'Correct?', 'Speedup'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of results. The *Correct?* column shows model accuracy. In the paper we report that the static mapping is accurate for **58.8%** of cases on AMD and **56.9%** of cases on NVIDIA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct?</th>\n",
       "      <th>Speedup</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platform</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AMD Tahiti 7970</th>\n",
       "      <td>0.552941</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVIDIA GTX 970</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Correct?  Speedup\n",
       "Platform                          \n",
       "AMD Tahiti 7970  0.552941      1.0\n",
       "NVIDIA GTX 970   0.588235      1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.groupby(['Platform'])['Platform', 'Correct?', 'Speedup'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Grewe et al. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Grewe et al. predictive model uses decision trees and hand engineered features to predict optimal device mapping, described in publication:\n",
    "\n",
    "> [2] Grewe, D., Wang, Z., & O’Boyle, M. (2013). [Portable Mapping of Data Parallel Programs to OpenCL for Heterogeneous Systems](http://www.ece.neu.edu/groups/nucar/NUCARTALKS/cgo2013-grewe.pdf). In CGO. IEEE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Grewe(HeterogemeousMappingModel):\n",
    "    __name__ = \"Grewe et al.\"\n",
    "    __basename__ = \"grewe\"\n",
    "    \n",
    "    def init(self, seed: int):\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "        self.model = DecisionTreeClassifier(\n",
    "            random_state=seed, splitter=\"best\",\n",
    "            criterion=\"entropy\", max_depth=5,\n",
    "            min_samples_leaf=5)\n",
    "        return self\n",
    "    \n",
    "    def save(self, outpath):\n",
    "        with open(outpath, \"wb\") as outfile:\n",
    "            pickle.dump(self.model, outfile)\n",
    "\n",
    "    def restore(self, inpath):\n",
    "        with open(inpath, \"rb\") as infile:\n",
    "            self.model = pickle.load(infile)\n",
    "        \n",
    "    def train(self, **train):\n",
    "        self.model.fit(train[\"features\"], train[\"y\"])\n",
    "\n",
    "    def predict(self, **test):\n",
    "        return self.model.predict(test[\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Grewe et al. ...\n",
      " 10% (2 of 20) |##                       | Elapsed Time: 0:00:01 ETA:   0:00:13/mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Correct?</th>\n",
       "      <th>Speedup</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platform</th>\n",
       "      <th>Benchmark Suite</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">AMD Tahiti 7970</th>\n",
       "      <th>AMD SDK</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.212337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPB</th>\n",
       "      <td>0.704545</td>\n",
       "      <td>3.191840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVIDIA SDK</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.993184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parboil</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.449144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polybench</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.616568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rodinia</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.965156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHOC</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.969719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">NVIDIA GTX 970</th>\n",
       "      <th>AMD SDK</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.633872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPB</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.355666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVIDIA SDK</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.573624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parboil</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.869863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polybench</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.832637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rodinia</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.124338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHOC</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.933681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Correct?    Speedup\n",
       "Platform        Benchmark Suite                     \n",
       "AMD Tahiti 7970 AMD SDK          0.857143   1.212337\n",
       "                NPB              0.704545   3.191840\n",
       "                NVIDIA SDK       0.500000   1.993184\n",
       "                Parboil          1.000000  16.449144\n",
       "                Polybench        0.800000   1.616568\n",
       "                Rodinia          0.571429   0.965156\n",
       "                SHOC             0.666667   0.969719\n",
       "NVIDIA GTX 970  AMD SDK          0.285714   0.633872\n",
       "                NPB              0.818182   1.355666\n",
       "                NVIDIA SDK       0.250000   0.573624\n",
       "                Parboil          0.333333   0.869863\n",
       "                Polybench        0.600000   0.832637\n",
       "                Rodinia          0.571429   1.124338\n",
       "                SHOC             0.777778   1.933681"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Evaluating Grewe et al. ...\", file=sys.stderr)\n",
    "grewe = evaluate(Grewe())\n",
    "grewe.groupby(['Platform', 'Benchmark Suite'])['Platform', 'Correct?', 'Speedup'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of results. The *Correct?* column shows model accuracy. In the paper we report that the Grewe et al. model is accurate **73%** of cases, achieving speedups of **2.91$\\times$** on AMD and **1.26$\\times$** on NVIDIA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct?</th>\n",
       "      <th>Speedup</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platform</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AMD Tahiti 7970</th>\n",
       "      <td>0.711765</td>\n",
       "      <td>3.294372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVIDIA GTX 970</th>\n",
       "      <td>0.747059</td>\n",
       "      <td>1.296091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Correct?   Speedup\n",
       "Platform                           \n",
       "AMD Tahiti 7970  0.711765  3.294372\n",
       "NVIDIA GTX 970   0.747059  1.296091"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grewe.groupby(['Platform'])['Platform', 'Correct?', 'Speedup'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. DeepTune\n",
    "\n",
    "We predict optimal device mapping from raw source code inputs, and the\n",
    "two auxiliary inputs wgsize and dsize (which cannot be obtained statically\n",
    "from the program source):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DeepTune(HeterogemeousMappingModel):\n",
    "    __name__ = \"DeepTune\"\n",
    "    __basename__ = \"deeptune\"\n",
    "    \n",
    "    def init(self, seed: int):\n",
    "        from keras.layers import Input, Embedding, LSTM, Dense, Conv1D, GlobalMaxPooling1D\n",
    "        from keras.layers.merge import Concatenate\n",
    "        from keras.layers.normalization import BatchNormalization\n",
    "        from keras.models import Model\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        # Language model. Takes as inputs source code sequences.\n",
    "        code_in = Input(shape=(1024,), dtype=\"int32\", name=\"code_in\")\n",
    "        x = Embedding(input_dim=atomizer.vocab_size + 1, input_length=1024, \n",
    "                      output_dim=64, name=\"embedding\")(code_in)\n",
    "        # x = LSTM(64, implementation=1, return_sequences=True, name=\"lstm_1\")(x)\n",
    "        # x = LSTM(64, implementation=1, name=\"lstm_2\")(x)\n",
    "        x = Conv1D(32, 9, name=\"conv_1\")(x)\n",
    "        x = Conv1D(32, 9, name=\"conv_2\")(x)\n",
    "        x = GlobalMaxPooling1D()(x)\n",
    "        print(x.shape)\n",
    "        langmodel_out = Dense(2, activation=\"sigmoid\")(x)\n",
    "        \n",
    "        # Auxiliary inputs. wgsize and dsize.\n",
    "        auxiliary_inputs = Input(shape=(2,))\n",
    "        \n",
    "        # Heuristic model. Takes as inputs the language model,\n",
    "        #   outputs 1-hot encoded device mapping\n",
    "        x = Concatenate()([auxiliary_inputs, x])\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dense(32, activation=\"relu\")(x)\n",
    "        out = Dense(2, activation=\"sigmoid\")(x)\n",
    "\n",
    "        self.model = Model(inputs=[auxiliary_inputs, code_in], outputs=[out, langmodel_out])\n",
    "        self.model.compile(\n",
    "            optimizer=\"adam\", metrics=['accuracy'],\n",
    "            loss=[\"categorical_crossentropy\", \"categorical_crossentropy\"],\n",
    "            loss_weights=[1., .2])\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def save(self, outpath):\n",
    "        self.model.save(outpath)\n",
    "\n",
    "    def restore(self, inpath):\n",
    "        from keras.models import load_model\n",
    "        self.model = load_model(inpath)\n",
    "        \n",
    "    def train(self, **train):\n",
    "        self.model.fit([train[\"aux_in\"], train[\"sequences\"]], [train[\"y_1hot\"], train[\"y_1hot\"]],\n",
    "                       epochs=50, batch_size=64, verbose=train[\"verbose\"], shuffle=True)\n",
    "\n",
    "    def predict(self, **test):\n",
    "        p = np.array(self.model.predict(\n",
    "            [test[\"aux_in\"], test[\"sequences\"]], batch_size=64, verbose=test[\"verbose\"]))\n",
    "        indices = [np.argmax(x) for x in p[0]]\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview of the DeepTune model, showing the number of parameters in each layer, used to construct Table 5 in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:492: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3630: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:63: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1208: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "(?, 32)\n",
      "WARNING:tensorflow:From /mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2880: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2884: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "code_in (InputLayer)            (None, 1024)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1024, 64)     6528        code_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv1D)                 (None, 1016, 32)     18464       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv1D)                 (None, 1008, 32)     9248        conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 32)           0           conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 34)           0           input_1[0][0]                    \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 34)           136         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           1120        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            66          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            66          global_max_pooling1d_1[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 35,628\n",
      "Trainable params: 35,560\n",
      "Non-trainable params: 68\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deeptune_model = DeepTune()\n",
    "deeptune_model.init(seed)\n",
    "deeptune_model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<svg height=\"719pt\" viewBox=\"0.00 0.00 956.00 719.00\" width=\"956pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 715)\">\n<title>G</title>\n<polygon fill=\"white\" points=\"-4,4 -4,-715 952,-715 952,4 -4,4\" stroke=\"none\"/>\n<!-- 140463751560848 -->\n<g class=\"node\" id=\"node1\"><title>140463751560848</title>\n<polygon fill=\"none\" points=\"500.5,-664.5 500.5,-710.5 839.5,-710.5 839.5,-664.5 500.5,-664.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"581\" y=\"-683.8\">code_in: InputLayer</text>\n<polyline fill=\"none\" points=\"661.5,-664.5 661.5,-710.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"695.5\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"661.5,-687.5 729.5,-687.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"695.5\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"729.5,-664.5 729.5,-710.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"784.5\" y=\"-695.3\">(None, 1024)</text>\n<polyline fill=\"none\" points=\"729.5,-687.5 839.5,-687.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"784.5\" y=\"-672.3\">(None, 1024)</text>\n</g>\n<!-- 140462003093456 -->\n<g class=\"node\" id=\"node2\"><title>140462003093456</title>\n<polygon fill=\"none\" points=\"474,-581.5 474,-627.5 866,-627.5 866,-581.5 474,-581.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"567.5\" y=\"-600.8\">embedding: Embedding</text>\n<polyline fill=\"none\" points=\"661,-581.5 661,-627.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"695\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"661,-604.5 729,-604.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"695\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"729,-581.5 729,-627.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"797.5\" y=\"-612.3\">(None, 1024)</text>\n<polyline fill=\"none\" points=\"729,-604.5 866,-604.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"797.5\" y=\"-589.3\">(None, 1024, 64)</text>\n</g>\n<!-- 140463751560848&#45;&gt;140462003093456 -->\n<g class=\"edge\" id=\"edge1\"><title>140463751560848-&gt;140462003093456</title>\n<path d=\"M670,-664.366C670,-656.152 670,-646.658 670,-637.725\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"673.5,-637.607 670,-627.607 666.5,-637.607 673.5,-637.607\" stroke=\"black\"/>\n</g>\n<!-- 140462002920848 -->\n<g class=\"node\" id=\"node3\"><title>140462002920848</title>\n<polygon fill=\"none\" points=\"501,-498.5 501,-544.5 839,-544.5 839,-498.5 501,-498.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"567.5\" y=\"-517.8\">conv_1: Conv1D</text>\n<polyline fill=\"none\" points=\"634,-498.5 634,-544.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"668\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"634,-521.5 702,-521.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"668\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"702,-498.5 702,-544.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"770.5\" y=\"-529.3\">(None, 1024, 64)</text>\n<polyline fill=\"none\" points=\"702,-521.5 839,-521.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"770.5\" y=\"-506.3\">(None, 1016, 32)</text>\n</g>\n<!-- 140462003093456&#45;&gt;140462002920848 -->\n<g class=\"edge\" id=\"edge2\"><title>140462003093456-&gt;140462002920848</title>\n<path d=\"M670,-581.366C670,-573.152 670,-563.658 670,-554.725\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"673.5,-554.607 670,-544.607 666.5,-554.607 673.5,-554.607\" stroke=\"black\"/>\n</g>\n<!-- 140461990949008 -->\n<g class=\"node\" id=\"node4\"><title>140461990949008</title>\n<polygon fill=\"none\" points=\"501,-415.5 501,-461.5 839,-461.5 839,-415.5 501,-415.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"567.5\" y=\"-434.8\">conv_2: Conv1D</text>\n<polyline fill=\"none\" points=\"634,-415.5 634,-461.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"668\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"634,-438.5 702,-438.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"668\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"702,-415.5 702,-461.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"770.5\" y=\"-446.3\">(None, 1016, 32)</text>\n<polyline fill=\"none\" points=\"702,-438.5 839,-438.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"770.5\" y=\"-423.3\">(None, 1008, 32)</text>\n</g>\n<!-- 140462002920848&#45;&gt;140461990949008 -->\n<g class=\"edge\" id=\"edge3\"><title>140462002920848-&gt;140461990949008</title>\n<path d=\"M670,-498.366C670,-490.152 670,-480.658 670,-471.725\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"673.5,-471.607 670,-461.607 666.5,-471.607 673.5,-471.607\" stroke=\"black\"/>\n</g>\n<!-- 140461983432464 -->\n<g class=\"node\" id=\"node6\"><title>140461983432464</title>\n<polygon fill=\"none\" points=\"392,-332.5 392,-378.5 948,-378.5 948,-332.5 392,-332.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"567.5\" y=\"-351.8\">global_max_pooling1d_1: GlobalMaxPooling1D</text>\n<polyline fill=\"none\" points=\"743,-332.5 743,-378.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"777\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"743,-355.5 811,-355.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"777\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"811,-332.5 811,-378.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"879.5\" y=\"-363.3\">(None, 1008, 32)</text>\n<polyline fill=\"none\" points=\"811,-355.5 948,-355.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"879.5\" y=\"-340.3\">(None, 32)</text>\n</g>\n<!-- 140461990949008&#45;&gt;140461983432464 -->\n<g class=\"edge\" id=\"edge4\"><title>140461990949008-&gt;140461983432464</title>\n<path d=\"M670,-415.366C670,-407.152 670,-397.658 670,-388.725\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"673.5,-388.607 670,-378.607 666.5,-388.607 673.5,-388.607\" stroke=\"black\"/>\n</g>\n<!-- 140461974930832 -->\n<g class=\"node\" id=\"node5\"><title>140461974930832</title>\n<polygon fill=\"none\" points=\"62.5,-332.5 62.5,-378.5 373.5,-378.5 373.5,-332.5 62.5,-332.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"142.5\" y=\"-351.8\">input_1: InputLayer</text>\n<polyline fill=\"none\" points=\"222.5,-332.5 222.5,-378.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"222.5,-355.5 290.5,-355.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"290.5,-332.5 290.5,-378.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"332\" y=\"-363.3\">(None, 2)</text>\n<polyline fill=\"none\" points=\"290.5,-355.5 373.5,-355.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"332\" y=\"-340.3\">(None, 2)</text>\n</g>\n<!-- 140461974930576 -->\n<g class=\"node\" id=\"node7\"><title>140461974930576</title>\n<polygon fill=\"none\" points=\"12,-249.5 12,-295.5 480,-295.5 480,-249.5 12,-249.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"122.5\" y=\"-268.8\">concatenate_1: Concatenate</text>\n<polyline fill=\"none\" points=\"233,-249.5 233,-295.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"233,-272.5 301,-272.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"301,-249.5 301,-295.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"390.5\" y=\"-280.3\">[(None, 2), (None, 32)]</text>\n<polyline fill=\"none\" points=\"301,-272.5 480,-272.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"390.5\" y=\"-257.3\">(None, 34)</text>\n</g>\n<!-- 140461974930832&#45;&gt;140461974930576 -->\n<g class=\"edge\" id=\"edge5\"><title>140461974930832-&gt;140461974930576</title>\n<path d=\"M225.651,-332.366C228.553,-323.973 231.915,-314.245 235.062,-305.143\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"238.399,-306.202 238.358,-295.607 231.783,-303.915 238.399,-306.202\" stroke=\"black\"/>\n</g>\n<!-- 140461983432464&#45;&gt;140461974930576 -->\n<g class=\"edge\" id=\"edge6\"><title>140461983432464-&gt;140461974930576</title>\n<path d=\"M554.7,-332.473C497.906,-321.624 429.328,-308.522 371.247,-297.427\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"371.756,-293.961 361.277,-295.522 370.442,-300.837 371.756,-293.961\" stroke=\"black\"/>\n</g>\n<!-- 140461974749136 -->\n<g class=\"node\" id=\"node11\"><title>140461974749136</title>\n<polygon fill=\"none\" points=\"526,-249.5 526,-295.5 814,-295.5 814,-249.5 526,-249.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"590\" y=\"-268.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"654,-249.5 654,-295.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"688\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"654,-272.5 722,-272.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"688\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"722,-249.5 722,-295.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"768\" y=\"-280.3\">(None, 32)</text>\n<polyline fill=\"none\" points=\"722,-272.5 814,-272.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"768\" y=\"-257.3\">(None, 2)</text>\n</g>\n<!-- 140461983432464&#45;&gt;140461974749136 -->\n<g class=\"edge\" id=\"edge10\"><title>140461983432464-&gt;140461974749136</title>\n<path d=\"M670,-332.366C670,-324.152 670,-314.658 670,-305.725\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"673.5,-305.607 670,-295.607 666.5,-305.607 673.5,-305.607\" stroke=\"black\"/>\n</g>\n<!-- 140461974931536 -->\n<g class=\"node\" id=\"node8\"><title>140461974931536</title>\n<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 492,-212.5 492,-166.5 0,-166.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166\" y=\"-185.8\">batch_normalization_1: BatchNormalization</text>\n<polyline fill=\"none\" points=\"332,-166.5 332,-212.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"332,-189.5 400,-189.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"400,-166.5 400,-212.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"446\" y=\"-197.3\">(None, 34)</text>\n<polyline fill=\"none\" points=\"400,-189.5 492,-189.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"446\" y=\"-174.3\">(None, 34)</text>\n</g>\n<!-- 140461974930576&#45;&gt;140461974931536 -->\n<g class=\"edge\" id=\"edge7\"><title>140461974930576-&gt;140461974931536</title>\n<path d=\"M246,-249.366C246,-241.152 246,-231.658 246,-222.725\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"249.5,-222.607 246,-212.607 242.5,-222.607 249.5,-222.607\" stroke=\"black\"/>\n</g>\n<!-- 140461974464976 -->\n<g class=\"node\" id=\"node9\"><title>140461974464976</title>\n<polygon fill=\"none\" points=\"102,-83.5 102,-129.5 390,-129.5 390,-83.5 102,-83.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166\" y=\"-102.8\">dense_2: Dense</text>\n<polyline fill=\"none\" points=\"230,-83.5 230,-129.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"230,-106.5 298,-106.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"298,-83.5 298,-129.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"344\" y=\"-114.3\">(None, 34)</text>\n<polyline fill=\"none\" points=\"298,-106.5 390,-106.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"344\" y=\"-91.3\">(None, 32)</text>\n</g>\n<!-- 140461974931536&#45;&gt;140461974464976 -->\n<g class=\"edge\" id=\"edge8\"><title>140461974931536-&gt;140461974464976</title>\n<path d=\"M246,-166.366C246,-158.152 246,-148.658 246,-139.725\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"249.5,-139.607 246,-129.607 242.5,-139.607 249.5,-139.607\" stroke=\"black\"/>\n</g>\n<!-- 140461974932240 -->\n<g class=\"node\" id=\"node10\"><title>140461974932240</title>\n<polygon fill=\"none\" points=\"102,-0.5 102,-46.5 390,-46.5 390,-0.5 102,-0.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166\" y=\"-19.8\">dense_3: Dense</text>\n<polyline fill=\"none\" points=\"230,-0.5 230,-46.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"230,-23.5 298,-23.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"298,-0.5 298,-46.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"344\" y=\"-31.3\">(None, 32)</text>\n<polyline fill=\"none\" points=\"298,-23.5 390,-23.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"344\" y=\"-8.3\">(None, 2)</text>\n</g>\n<!-- 140461974464976&#45;&gt;140461974932240 -->\n<g class=\"edge\" id=\"edge9\"><title>140461974464976-&gt;140461974932240</title>\n<path d=\"M246,-83.3664C246,-75.1516 246,-65.6579 246,-56.7252\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"249.5,-56.6068 246,-46.6068 242.5,-56.6069 249.5,-56.6068\" stroke=\"black\"/>\n</g>\n</g>\n</svg>",
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def isnotebook():\n",
    "    # written by @mtd http://stackoverflow.com/a/39662359\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':  # Jupyter notebook or qtconsole?\n",
    "            return True\n",
    "        elif shell == 'TerminalInteractiveShell':  # Terminal running IPython?\n",
    "            return False\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "\n",
    "\n",
    "img = None\n",
    "if isnotebook():\n",
    "    from keras.utils.vis_utils import model_to_dot\n",
    "    from IPython.display import SVG\n",
    "    img = SVG(model_to_dot(deeptune_model.model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DeepTune ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 32)\n",
      "WARNING:tensorflow:From /mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:953: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:675: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 20:17:39.186884: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-12-10 20:17:39.189689: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3699995000 Hz\n",
      "2022-12-10 20:17:39.190369: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x53c7bf0 executing computations on platform Host. Devices:\n",
      "2022-12-10 20:17:39.190390: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2022-12-10 20:17:39.399242: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510/510 [==============================] - 1s 2ms/step - loss: 0.7943 - dense_6_loss: 0.6572 - dense_4_loss: 0.6854 - dense_6_acc: 0.5980 - dense_4_acc: 0.6000\n",
      "Epoch 2/50\n",
      "510/510 [==============================] - 0s 954us/step - loss: 0.6735 - dense_6_loss: 0.5378 - dense_4_loss: 0.6786 - dense_6_acc: 0.7627 - dense_4_acc: 0.6000\n",
      "Epoch 3/50\n",
      "510/510 [==============================] - 0s 948us/step - loss: 0.6104 - dense_6_loss: 0.4760 - dense_4_loss: 0.6722 - dense_6_acc: 0.7843 - dense_4_acc: 0.6000\n",
      "Epoch 4/50\n",
      "510/510 [==============================] - 0s 953us/step - loss: 0.5608 - dense_6_loss: 0.4269 - dense_4_loss: 0.6697 - dense_6_acc: 0.8275 - dense_4_acc: 0.6000\n",
      "Epoch 5/50\n",
      "510/510 [==============================] - 0s 976us/step - loss: 0.5301 - dense_6_loss: 0.3962 - dense_4_loss: 0.6696 - dense_6_acc: 0.8294 - dense_4_acc: 0.6000\n",
      "Epoch 6/50\n",
      "510/510 [==============================] - 0s 950us/step - loss: 0.5038 - dense_6_loss: 0.3701 - dense_4_loss: 0.6685 - dense_6_acc: 0.8275 - dense_4_acc: 0.6000\n",
      "Epoch 7/50\n",
      "510/510 [==============================] - 0s 944us/step - loss: 0.4679 - dense_6_loss: 0.3343 - dense_4_loss: 0.6680 - dense_6_acc: 0.8490 - dense_4_acc: 0.6000\n",
      "Epoch 8/50\n",
      "510/510 [==============================] - 0s 971us/step - loss: 0.4546 - dense_6_loss: 0.3210 - dense_4_loss: 0.6676 - dense_6_acc: 0.8549 - dense_4_acc: 0.6000\n",
      "Epoch 9/50\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.4310 - dense_6_loss: 0.2977 - dense_4_loss: 0.6668 - dense_6_acc: 0.8745 - dense_4_acc: 0.6000\n",
      "Epoch 10/50\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.4198 - dense_6_loss: 0.2867 - dense_4_loss: 0.6651 - dense_6_acc: 0.8667 - dense_4_acc: 0.6000\n",
      "Epoch 11/50\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.4161 - dense_6_loss: 0.2832 - dense_4_loss: 0.6645 - dense_6_acc: 0.8647 - dense_4_acc: 0.6000\n",
      "Epoch 12/50\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.4103 - dense_6_loss: 0.2776 - dense_4_loss: 0.6636 - dense_6_acc: 0.8725 - dense_4_acc: 0.6000\n",
      "Epoch 13/50\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.4073 - dense_6_loss: 0.2748 - dense_4_loss: 0.6629 - dense_6_acc: 0.8765 - dense_4_acc: 0.6000\n",
      "Epoch 14/50\n",
      "510/510 [==============================] - 0s 973us/step - loss: 0.3930 - dense_6_loss: 0.2607 - dense_4_loss: 0.6615 - dense_6_acc: 0.8902 - dense_4_acc: 0.6000\n",
      "Epoch 15/50\n",
      "510/510 [==============================] - 0s 932us/step - loss: 0.3919 - dense_6_loss: 0.2597 - dense_4_loss: 0.6608 - dense_6_acc: 0.8647 - dense_4_acc: 0.6000\n",
      "Epoch 16/50\n",
      "510/510 [==============================] - 0s 943us/step - loss: 0.3846 - dense_6_loss: 0.2524 - dense_4_loss: 0.6608 - dense_6_acc: 0.8725 - dense_4_acc: 0.6000\n",
      "Epoch 17/50\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.3764 - dense_6_loss: 0.2443 - dense_4_loss: 0.6605 - dense_6_acc: 0.8843 - dense_4_acc: 0.6000\n",
      "Epoch 18/50\n",
      "510/510 [==============================] - 1s 1000us/step - loss: 0.3699 - dense_6_loss: 0.2382 - dense_4_loss: 0.6584 - dense_6_acc: 0.8941 - dense_4_acc: 0.6000\n",
      "Epoch 19/50\n",
      "510/510 [==============================] - 0s 976us/step - loss: 0.3647 - dense_6_loss: 0.2333 - dense_4_loss: 0.6571 - dense_6_acc: 0.8922 - dense_4_acc: 0.6000\n",
      "Epoch 20/50\n",
      "510/510 [==============================] - 0s 964us/step - loss: 0.3529 - dense_6_loss: 0.2218 - dense_4_loss: 0.6556 - dense_6_acc: 0.8980 - dense_4_acc: 0.6000\n",
      "Epoch 21/50\n",
      "510/510 [==============================] - 1s 985us/step - loss: 0.3538 - dense_6_loss: 0.2230 - dense_4_loss: 0.6541 - dense_6_acc: 0.9020 - dense_4_acc: 0.6000\n",
      "Epoch 22/50\n",
      "510/510 [==============================] - 0s 959us/step - loss: 0.3444 - dense_6_loss: 0.2138 - dense_4_loss: 0.6531 - dense_6_acc: 0.9137 - dense_4_acc: 0.6000\n",
      "Epoch 23/50\n",
      "510/510 [==============================] - 0s 973us/step - loss: 0.3446 - dense_6_loss: 0.2141 - dense_4_loss: 0.6526 - dense_6_acc: 0.8902 - dense_4_acc: 0.6000\n",
      "Epoch 24/50\n",
      "510/510 [==============================] - 0s 949us/step - loss: 0.3379 - dense_6_loss: 0.2074 - dense_4_loss: 0.6524 - dense_6_acc: 0.8961 - dense_4_acc: 0.6000\n",
      "Epoch 25/50\n",
      "510/510 [==============================] - 0s 948us/step - loss: 0.3291 - dense_6_loss: 0.1991 - dense_4_loss: 0.6504 - dense_6_acc: 0.9039 - dense_4_acc: 0.6000\n",
      "Epoch 26/50\n",
      "510/510 [==============================] - 0s 952us/step - loss: 0.3225 - dense_6_loss: 0.1928 - dense_4_loss: 0.6481 - dense_6_acc: 0.9255 - dense_4_acc: 0.6000\n",
      "Epoch 27/50\n",
      "510/510 [==============================] - 0s 951us/step - loss: 0.3265 - dense_6_loss: 0.1971 - dense_4_loss: 0.6468 - dense_6_acc: 0.9098 - dense_4_acc: 0.6000\n",
      "Epoch 28/50\n",
      "510/510 [==============================] - 0s 955us/step - loss: 0.3110 - dense_6_loss: 0.1821 - dense_4_loss: 0.6446 - dense_6_acc: 0.9275 - dense_4_acc: 0.6000\n",
      "Epoch 29/50\n",
      "510/510 [==============================] - 0s 961us/step - loss: 0.3110 - dense_6_loss: 0.1825 - dense_4_loss: 0.6427 - dense_6_acc: 0.9216 - dense_4_acc: 0.6000\n",
      "Epoch 30/50\n",
      "510/510 [==============================] - 0s 969us/step - loss: 0.2946 - dense_6_loss: 0.1664 - dense_4_loss: 0.6413 - dense_6_acc: 0.9392 - dense_4_acc: 0.6000\n",
      "Epoch 31/50\n",
      "510/510 [==============================] - 0s 942us/step - loss: 0.2932 - dense_6_loss: 0.1655 - dense_4_loss: 0.6386 - dense_6_acc: 0.9353 - dense_4_acc: 0.6000\n",
      "Epoch 32/50\n",
      "510/510 [==============================] - 0s 974us/step - loss: 0.2962 - dense_6_loss: 0.1688 - dense_4_loss: 0.6370 - dense_6_acc: 0.9216 - dense_4_acc: 0.6000\n",
      "Epoch 33/50\n",
      "510/510 [==============================] - 0s 976us/step - loss: 0.2989 - dense_6_loss: 0.1719 - dense_4_loss: 0.6348 - dense_6_acc: 0.9275 - dense_4_acc: 0.6000\n",
      "Epoch 34/50\n",
      "510/510 [==============================] - 0s 943us/step - loss: 0.2850 - dense_6_loss: 0.1582 - dense_4_loss: 0.6337 - dense_6_acc: 0.9373 - dense_4_acc: 0.6000\n",
      "Epoch 35/50\n",
      "510/510 [==============================] - 0s 947us/step - loss: 0.2772 - dense_6_loss: 0.1509 - dense_4_loss: 0.6313 - dense_6_acc: 0.9314 - dense_4_acc: 0.6000\n",
      "Epoch 36/50\n",
      "510/510 [==============================] - 0s 958us/step - loss: 0.2847 - dense_6_loss: 0.1592 - dense_4_loss: 0.6275 - dense_6_acc: 0.9412 - dense_4_acc: 0.6000\n",
      "Epoch 37/50\n",
      "510/510 [==============================] - 0s 964us/step - loss: 0.2580 - dense_6_loss: 0.1329 - dense_4_loss: 0.6253 - dense_6_acc: 0.9549 - dense_4_acc: 0.6039\n",
      "Epoch 38/50\n",
      "510/510 [==============================] - 0s 942us/step - loss: 0.2586 - dense_6_loss: 0.1343 - dense_4_loss: 0.6218 - dense_6_acc: 0.9627 - dense_4_acc: 0.6235\n",
      "Epoch 39/50\n",
      "510/510 [==============================] - 0s 949us/step - loss: 0.2663 - dense_6_loss: 0.1425 - dense_4_loss: 0.6189 - dense_6_acc: 0.9431 - dense_4_acc: 0.6176\n",
      "Epoch 40/50\n",
      "510/510 [==============================] - 0s 966us/step - loss: 0.2646 - dense_6_loss: 0.1412 - dense_4_loss: 0.6168 - dense_6_acc: 0.9373 - dense_4_acc: 0.6118\n",
      "Epoch 41/50\n",
      "510/510 [==============================] - 1s 983us/step - loss: 0.2640 - dense_6_loss: 0.1415 - dense_4_loss: 0.6127 - dense_6_acc: 0.9392 - dense_4_acc: 0.6510\n",
      "Epoch 42/50\n",
      "510/510 [==============================] - 0s 955us/step - loss: 0.2686 - dense_6_loss: 0.1467 - dense_4_loss: 0.6095 - dense_6_acc: 0.9392 - dense_4_acc: 0.6667\n",
      "Epoch 43/50\n",
      "510/510 [==============================] - 0s 954us/step - loss: 0.2667 - dense_6_loss: 0.1454 - dense_4_loss: 0.6062 - dense_6_acc: 0.9373 - dense_4_acc: 0.6608\n",
      "Epoch 44/50\n",
      "510/510 [==============================] - 0s 941us/step - loss: 0.2523 - dense_6_loss: 0.1320 - dense_4_loss: 0.6014 - dense_6_acc: 0.9549 - dense_4_acc: 0.6784\n",
      "Epoch 45/50\n",
      "510/510 [==============================] - 0s 949us/step - loss: 0.2457 - dense_6_loss: 0.1261 - dense_4_loss: 0.5976 - dense_6_acc: 0.9529 - dense_4_acc: 0.6627\n",
      "Epoch 46/50\n",
      "510/510 [==============================] - 0s 973us/step - loss: 0.2584 - dense_6_loss: 0.1394 - dense_4_loss: 0.5952 - dense_6_acc: 0.9373 - dense_4_acc: 0.6627\n",
      "Epoch 47/50\n",
      "510/510 [==============================] - 0s 963us/step - loss: 0.2419 - dense_6_loss: 0.1241 - dense_4_loss: 0.5892 - dense_6_acc: 0.9471 - dense_4_acc: 0.7118\n",
      "Epoch 48/50\n",
      "510/510 [==============================] - 1s 985us/step - loss: 0.2337 - dense_6_loss: 0.1163 - dense_4_loss: 0.5866 - dense_6_acc: 0.9510 - dense_4_acc: 0.6725\n",
      "Epoch 49/50\n",
      "510/510 [==============================] - 0s 950us/step - loss: 0.2343 - dense_6_loss: 0.1182 - dense_4_loss: 0.5806 - dense_6_acc: 0.9569 - dense_4_acc: 0.7039\n",
      "Epoch 50/50\n",
      "510/510 [==============================] - 0s 979us/step - loss: 0.2341 - dense_6_loss: 0.1191 - dense_4_loss: 0.5753 - dense_6_acc: 0.9510 - dense_4_acc: 0.7647\n",
      "170/170 [==============================] - 0s 343us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 20) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 32)\n",
      "Epoch 1/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 0.7413 - dense_9_loss: 0.6032 - dense_7_loss: 0.6906 - dense_9_acc: 0.6510 - dense_7_acc: 0.5627\n",
      "Epoch 2/50\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.5836 - dense_9_loss: 0.4472 - dense_7_loss: 0.6824 - dense_9_acc: 0.8529 - dense_7_acc: 0.5627\n",
      "Epoch 3/50\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.5159 - dense_9_loss: 0.3808 - dense_7_loss: 0.6759 - dense_9_acc: 0.8608 - dense_7_acc: 0.5627\n",
      "Epoch 4/50\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.4712 - dense_9_loss: 0.3367 - dense_7_loss: 0.6728 - dense_9_acc: 0.8667 - dense_7_acc: 0.5627\n",
      "Epoch 5/50\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.4353 - dense_9_loss: 0.3012 - dense_7_loss: 0.6705 - dense_9_acc: 0.8804 - dense_7_acc: 0.5627\n",
      "Epoch 6/50\n",
      "510/510 [==============================] - 0s 959us/step - loss: 0.4053 - dense_9_loss: 0.2718 - dense_7_loss: 0.6673 - dense_9_acc: 0.8784 - dense_7_acc: 0.5627\n",
      "Epoch 7/50\n",
      "510/510 [==============================] - 0s 956us/step - loss: 0.3837 - dense_9_loss: 0.2507 - dense_7_loss: 0.6648 - dense_9_acc: 0.8882 - dense_7_acc: 0.5627\n",
      "Epoch 8/50\n",
      "510/510 [==============================] - 0s 958us/step - loss: 0.3674 - dense_9_loss: 0.2352 - dense_7_loss: 0.6613 - dense_9_acc: 0.8980 - dense_7_acc: 0.5627\n",
      "Epoch 9/50\n",
      "510/510 [==============================] - 0s 957us/step - loss: 0.3640 - dense_9_loss: 0.2324 - dense_7_loss: 0.6585 - dense_9_acc: 0.9098 - dense_7_acc: 0.5627\n",
      "Epoch 10/50\n",
      "510/510 [==============================] - 0s 952us/step - loss: 0.3600 - dense_9_loss: 0.2286 - dense_7_loss: 0.6569 - dense_9_acc: 0.9039 - dense_7_acc: 0.5627\n",
      "Epoch 11/50\n",
      "510/510 [==============================] - 0s 956us/step - loss: 0.3472 - dense_9_loss: 0.2167 - dense_7_loss: 0.6526 - dense_9_acc: 0.9020 - dense_7_acc: 0.5627\n",
      "Epoch 12/50\n",
      "510/510 [==============================] - 0s 946us/step - loss: 0.3383 - dense_9_loss: 0.2084 - dense_7_loss: 0.6495 - dense_9_acc: 0.9059 - dense_7_acc: 0.5627\n",
      "Epoch 13/50\n",
      "510/510 [==============================] - 0s 956us/step - loss: 0.3278 - dense_9_loss: 0.1988 - dense_7_loss: 0.6451 - dense_9_acc: 0.9176 - dense_7_acc: 0.5627\n",
      "Epoch 14/50\n",
      "510/510 [==============================] - 1s 986us/step - loss: 0.3295 - dense_9_loss: 0.2012 - dense_7_loss: 0.6414 - dense_9_acc: 0.9098 - dense_7_acc: 0.5667\n",
      "Epoch 15/50\n",
      "510/510 [==============================] - 0s 958us/step - loss: 0.3265 - dense_9_loss: 0.1993 - dense_7_loss: 0.6359 - dense_9_acc: 0.9137 - dense_7_acc: 0.5784\n",
      "Epoch 16/50\n",
      "510/510 [==============================] - 0s 955us/step - loss: 0.3202 - dense_9_loss: 0.1940 - dense_7_loss: 0.6312 - dense_9_acc: 0.9157 - dense_7_acc: 0.5784\n",
      "Epoch 17/50\n",
      "510/510 [==============================] - 0s 957us/step - loss: 0.3190 - dense_9_loss: 0.1936 - dense_7_loss: 0.6270 - dense_9_acc: 0.9098 - dense_7_acc: 0.6137\n",
      "Epoch 18/50\n",
      "510/510 [==============================] - 0s 975us/step - loss: 0.3161 - dense_9_loss: 0.1916 - dense_7_loss: 0.6225 - dense_9_acc: 0.9157 - dense_7_acc: 0.7275\n",
      "Epoch 19/50\n",
      "510/510 [==============================] - 0s 957us/step - loss: 0.3128 - dense_9_loss: 0.1890 - dense_7_loss: 0.6190 - dense_9_acc: 0.9137 - dense_7_acc: 0.7412\n",
      "Epoch 20/50\n",
      "510/510 [==============================] - 0s 956us/step - loss: 0.3127 - dense_9_loss: 0.1901 - dense_7_loss: 0.6133 - dense_9_acc: 0.9118 - dense_7_acc: 0.7686\n",
      "Epoch 21/50\n",
      "510/510 [==============================] - 0s 971us/step - loss: 0.3070 - dense_9_loss: 0.1854 - dense_7_loss: 0.6077 - dense_9_acc: 0.9196 - dense_7_acc: 0.7961\n",
      "Epoch 22/50\n",
      "510/510 [==============================] - 0s 970us/step - loss: 0.2970 - dense_9_loss: 0.1766 - dense_7_loss: 0.6019 - dense_9_acc: 0.9118 - dense_7_acc: 0.8451\n",
      "Epoch 23/50\n",
      "510/510 [==============================] - 0s 965us/step - loss: 0.2951 - dense_9_loss: 0.1760 - dense_7_loss: 0.5956 - dense_9_acc: 0.9176 - dense_7_acc: 0.8275\n",
      "Epoch 24/50\n",
      "510/510 [==============================] - 0s 953us/step - loss: 0.3020 - dense_9_loss: 0.1844 - dense_7_loss: 0.5881 - dense_9_acc: 0.9157 - dense_7_acc: 0.8353\n",
      "Epoch 25/50\n",
      "510/510 [==============================] - 0s 956us/step - loss: 0.2886 - dense_9_loss: 0.1723 - dense_7_loss: 0.5814 - dense_9_acc: 0.9118 - dense_7_acc: 0.8431\n",
      "Epoch 26/50\n",
      "510/510 [==============================] - 0s 948us/step - loss: 0.3021 - dense_9_loss: 0.1869 - dense_7_loss: 0.5759 - dense_9_acc: 0.9176 - dense_7_acc: 0.8176\n",
      "Epoch 27/50\n",
      "510/510 [==============================] - 0s 975us/step - loss: 0.2920 - dense_9_loss: 0.1779 - dense_7_loss: 0.5704 - dense_9_acc: 0.9176 - dense_7_acc: 0.7686\n",
      "Epoch 28/50\n",
      "510/510 [==============================] - 0s 951us/step - loss: 0.2837 - dense_9_loss: 0.1708 - dense_7_loss: 0.5642 - dense_9_acc: 0.9216 - dense_7_acc: 0.8137\n",
      "Epoch 29/50\n",
      "510/510 [==============================] - 0s 939us/step - loss: 0.2795 - dense_9_loss: 0.1677 - dense_7_loss: 0.5586 - dense_9_acc: 0.9216 - dense_7_acc: 0.8275\n",
      "Epoch 30/50\n",
      "510/510 [==============================] - 0s 951us/step - loss: 0.2748 - dense_9_loss: 0.1645 - dense_7_loss: 0.5514 - dense_9_acc: 0.9255 - dense_7_acc: 0.8039\n",
      "Epoch 31/50\n",
      "510/510 [==============================] - 0s 975us/step - loss: 0.2728 - dense_9_loss: 0.1637 - dense_7_loss: 0.5456 - dense_9_acc: 0.9196 - dense_7_acc: 0.7941\n",
      "Epoch 32/50\n",
      "510/510 [==============================] - 0s 966us/step - loss: 0.2669 - dense_9_loss: 0.1596 - dense_7_loss: 0.5369 - dense_9_acc: 0.9294 - dense_7_acc: 0.8098\n",
      "Epoch 33/50\n",
      "510/510 [==============================] - 0s 942us/step - loss: 0.2710 - dense_9_loss: 0.1644 - dense_7_loss: 0.5333 - dense_9_acc: 0.9176 - dense_7_acc: 0.8078\n",
      "Epoch 34/50\n",
      "510/510 [==============================] - 0s 952us/step - loss: 0.2621 - dense_9_loss: 0.1571 - dense_7_loss: 0.5247 - dense_9_acc: 0.9333 - dense_7_acc: 0.7745\n",
      "Epoch 35/50\n",
      "510/510 [==============================] - 0s 947us/step - loss: 0.2626 - dense_9_loss: 0.1590 - dense_7_loss: 0.5180 - dense_9_acc: 0.9235 - dense_7_acc: 0.7804\n",
      "Epoch 36/50\n",
      "510/510 [==============================] - 1s 999us/step - loss: 0.2604 - dense_9_loss: 0.1580 - dense_7_loss: 0.5120 - dense_9_acc: 0.9196 - dense_7_acc: 0.8255\n",
      "Epoch 37/50\n",
      "510/510 [==============================] - 0s 946us/step - loss: 0.2639 - dense_9_loss: 0.1626 - dense_7_loss: 0.5069 - dense_9_acc: 0.9157 - dense_7_acc: 0.8059\n",
      "Epoch 38/50\n",
      "510/510 [==============================] - 0s 937us/step - loss: 0.2600 - dense_9_loss: 0.1593 - dense_7_loss: 0.5033 - dense_9_acc: 0.9196 - dense_7_acc: 0.7765\n",
      "Epoch 39/50\n",
      "510/510 [==============================] - 0s 969us/step - loss: 0.2535 - dense_9_loss: 0.1546 - dense_7_loss: 0.4944 - dense_9_acc: 0.9176 - dense_7_acc: 0.8314\n",
      "Epoch 40/50\n",
      "510/510 [==============================] - 0s 975us/step - loss: 0.2587 - dense_9_loss: 0.1601 - dense_7_loss: 0.4932 - dense_9_acc: 0.9235 - dense_7_acc: 0.8000\n",
      "Epoch 41/50\n",
      "510/510 [==============================] - 0s 940us/step - loss: 0.2610 - dense_9_loss: 0.1640 - dense_7_loss: 0.4849 - dense_9_acc: 0.9196 - dense_7_acc: 0.8157\n",
      "Epoch 42/50\n",
      "510/510 [==============================] - 0s 951us/step - loss: 0.2498 - dense_9_loss: 0.1551 - dense_7_loss: 0.4740 - dense_9_acc: 0.9235 - dense_7_acc: 0.8157\n",
      "Epoch 43/50\n",
      "510/510 [==============================] - 0s 956us/step - loss: 0.2502 - dense_9_loss: 0.1558 - dense_7_loss: 0.4723 - dense_9_acc: 0.9255 - dense_7_acc: 0.8000\n",
      "Epoch 44/50\n",
      "510/510 [==============================] - 0s 947us/step - loss: 0.2477 - dense_9_loss: 0.1543 - dense_7_loss: 0.4670 - dense_9_acc: 0.9216 - dense_7_acc: 0.8431\n",
      "Epoch 45/50\n",
      "510/510 [==============================] - 0s 973us/step - loss: 0.2473 - dense_9_loss: 0.1551 - dense_7_loss: 0.4607 - dense_9_acc: 0.9176 - dense_7_acc: 0.8216\n",
      "Epoch 46/50\n",
      "510/510 [==============================] - 0s 963us/step - loss: 0.2493 - dense_9_loss: 0.1588 - dense_7_loss: 0.4522 - dense_9_acc: 0.9216 - dense_7_acc: 0.8373\n",
      "Epoch 47/50\n",
      "510/510 [==============================] - 0s 947us/step - loss: 0.2397 - dense_9_loss: 0.1507 - dense_7_loss: 0.4448 - dense_9_acc: 0.9294 - dense_7_acc: 0.8490\n",
      "Epoch 48/50\n",
      "510/510 [==============================] - 1s 997us/step - loss: 0.2418 - dense_9_loss: 0.1540 - dense_7_loss: 0.4388 - dense_9_acc: 0.9157 - dense_7_acc: 0.8451\n",
      "Epoch 49/50\n",
      "510/510 [==============================] - 0s 971us/step - loss: 0.2312 - dense_9_loss: 0.1447 - dense_7_loss: 0.4324 - dense_9_acc: 0.9314 - dense_7_acc: 0.8529\n",
      "Epoch 50/50\n",
      "510/510 [==============================] - 0s 964us/step - loss: 0.2397 - dense_9_loss: 0.1533 - dense_7_loss: 0.4320 - dense_9_acc: 0.9294 - dense_7_acc: 0.8667\n",
      "170/170 [==============================] - 0s 421us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% (2 of 20) |##                       | Elapsed Time: 0:00:27 ETA:   0:04:04/mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Correct?</th>\n",
       "      <th>Speedup</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platform</th>\n",
       "      <th>Benchmark Suite</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">AMD Tahiti 7970</th>\n",
       "      <th>AMD SDK</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.152237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPB</th>\n",
       "      <td>0.795455</td>\n",
       "      <td>3.218831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVIDIA SDK</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>3.736255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parboil</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.449144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polybench</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.408824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rodinia</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>5.795564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHOC</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.010064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">NVIDIA GTX 970</th>\n",
       "      <th>AMD SDK</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPB</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.476968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVIDIA SDK</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parboil</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.422358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polybench</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rodinia</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.254350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHOC</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.379903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Correct?    Speedup\n",
       "Platform        Benchmark Suite                     \n",
       "AMD Tahiti 7970 AMD SDK          0.857143   1.152237\n",
       "                NPB              0.795455   3.218831\n",
       "                NVIDIA SDK       0.750000   3.736255\n",
       "                Parboil          1.000000  16.449144\n",
       "                Polybench        1.000000   2.408824\n",
       "                Rodinia          0.571429   5.795564\n",
       "                SHOC             0.888889   1.010064\n",
       "NVIDIA GTX 970  AMD SDK          1.000000   1.000000\n",
       "                NPB              0.818182   1.476968\n",
       "                NVIDIA SDK       0.750000   1.000000\n",
       "                Parboil          1.000000   1.422358\n",
       "                Polybench        0.600000   1.000000\n",
       "                Rodinia          0.571429   1.254350\n",
       "                SHOC             0.555556   1.379903"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Evaluating DeepTune ...\", file=sys.stderr)\n",
    "deeptune = evaluate(deeptune_model)\n",
    "deeptune.groupby(['Platform', 'Benchmark Suite'])['Platform', 'Correct?', 'Speedup'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of results. The *Correct?* column shows model accuracy. In the paper we report that DeepTune is accurate for **82%** of cases, achieving speedups of **3.34$\\times$** on AMD and **1.41$\\times$** on NVIDIA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Ralph/Documents/GitHub/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct?</th>\n",
       "      <th>Speedup</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platform</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AMD Tahiti 7970</th>\n",
       "      <td>0.805882</td>\n",
       "      <td>3.578205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVIDIA GTX 970</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.415844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Correct?   Speedup\n",
       "Platform                           \n",
       "AMD Tahiti 7970  0.805882  3.578205\n",
       "NVIDIA GTX 970   0.800000  1.415844"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeptune.groupby(['Platform'])['Platform', 'Correct?', 'Speedup'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation\n",
    "\n",
    "Here we evaluate the quality of the models using two metrics: prediction accuracy, and performance relative to the static mapping:\n",
    "\n",
    "### 4.1. Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "d.append(np.append(baseline.groupby(['Platform'])['Correct?'].mean().values * 100,\n",
    "                   baseline['Correct?'].mean() * 100))\n",
    "# print(baseline)\n",
    "d.append(np.append(grewe.groupby(['Platform'])['Correct?'].mean().values * 100,\n",
    "                   grewe['Correct?'].mean() * 100))\n",
    "d.append(np.append(deeptune.groupby(['Platform'])['Correct?'].mean().values * 100,\n",
    "                   deeptune['Correct?'].mean() * 100))\n",
    "d = np.array(d).T.reshape(3, 3)\n",
    "\n",
    "pd.DataFrame(d, columns=['Static mapping', 'Grewe et al.', 'DeepTune'],\n",
    "             index=['AMD Tahiti 7970', 'NVIDIA GTX 970', 'Average'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 6 of the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isnotebook():\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    from matplotlib.ticker import FormatStrFormatter\n",
    "    from labm8 import viz\n",
    "\n",
    "    # Plotting configuration\n",
    "    %matplotlib inline\n",
    "    sns.set(style=\"ticks\", color_codes=True)\n",
    "    plt.style.use([\"seaborn-white\", \"seaborn-paper\"])\n",
    "    matplotlib.rcParams['figure.dpi'] = 120\n",
    "    \n",
    "    for i, platform in enumerate([\"AMD Tahiti 7970\", \"NVIDIA GTX 970\"]):\n",
    "        \n",
    "        def get_accuracies(df, platform):\n",
    "            \"\"\" get % accuracies for platform, aggregated by benchmark suite \"\"\"\n",
    "            # average by benchmark suites\n",
    "            series = df[df[\"Platform\"] == platform]\\\n",
    "                        .groupby(['Benchmark Suite'])['Correct?'].mean() * 100  # %\n",
    "            # append average across all benchamrks\n",
    "            average = pd.Series(df[df[\"Platform\"] == platform]['Correct?'].mean() * 100,\n",
    "                                index=[\"Average\"])\n",
    "            return series.append(average)\n",
    "\n",
    "        # Aggregate data\n",
    "        models, results = (StaticMapping, Grewe, DeepTune), (baseline, grewe, deeptune)\n",
    "        dfs = [get_accuracies(r, platform) for r in results]\n",
    "\n",
    "        accuracies = np.concatenate([dfs[i].values for i in range(len(dfs))])\n",
    "        benchmarks = np.concatenate([dfs[i].keys().values for i in range(len(dfs))])\n",
    "        models = np.concatenate([np.array([m().__name__] * len(dfs[0])) for m in models])\n",
    "\n",
    "        benchmarks = np.append(benchmarks, \"Average\")\n",
    "\n",
    "        df = pd.DataFrame([{\"Benchmark\": b, \"Accuracy\": a, \"Model\": m}\n",
    "                           for b, a, m in zip(benchmarks, accuracies, models)])\n",
    "\n",
    "        # Plot\n",
    "        plt.subplot(2, 1, i + 1)\n",
    "        palette = sns.cubehelix_palette(3, rot=.2, light=.85, dark=.35)\n",
    "        ax = sns.barplot(x=\"Benchmark\", y=\"Accuracy\", hue=\"Model\", palette=palette, data=df)\n",
    "\n",
    "        # x axis\n",
    "        c = chr(ord('a') + i)\n",
    "        plt.xlabel(f\"({c}) {platform}\", fontsize=10)\n",
    "        plt.setp(ax.get_xticklabels(), rotation=25)  # rotate x ticks\n",
    "        plt.axvline(x=plt.xlim()[1] - 1, color=\"k\", lw=1, linestyle=\"--\")  # average line\n",
    "\n",
    "        # y axis\n",
    "        plt.ylim((0, 100))    \n",
    "        plt.gca().yaxis.set_major_formatter(FormatStrFormatter(\"%d%%\"))\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "\n",
    "        # legend\n",
    "        if i == 0:\n",
    "            plt.legend(loc=(0.003, 1.05), ncol=3)\n",
    "            ax.get_legend().set_title(\"\")  # no legend title\n",
    "            ax.get_legend().draw_frame(True)\n",
    "        elif i == 1:\n",
    "            ax.legend().set_visible(False)\n",
    "\n",
    "    viz.finalise(\n",
    "        # TODO: fs.path(\"~/Inbox/cgo-acc.pdf\"),\n",
    "        figsize=(4.25, 4.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Speedups\n",
    "\n",
    "Mean speedup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "d.append(np.append(baseline.groupby(['Platform'])['Speedup'].mean().values,\n",
    "                   baseline['Speedup'].mean()))\n",
    "d.append(np.append(grewe.groupby(['Platform'])['Speedup'].mean().values,\n",
    "                   grewe['Speedup'].mean()))\n",
    "d.append(np.append(deeptune.groupby(['Platform'])['Speedup'].mean().values,\n",
    "                   deeptune['Speedup'].mean()))\n",
    "d = np.array(d).T.reshape(3, 3)\n",
    "\n",
    "pd.DataFrame(d, columns=['Static mapping', 'Grewe et al.', 'DeepTune'],\n",
    "             index=['AMD Tahiti 7970', 'NVIDIA GTX 970', 'Average'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper we report geometric means of **1.18$\\times$** for Grewe et al., and **1.31$\\times$** for DeepTune:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from labm8 import math as labmath\n",
    "\n",
    "grewe_geomean = labmath.geomean(grewe['Speedup'].values)\n",
    "deeptune_geomean = labmath.geomean(deeptune['Speedup'].values)\n",
    "\n",
    "print(f\"Geometric mean of Grewe et al. {grewe_geomean:.2f}x\")\n",
    "print(f\"Geometric mean of DeepTune {deeptune_geomean:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 7 of the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isnotebook():\n",
    "    for i, platform in enumerate([\"AMD Tahiti 7970\", \"NVIDIA GTX 970\"]):\n",
    "\n",
    "        def get_speedups(df, platform):\n",
    "            \"\"\" get speedups for platform, aggregated by benchmark \"\"\"\n",
    "            # average by benchmark\n",
    "            series = df[df[\"Platform\"] == platform]\\\n",
    "                .groupby(['Benchmark'])['Speedup'].mean()\n",
    "            # average across all benchmarks\n",
    "            average = pd.Series(df[df['Platform'] == platform]['Speedup'].mean(), index=['Average'])\n",
    "            return series.append(average)\n",
    "\n",
    "        # Aggregate data\n",
    "        models, results = (Grewe, DeepTune), (grewe, deeptune)\n",
    "        dfs = [get_speedups(r, platform) for r in results]\n",
    "\n",
    "        speedups    = np.concatenate([dfs[i].values for i in range(len(dfs))])\n",
    "        benchmarks  = np.concatenate([dfs[i].keys().values for i in range(len(dfs))])\n",
    "        model_names = np.concatenate([np.array([m().__name__] * len(dfs[0])) for m in models])\n",
    "\n",
    "        df = pd.DataFrame([{\"Benchmark\": b, \"Speedup\": s - 1, \"Model\": m}\n",
    "                           for b, s, m in zip(benchmarks, speedups, model_names)])\n",
    "\n",
    "        # Plot\n",
    "        plt.subplot(2, 1, i + 1)\n",
    "        palette = sns.cubehelix_palette(2, rot=1.8, light=.85, dark=.35)\n",
    "        ax = sns.barplot(x=\"Benchmark\", y=\"Speedup\", hue=\"Model\", palette=palette, data=df)\n",
    "        c = chr(ord('a') + i)\n",
    "        plt.xlabel(f\"({c}) {platform}\", fontsize=10)\n",
    "        \n",
    "        # x axis\n",
    "        plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "        plt.axvline(x=plt.xlim()[1] - 1, color=\"k\", lw=1, linestyle=\"--\")  # average line\n",
    "\n",
    "        # y axis\n",
    "        plt.ylim((-1, 3) if i else (-1, 9))\n",
    "        plt.ylabel(\"Speedup\", fontsize=10)\n",
    "\n",
    "        # legend\n",
    "        plt.legend(loc='upper left')\n",
    "        ax.get_legend().set_title(\"\")\n",
    "        ax.get_legend().draw_frame(True)\n",
    "\n",
    "        plt.axhline(y=0, color=\"k\", lw=.5)  # speedup line\n",
    "        ax.set_yticklabels([\"{:.1f}x\".format(i + 1) for i in ax.get_yticks()])\n",
    "    \n",
    "    viz.finalise(figsize=(8.5, 6.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Comparison to State-of-the-art\n",
    "\n",
    "Here we directly compare performance of DeepTune against the Grewe et al. state-of-the-art model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_improvement = (deeptune[\"Speedup\"].mean() / grewe[\"Speedup\"].mean()) - 1\n",
    "\n",
    "print(f\"DeepTune outperforms Grewe et al. by {performance_improvement:.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cases = len(deeptune)\n",
    "num_better = sum(1 for d, g in zip(deeptune[\"Speedup\"], grewe[\"Speedup\"]) if d >= g)\n",
    "ratio_better = num_better / num_cases\n",
    "print(\"DeepTune matched or improved over state-of-the-art in \"\n",
    "      f\"{num_better} of {num_cases} cases ({ratio_better:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Training without Auxiliary Inputs\n",
    "\n",
    "Finally, we evaluate the role of auxiliary inputs on the quality of the learned model. We configure a DeepTune model without the two auxiliary inputs for workgroup and dataset size, and repeat the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DeepTuneNoAux(HeterogemeousMappingModel):\n",
    "    __name__ = \"DeepTune wo. Auxiliary Inputs\"\n",
    "    __basename__ = \"deeptune-no-aux\"\n",
    "    \n",
    "    def init(self, seed: int):\n",
    "        from keras.layers import Input, Embedding, LSTM, Dense, Conv1D, GlobalMaxPooling1D\n",
    "        from keras.layers.merge import Concatenate\n",
    "        from keras.layers.normalization import BatchNormalization\n",
    "        from keras.models import Model\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        # Language model. Takes as inputs source code sequences.\n",
    "        code_in = Input(shape=(1024,), dtype=\"int32\", name=\"code_in\")\n",
    "        x = Embedding(input_dim=atomizer.vocab_size + 1, input_length=1024, \n",
    "                      output_dim=64, name=\"embedding\")(code_in)\n",
    "        # x = LSTM(64, implementation=1, return_sequences=True, name=\"lstm_1\")(x)\n",
    "        # x = LSTM(64, implementation=1, name=\"lstm_2\")(x)\n",
    "        x = Conv1D(filters=32, kernel_size=9, strides=1, name=\"conv_1\")(x)\n",
    "        x = GlobalMaxPooling1D()(x)\n",
    "            \n",
    "        # Heuristic model. Takes as inputs the language model,\n",
    "        #   outputs 1-hot encoded device mapping\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dense(32, activation=\"relu\")(x)\n",
    "        out = Dense(2, activation=\"sigmoid\")(x)\n",
    "\n",
    "        self.model = Model(inputs=[code_in], outputs=[out])\n",
    "        self.model.compile(\n",
    "            optimizer=\"adam\", metrics=['accuracy'],\n",
    "            loss=\"categorical_crossentropy\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def save(self, outpath):\n",
    "        self.model.save(outpath)\n",
    "\n",
    "    def restore(self, inpath):\n",
    "        from keras.models import load_model\n",
    "        self.model = load_model(inpath)\n",
    "        \n",
    "    def train(self, **train):\n",
    "        self.model.fit(train[\"sequences\"], train[\"y_1hot\"],\n",
    "                       epochs=50, batch_size=64, verbose=train[\"verbose\"], shuffle=True)\n",
    "\n",
    "    def predict(self, **test):\n",
    "        p = np.array(self.model.predict(test[\"sequences\"], batch_size=64, verbose=test[\"verbose\"]))\n",
    "        indices = [np.argmax(x) for x in p]\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeptune_noaux_model = DeepTuneNoAux()\n",
    "deeptune_noaux_model.init(seed)\n",
    "deeptune_noaux_model.model.summary()\n",
    "\n",
    "img = None\n",
    "if isnotebook():\n",
    "    from keras.utils.vis_utils import model_to_dot\n",
    "    from IPython.display import SVG\n",
    "    img = SVG(model_to_dot(deeptune_noaux_model.model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating DeepTune wo. auxiliary inputs ...\", file=sys.stderr)\n",
    "deeptune_noaux = evaluate(DeepTuneNoAux())\n",
    "deeptune_noaux.groupby(['Platform', 'Benchmark Suite'])['Platform', 'Correct?', 'Speedup'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of results. In the paper, we report that removing auxiliary inputs leads to a **12%** reduction in model accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup_loss = 1 - (deeptune_noaux['Speedup'].mean() / deeptune['Speedup'].mean())\n",
    "acc_loss = 1 - (deeptune_noaux['Correct?'].mean() / deeptune['Correct?'].mean())\n",
    "\n",
    "print(f\"Training without auxiliary inputs yields a \"\n",
    "      f\"{acc_loss:.0%} reduction in DeepTune's acccuracy, and a \"\n",
    "      f\"{speedup_loss:.0%} reduction in performance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Seeding Transfer Learning\n",
    "\n",
    "Now we train a DeepTune model which we will re-use in Case Study B by transferring the learned weights: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Seeding transfer learning ... \", end=\"\")\n",
    "\n",
    "model_path = f\"../data/case-study-b/case-study-a.model\"\n",
    "weights_path = f\"../data/case-study-b/case-study-a-weights.h5\"\n",
    "\n",
    "if not fs.exists(weights_path):\n",
    "    deeptune_model = DeepTune()\n",
    "\n",
    "    if fs.exists(model_path):\n",
    "        deeptune_model = deeptune_model.restore(model_path)\n",
    "    else:\n",
    "        df = pd.read_csv(f\"../data/case-study-a/cgo17-amd.csv\")\n",
    "\n",
    "        sequences = encode_srcs(df[\"src\"].values)\n",
    "\n",
    "        features = grewe_features(df)\n",
    "        aux_in = auxiliary_inputs(df)\n",
    "\n",
    "        y = np.array([1 if x == \"GPU\" else 0 for x in df[\"oracle\"].values])\n",
    "        y_1hot = encode_1hot(y)\n",
    "\n",
    "        deeptune_model.init(seed=seed)\n",
    "        deeptune_model.train(df=df,\n",
    "                             features=features,\n",
    "                             aux_in=aux_in,\n",
    "                             sequences=sequences,\n",
    "                             y=y,\n",
    "                             y_1hot=y_1hot,\n",
    "                             verbose=True)\n",
    "        deeptune_model.save(model_path)\n",
    "\n",
    "    deeptune_model.model.save_weights(weights_path)\n",
    "\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See '*Case Study B.ipynb*' for experiments using transfer learning.\n",
    "\n",
    "End of experiments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "104df134e61ee2e973e6704fd3055318865a4c9447c2680692bac6b44eefde8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
