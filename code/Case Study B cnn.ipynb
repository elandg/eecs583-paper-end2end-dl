{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCL Thread Coarsening\n",
    "\n",
    "This notebook contains the experiments for Case Study B - using deep learning to predict thread coarsening factor for OpenCL kernels, without hand engineered features.\n",
    "\n",
    "## 1. Runtime Data\n",
    "\n",
    "We use author-provided runtime data from the PACT'14 paper that we compare against [1].\n",
    "\n",
    "> [1] Magni, A., Dubach, C., & O’Boyle, M. (2014). [Automatic Optimization of Thread-Coarsening for Graphics Processors](http://www.research.ed.ac.uk/portal/files/19958629/magni14pact.pdf). In PACT. ACM.\n",
    "\n",
    "The data consists of runtimes from 17 benchmarks accross 4 experimental platforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>cf</th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "      <th>PCA3</th>\n",
       "      <th>PCA4</th>\n",
       "      <th>PCA5</th>\n",
       "      <th>PCA6</th>\n",
       "      <th>PCA7</th>\n",
       "      <th>runtime_Fermi</th>\n",
       "      <th>runtime_Kepler</th>\n",
       "      <th>runtime_Cypress</th>\n",
       "      <th>runtime_Tahiti</th>\n",
       "      <th>src</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>1</td>\n",
       "      <td>1.994918</td>\n",
       "      <td>-0.810402</td>\n",
       "      <td>-2.206370</td>\n",
       "      <td>3.217486</td>\n",
       "      <td>-2.193143</td>\n",
       "      <td>2.374925</td>\n",
       "      <td>0.174607</td>\n",
       "      <td>1321696.0</td>\n",
       "      <td>1381120.0</td>\n",
       "      <td>1783889.0</td>\n",
       "      <td>975555.0</td>\n",
       "      <td>__kernel void A(__global float* a, __global fl...</td>\n",
       "      <td>[ 59   1 118   1  31   7  58   1  80   9   1  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>2</td>\n",
       "      <td>2.133716</td>\n",
       "      <td>-1.493068</td>\n",
       "      <td>-1.286520</td>\n",
       "      <td>3.075195</td>\n",
       "      <td>-0.381715</td>\n",
       "      <td>0.677804</td>\n",
       "      <td>0.960159</td>\n",
       "      <td>1238176.0</td>\n",
       "      <td>1222336.0</td>\n",
       "      <td>1849444.0</td>\n",
       "      <td>962963.0</td>\n",
       "      <td>__kernel void A(__global float* a, __global fl...</td>\n",
       "      <td>[ 59   1 118   1  31   7  58   1  80   9   1  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>nbody</td>\n",
       "      <td>8</td>\n",
       "      <td>-1.753095</td>\n",
       "      <td>-0.428577</td>\n",
       "      <td>-4.534866</td>\n",
       "      <td>-1.279360</td>\n",
       "      <td>0.941490</td>\n",
       "      <td>1.106185</td>\n",
       "      <td>-0.531706</td>\n",
       "      <td>332913280.0</td>\n",
       "      <td>30859456.0</td>\n",
       "      <td>35734111.0</td>\n",
       "      <td>36427408.0</td>\n",
       "      <td>__kernel void A(__global float4* a, __global f...</td>\n",
       "      <td>[ 59   1 118   1  31   7  58   1  80  19   9  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>nbody</td>\n",
       "      <td>16</td>\n",
       "      <td>-4.279616</td>\n",
       "      <td>-1.328454</td>\n",
       "      <td>-6.529448</td>\n",
       "      <td>-1.415595</td>\n",
       "      <td>2.290164</td>\n",
       "      <td>-0.138573</td>\n",
       "      <td>0.294633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42521556.0</td>\n",
       "      <td>65451704.0</td>\n",
       "      <td>__kernel void A(__global float4* a, __global f...</td>\n",
       "      <td>[ 59   1 118   1  31   7  58   1  80  19   9  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          kernel  cf      PCA1      PCA2      PCA3      PCA4      PCA5  \\\n",
       "0   blackscholes   1  1.994918 -0.810402 -2.206370  3.217486 -2.193143   \n",
       "1   blackscholes   2  2.133716 -1.493068 -1.286520  3.075195 -0.381715   \n",
       "..           ...  ..       ...       ...       ...       ...       ...   \n",
       "87         nbody   8 -1.753095 -0.428577 -4.534866 -1.279360  0.941490   \n",
       "88         nbody  16 -4.279616 -1.328454 -6.529448 -1.415595  2.290164   \n",
       "\n",
       "        PCA6      PCA7  runtime_Fermi  runtime_Kepler  runtime_Cypress  \\\n",
       "0   2.374925  0.174607      1321696.0       1381120.0        1783889.0   \n",
       "1   0.677804  0.960159      1238176.0       1222336.0        1849444.0   \n",
       "..       ...       ...            ...             ...              ...   \n",
       "87  1.106185 -0.531706    332913280.0      30859456.0       35734111.0   \n",
       "88 -0.138573  0.294633            NaN             NaN       42521556.0   \n",
       "\n",
       "    runtime_Tahiti                                                src  \\\n",
       "0         975555.0  __kernel void A(__global float* a, __global fl...   \n",
       "1         962963.0  __kernel void A(__global float* a, __global fl...   \n",
       "..             ...                                                ...   \n",
       "87      36427408.0  __kernel void A(__global float4* a, __global f...   \n",
       "88      65451704.0  __kernel void A(__global float4* a, __global f...   \n",
       "\n",
       "                                                  seq  \n",
       "0   [ 59   1 118   1  31   7  58   1  80   9   1  ...  \n",
       "1   [ 59   1 118   1  31   7  58   1  80   9   1  ...  \n",
       "..                                                ...  \n",
       "87  [ 59   1 118   1  31   7  58   1  80  19   9  ...  \n",
       "88  [ 59   1 118   1  31   7  58   1  80  19   9  ...  \n",
       "\n",
       "[89 rows x 15 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 5)\n",
    "\n",
    "df = pd.read_csv(\"../data/case-study-b/pact-2014-runtimes.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can derive the \"oracle\" thread coarsening factors, i.e. the thread coarsening factors which provided the lowest runtime on each of the four architectures, for each of the 17 benchmarks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>cf_Fermi</th>\n",
       "      <th>runtime_Fermi</th>\n",
       "      <th>cf_Kepler</th>\n",
       "      <th>runtime_Kepler</th>\n",
       "      <th>cf_Cypress</th>\n",
       "      <th>runtime_Cypress</th>\n",
       "      <th>cf_Tahiti</th>\n",
       "      <th>runtime_Tahiti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>binarySearch</td>\n",
       "      <td>1.0</td>\n",
       "      <td>213216.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>165248.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>290889.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>178518.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackscholes</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1148128.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1179008.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1783889.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>962963.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spmv</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36224.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52896.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>stencil</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4295104.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4330912.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10420555.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5200148.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          kernel  cf_Fermi  runtime_Fermi  cf_Kepler  runtime_Kepler  \\\n",
       "0   binarySearch       1.0       213216.0       16.0        165248.0   \n",
       "1   blackscholes       8.0      1148128.0        4.0       1179008.0   \n",
       "..           ...       ...            ...        ...             ...   \n",
       "15          spmv       1.0        36224.0        1.0         52896.0   \n",
       "16       stencil       2.0      4295104.0        1.0       4330912.0   \n",
       "\n",
       "    cf_Cypress  runtime_Cypress  cf_Tahiti  runtime_Tahiti  \n",
       "0          2.0         290889.0        4.0        178518.0  \n",
       "1          1.0        1783889.0        2.0        962963.0  \n",
       "..         ...              ...        ...             ...  \n",
       "15         1.0          82000.0        1.0         64592.0  \n",
       "16         1.0       10420555.0        1.0       5200148.0  \n",
       "\n",
       "[17 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracles = pd.read_csv(\"../data/case-study-b/pact-2014-oracles.csv\")\n",
    "oracles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predictive Models\n",
    "\n",
    "We define a base class for implementing predictive models for thread coarsening:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from clgen import _atomizer as clgen\n",
    "\n",
    "class ThreadCoarseningModel(object):\n",
    "    \"\"\"\n",
    "    A model for predicting OpenCL thread coarsening factors.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    __name__ : str\n",
    "        Model name\n",
    "    __basename__ : str\n",
    "        Shortened name, used for files\n",
    "    \"\"\"\n",
    "    __name__ = None\n",
    "    __basename__ = None\n",
    "\n",
    "    def init(self, seed: int) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the model.\n",
    "\n",
    "        Do whatever is required to setup a new thread coarsening model here.\n",
    "        This method is called prior to training and predicting.\n",
    "        This method may be omitted if no initial setup is required.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        seed : int\n",
    "            The seed value used to reproducible results. May be 'None',\n",
    "            indicating that no seed is to be used.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def save(self, outpath: str) -> None:\n",
    "        \"\"\"\n",
    "        Save model state.\n",
    "\n",
    "        This must capture all of the relevant state of the model. It is up\n",
    "        to implementing classes to determine how best to save the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        outpath : str\n",
    "            The path to save the model state to.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def restore(self, inpath: str) -> None:\n",
    "        \"\"\"\n",
    "        Load a trained model from file.\n",
    "\n",
    "        This is called in place of init() if a saved model file exists. It\n",
    "        must restore all of the required model state.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inpath : str\n",
    "            The path to load the model from. This is the same path as\n",
    "            was passed to save() to create the file.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def train(self, cascading_features: np.array, cascading_y: np.array,\n",
    "              sequences: np.array, y_1hot: np.array, verbose: bool=False) -> None:\n",
    "        \"\"\"\n",
    "        Train a model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cascading_features : np.array\n",
    "            An array of feature vectors of shape (n,7,7). Used for the cascading\n",
    "            model, there are 7 vectors of 7 features for each benchmark, one for\n",
    "            each coarsening factor.\n",
    "\n",
    "        cascading_y : np.array\n",
    "            An array of classification labels of shape(n,7). Used for the cascading\n",
    "            model.\n",
    "\n",
    "        sequences : np.array\n",
    "            An array of encoded source code sequences of shape (n,seq_length).\n",
    "\n",
    "        y_1hot : np.array\n",
    "            An array of optimal coarsening factors of shape (n,6), in 1-hot encoding.\n",
    "\n",
    "        verbose: bool, optional\n",
    "            Whether to print verbose status messages during training.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self, cascading_features: np.array, sequences: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        Make predictions for programs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cascading_features : np.array\n",
    "            An array of feature vectors of shape (n,7,7). Used for the cascading\n",
    "            model, there are 7 vectors of 7 features for each benchmark, one for\n",
    "            each coarsening factor.\n",
    "\n",
    "        sequences : np.array\n",
    "            An array of encoded source code sequences of shape (n,seq_length).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array\n",
    "            Predicted 'y' values (optimal thread coarsening factors) with shape (n,1).\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define some utility code which we will use later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfs = [1, 2, 4, 8, 16, 32]  # thread coarsening factors\n",
    "\n",
    "def get_onehot(df, platform):\n",
    "    hot = np.zeros((len(df), len(cfs)), dtype=np.int32)\n",
    "    for i, cf in enumerate(df[f\"cf_{platform}\"]):\n",
    "        hot[i][cfs.index(cf)] = 1\n",
    "\n",
    "    return hot\n",
    "\n",
    "\n",
    "def get_magni_features(df, oracles, platform):\n",
    "    \"\"\"\n",
    "    Assemble cascading data.\n",
    "    \"\"\"\n",
    "    X_cc, y_cc, = [], []\n",
    "    for kernel in sorted(set(df[\"kernel\"])):\n",
    "        _df = df[df[\"kernel\"] == kernel]\n",
    "\n",
    "        oracle_cf = int(oracles[oracles[\"kernel\"] == kernel][f\"cf_{platform}\"].values[0])\n",
    "\n",
    "        feature_vectors = np.asarray([\n",
    "            _df['PCA1'].values,\n",
    "            _df['PCA2'].values,\n",
    "            _df['PCA3'].values,\n",
    "            _df['PCA4'].values,\n",
    "            _df['PCA5'].values,\n",
    "            _df['PCA6'].values,\n",
    "            _df['PCA7'].values,\n",
    "        ]).T\n",
    "                \n",
    "        X_cc.append(feature_vectors)\n",
    "        y = []\n",
    "        cfs__ = []\n",
    "        for i, cf in enumerate(cfs[:len(feature_vectors)]):\n",
    "            y_ = 1 if cf < oracle_cf else 0\n",
    "            y.append(y_)\n",
    "        y_cc.append(y)\n",
    "    \n",
    "        assert len(feature_vectors) == len(y)\n",
    "        \n",
    "    assert len(X_cc) == len(y_cc) == 17\n",
    "    \n",
    "    return np.asarray(X_cc), np.asarray(y_cc)\n",
    "\n",
    "\n",
    "def encode_srcs(srcs):\n",
    "    \"\"\" encode and pad source code for learning \"\"\"\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "    \n",
    "    seqs = [atomizer.atomize(src) for src in srcs]\n",
    "    pad_val = atomizer.vocab_size\n",
    "    encoded = np.array(pad_sequences(seqs, maxlen=1024, value=pad_val))\n",
    "    return np.vstack([np.expand_dims(x, axis=0) for x in encoded])\n",
    "\n",
    "\n",
    "def platform2str(platform):\n",
    "    if platform == \"Fermi\":\n",
    "        return \"NVIDIA GTX 480\"\n",
    "    elif platform == \"Kepler\":\n",
    "        return \"NVIDIA Tesla K20c\"\n",
    "    elif platform == \"Cypress\":\n",
    "        return \"AMD Radeon HD 5900\"\n",
    "    elif platform == \"Tahiti\":\n",
    "        return \"AMD Tahiti 7970\"\n",
    "    else:\n",
    "        raise LookupError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experimental Methodology\n",
    "\n",
    "For reproducible results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 204"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source encoder (see the *'Language Model.ipynb'* notebook for details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GreedyAtomizer[128 tokens]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from clgen import Language\n",
    "\n",
    "srcs = '\\n'.join(pd.read_csv(\"../data/case-study-a/cgo17-amd.csv\")['src'].values)\n",
    "atomizer = clgen.GreedyAtomizer.from_text(lang=Language.from_str(\"opencl\"), text=srcs)\n",
    "atomizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "from labm8 import fs\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "def evaluate(model):\n",
    "    # report progress:\n",
    "    from progressbar import ProgressBar\n",
    "    progressbar = [0, ProgressBar(max_value=68)]\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    X_seq = None  # defer sequence encoding (it's expensive)\n",
    "    \n",
    "    for i, platform in enumerate([\"Cypress\", \"Tahiti\", \"Fermi\", \"Kepler\"]):\n",
    "        platform_name = platform2str(platform)\n",
    "                \n",
    "        # load data\n",
    "        oracle_runtimes = np.array([float(x) for x in oracles[\"runtime_\" + platform]])\n",
    "        y = np.array([int(x) for x in oracles[\"cf_\" + platform]], dtype=np.int32)\n",
    "        y_1hot = get_onehot(oracles, platform)\n",
    "        X_cc, y_cc = get_magni_features(df, oracles, platform)\n",
    "        \n",
    "        # LOOCV\n",
    "        kf = KFold(n_splits=len(y), shuffle=False)\n",
    "    \n",
    "        for j, (train_index, test_index) in enumerate(kf.split(y)):\n",
    "        # indices = np.arange(len(y))\n",
    "        # train_index, test_index = train_test_split(indices, shuffle=True, random_state=seed, test_size=0.25)\n",
    "            kernel = sorted(set(df[\"kernel\"]))[test_index[0]]\n",
    "\n",
    "            model_name = model.__name__\n",
    "            model_basename = model.__basename__\n",
    "            \n",
    "            model_path = f\"../data/case-study-b/models/{model_basename}-{platform}.model\"\n",
    "            predictions_path = f\"../data/case-study-b/predictions/{model_basename}-{platform}.result\"  \n",
    "\n",
    "            if False:\n",
    "            # if fs.exists(predictions_path):\n",
    "                # load result from cache\n",
    "                with open(predictions_path, 'rb') as infile:\n",
    "                    p = pickle.load(infile)\n",
    "            else:\n",
    "                if False:\n",
    "                # if fs.exists(model_path):\n",
    "                    # load a trained model from cache\n",
    "                    model.restore(model_path)\n",
    "                else:\n",
    "                    # encode source codes\n",
    "                    if X_seq is None:\n",
    "                        X_seq = encode_srcs(df[\"src\"].values)\n",
    "\n",
    "                    # create a new model and train it\n",
    "                    model.init(seed=seed)\n",
    "                    model.train(cascading_features=np.concatenate(X_cc[train_index]),\n",
    "                                cascading_y=np.concatenate(y_cc[train_index]),\n",
    "                                sequences=X_seq[train_index],\n",
    "                                verbose=True, # TODO\n",
    "                                y_1hot=y_1hot[train_index])\n",
    "\n",
    "                    # cache the model\n",
    "                    fs.mkdir(fs.dirname(model_path))\n",
    "                    model.save(model_path)\n",
    "\n",
    "                # make prediction\n",
    "                p = model.predict(cascading_features=X_cc[test_index[0]], sequences=X_seq[test_index])[0]\n",
    "                p = min(p, 2 ** (len(X_cc[test_index[0]]) - 1))\n",
    "                \n",
    "                # cache the prediction\n",
    "                fs.mkdir(fs.dirname(predictions_path))\n",
    "                with open(predictions_path, 'wb') as outfile:\n",
    "                    pickle.dump(p, outfile)\n",
    "                    \n",
    "            # oracle prediction\n",
    "            o = y[test_index[0]]\n",
    "            correct = p == o\n",
    "\n",
    "            # get runtime without thread coarsening\n",
    "            row = df[(df[\"kernel\"] == kernel) & (df[\"cf\"] == 1)]\n",
    "            assert(len(row) == 1)  # sanity check\n",
    "            nocf_runtime = float(row[\"runtime_\" + platform])\n",
    "\n",
    "            # get runtime of prediction\n",
    "            row = df[(df[\"kernel\"] == kernel) & (df[\"cf\"] == p)]\n",
    "            assert(len(row) == 1)  # sanity check\n",
    "            p_runtime = float(row[\"runtime_\" + platform])\n",
    "            \n",
    "            # get runtime of oracle coarsening factor\n",
    "            o_runtime = oracle_runtimes[test_index[0]]\n",
    "\n",
    "            # speedup and % oracle\n",
    "            s_oracle = nocf_runtime / o_runtime\n",
    "            p_speedup = nocf_runtime / p_runtime\n",
    "            p_oracle = o_runtime / p_runtime\n",
    "\n",
    "            # record result\n",
    "            data.append({\n",
    "                \"Model\": model_name,\n",
    "                \"Platform\": platform_name,\n",
    "                \"Kernel\": kernel,\n",
    "                \"Oracle-CF\": o,\n",
    "                \"Predicted-CF\": p,\n",
    "                \"Speedup\": p_speedup,\n",
    "                \"Oracle\": p_oracle\n",
    "            })\n",
    "            \n",
    "            progressbar[0] += 1  # update progress bar\n",
    "            progressbar[1].update(progressbar[0])\n",
    "\n",
    "    return pd.DataFrame(data, columns=[\n",
    "        \"Model\", \"Platform\", \"Kernel\", \"Oracle-CF\", \"Predicted-CF\", \"Speedup\", \"Oracle\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Magni et al. Model\n",
    "\n",
    "The Magni et al. predictive model.\n",
    "\n",
    "Described in publication:\n",
    "\n",
    "> [1] Magni, A., Dubach, C., & O’Boyle, M. (2014). [Automatic Optimization of Thread-Coarsening for Graphics Processors](http://www.research.ed.ac.uk/portal/files/19958629/magni14pact.pdf). In PACT. ACM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "# during grid search, not all parameters will converge. Ignore these warnings\n",
    "from warnings import filterwarnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "class Magni(ThreadCoarseningModel):\n",
    "    __name__ = \"Magni et al.\"\n",
    "    __basename__ = \"magni\"\n",
    "\n",
    "    def init(self, seed: int=None):\n",
    "        # the neural network\n",
    "        nn = MLPClassifier(random_state=seed, shuffle=True)\n",
    "\n",
    "        # cross-validation over the training set. We train on 16 programs,\n",
    "        # so with k=16 and no shuffling of the data, we're performing\n",
    "        # nested leave-one-out cross-validation\n",
    "        inner_cv = KFold(n_splits=16, shuffle=False)\n",
    "\n",
    "        # hyper-parameter combinations to try\n",
    "        params = {\n",
    "            \"max_iter\": [200, 500, 1000, 2000],\n",
    "            \"hidden_layer_sizes\": [\n",
    "                (32,),\n",
    "                (32, 32),\n",
    "                (32, 32, 32),\n",
    "                (64,),\n",
    "                (64, 64),\n",
    "                (64, 64, 64),\n",
    "                (128,),\n",
    "                (128, 128),\n",
    "                (128, 128, 128),\n",
    "                (256,),\n",
    "                (256, 256),\n",
    "                (256, 256, 256),\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        self.model = GridSearchCV(nn, cv=inner_cv, param_grid=params, n_jobs=-1)\n",
    "\n",
    "    def save(self, outpath):\n",
    "        with open(outpath, 'wb') as outfile:\n",
    "            pickle.dump(self.model, outfile)\n",
    "\n",
    "    def restore(self, inpath):\n",
    "        with open(inpath, 'rb') as infile:\n",
    "            self.model = pickle.load(infile)\n",
    "\n",
    "    def train(self, cascading_features: np.array, cascading_y: np.array,\n",
    "              sequences: np.array, y_1hot: np.array, verbose: bool=False) -> None:\n",
    "        self.model.fit(cascading_features, cascading_y)\n",
    "\n",
    "    def predict(self, cascading_features: np.array, sequences: np.array) -> np.array:\n",
    "        # we only support leave-one-out cross-validation (implementation detail):\n",
    "        assert(len(sequences) == 1)\n",
    "\n",
    "        # The binary cascading model:\n",
    "        #\n",
    "        # iteratively apply thread coarsening, using a new feature vector\n",
    "        # every time coarsening is applied\n",
    "        for i in range(len(cascading_features)):\n",
    "            # predict whether to coarsen, using the program features of\n",
    "            # the current coarsening level:\n",
    "            should_coarsen = self.model.predict([cascading_features[i]])[0]\n",
    "            if not should_coarsen:\n",
    "                break\n",
    "        p = cfs[i]\n",
    "        return [cfs[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Evaluating Magni et al. ...\", file=sys.stderr)\n",
    "# magni = evaluate(Magni())\n",
    "# magni.groupby('Platform')['Platform', 'Speedup', 'Oracle'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. DeepTune\n",
    "\n",
    "We predict thread coarsening factor directly from raw source code inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DeepTune(ThreadCoarseningModel):\n",
    "    __name__ = \"DeepTune\"\n",
    "    __basename__ = \"deeptune\"\n",
    "\n",
    "    def init(self, seed: int=None):\n",
    "        from keras.layers import Input, Embedding, LSTM, Dense, Conv1D, GlobalMaxPooling1D\n",
    "        from keras.layers.normalization import BatchNormalization\n",
    "        from keras.models import Model, Sequential, load_model\n",
    "    \n",
    "        np.random.seed(seed)\n",
    "    \n",
    "        # Vocabulary has a padding character\n",
    "        vocab_size = atomizer.vocab_size + 1\n",
    "\n",
    "        # Language model. Takes as inputs source code sequences.\n",
    "        seq_inputs = Input(shape=(1024,), dtype=\"int32\")\n",
    "        x = Embedding(input_dim=vocab_size, input_length=1024,\n",
    "                      output_dim=64, name=\"embedding\")(seq_inputs)\n",
    "        # x = LSTM(64, return_sequences=True, implementation=1, name=\"lstm_1\")(x)\n",
    "        # x = LSTM(64, implementation=1, name=\"lstm_2\")(x)\n",
    "        x = Conv1D(32, 9, name=\"conv_1\")(x)\n",
    "        x = Conv1D(32, 9, name=\"conv_2\")(x)\n",
    "        x = GlobalMaxPooling1D()(x)\n",
    "        \n",
    "        # Heuristic model. Takes as inputs the language model,\n",
    "        #   outputs 1-of-6 thread coarsening factor\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dense(32, activation=\"relu\")(x)\n",
    "        outputs = Dense(6, activation=\"sigmoid\")(x)\n",
    "\n",
    "        self.model = Model(inputs=seq_inputs, outputs=outputs)\n",
    "        self.model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "    def save(self, outpath: str):\n",
    "        self.model.save(outpath)\n",
    "\n",
    "    def restore(self, inpath: str):\n",
    "        self.model = load_model(inpath)\n",
    "        \n",
    "    def train(self, cascading_features: np.array, cascading_y: np.array,\n",
    "              sequences: np.array, y_1hot: np.array, verbose: bool=False) -> None:\n",
    "        self.model.fit(sequences, y_1hot, epochs=50, batch_size=64, verbose=verbose, shuffle=True)\n",
    "\n",
    "    def predict(self, cascading_features: np.array, sequences: np.array) -> np.array:\n",
    "        # directly predict optimal thread coarsening factor from source sequences:\n",
    "        p = np.array(self.model.predict(sequences, batch_size=64, verbose=0))\n",
    "        indices = [np.argmax(x) for x in p]\n",
    "        return [cfs[x] for x in indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview of the DeepTune model, showing the number of parameters in each layer, used to construct Table 5 in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:63: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:492: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3630: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1208: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2880: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2884: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 1024, 64)          8256      \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv1D)              (None, 1016, 32)          18464     \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv1D)              (None, 1008, 32)          9248      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 37,350\n",
      "Trainable params: 37,286\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deeptune_model = DeepTune()\n",
    "deeptune_model.init(seed)\n",
    "deeptune_model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<svg height=\"636pt\" viewBox=\"0.00 0.00 564.00 636.00\" width=\"564pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 632)\">\n<title>G</title>\n<polygon fill=\"white\" points=\"-4,4 -4,-632 560,-632 560,4 -4,4\" stroke=\"none\"/>\n<!-- 140343783177872 -->\n<g class=\"node\" id=\"node1\"><title>140343783177872</title>\n<polygon fill=\"none\" points=\"109,-581.5 109,-627.5 447,-627.5 447,-581.5 109,-581.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"189\" y=\"-600.8\">input_1: InputLayer</text>\n<polyline fill=\"none\" points=\"269,-581.5 269,-627.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"303\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"269,-604.5 337,-604.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"303\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"337,-581.5 337,-627.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"392\" y=\"-612.3\">(None, 1024)</text>\n<polyline fill=\"none\" points=\"337,-604.5 447,-604.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"392\" y=\"-589.3\">(None, 1024)</text>\n</g>\n<!-- 140343160957200 -->\n<g class=\"node\" id=\"node2\"><title>140343160957200</title>\n<polygon fill=\"none\" points=\"82,-498.5 82,-544.5 474,-544.5 474,-498.5 82,-498.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"175.5\" y=\"-517.8\">embedding: Embedding</text>\n<polyline fill=\"none\" points=\"269,-498.5 269,-544.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"303\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"269,-521.5 337,-521.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"303\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"337,-498.5 337,-544.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-529.3\">(None, 1024)</text>\n<polyline fill=\"none\" points=\"337,-521.5 474,-521.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-506.3\">(None, 1024, 64)</text>\n</g>\n<!-- 140343783177872&#45;&gt;140343160957200 -->\n<g class=\"edge\" id=\"edge1\"><title>140343783177872-&gt;140343160957200</title>\n<path d=\"M278,-581.366C278,-573.152 278,-563.658 278,-554.725\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"281.5,-554.607 278,-544.607 274.5,-554.607 281.5,-554.607\" stroke=\"black\"/>\n</g>\n<!-- 140343160035920 -->\n<g class=\"node\" id=\"node3\"><title>140343160035920</title>\n<polygon fill=\"none\" points=\"109,-415.5 109,-461.5 447,-461.5 447,-415.5 109,-415.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"175.5\" y=\"-434.8\">conv_1: Conv1D</text>\n<polyline fill=\"none\" points=\"242,-415.5 242,-461.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"242,-438.5 310,-438.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"310,-415.5 310,-461.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"378.5\" y=\"-446.3\">(None, 1024, 64)</text>\n<polyline fill=\"none\" points=\"310,-438.5 447,-438.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"378.5\" y=\"-423.3\">(None, 1016, 32)</text>\n</g>\n<!-- 140343160957200&#45;&gt;140343160035920 -->\n<g class=\"edge\" id=\"edge2\"><title>140343160957200-&gt;140343160035920</title>\n<path d=\"M278,-498.366C278,-490.152 278,-480.658 278,-471.725\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"281.5,-471.607 278,-461.607 274.5,-471.607 281.5,-471.607\" stroke=\"black\"/>\n</g>\n<!-- 140343160077648 -->\n<g class=\"node\" id=\"node4\"><title>140343160077648</title>\n<polygon fill=\"none\" points=\"109,-332.5 109,-378.5 447,-378.5 447,-332.5 109,-332.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"175.5\" y=\"-351.8\">conv_2: Conv1D</text>\n<polyline fill=\"none\" points=\"242,-332.5 242,-378.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"242,-355.5 310,-355.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"310,-332.5 310,-378.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"378.5\" y=\"-363.3\">(None, 1016, 32)</text>\n<polyline fill=\"none\" points=\"310,-355.5 447,-355.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"378.5\" y=\"-340.3\">(None, 1008, 32)</text>\n</g>\n<!-- 140343160035920&#45;&gt;140343160077648 -->\n<g class=\"edge\" id=\"edge3\"><title>140343160035920-&gt;140343160077648</title>\n<path d=\"M278,-415.366C278,-407.152 278,-397.658 278,-388.725\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"281.5,-388.607 278,-378.607 274.5,-388.607 281.5,-388.607\" stroke=\"black\"/>\n</g>\n<!-- 140343159631440 -->\n<g class=\"node\" id=\"node5\"><title>140343159631440</title>\n<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 556,-295.5 556,-249.5 0,-249.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"175.5\" y=\"-268.8\">global_max_pooling1d_1: GlobalMaxPooling1D</text>\n<polyline fill=\"none\" points=\"351,-249.5 351,-295.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"385\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"351,-272.5 419,-272.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"385\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"419,-249.5 419,-295.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"487.5\" y=\"-280.3\">(None, 1008, 32)</text>\n<polyline fill=\"none\" points=\"419,-272.5 556,-272.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"487.5\" y=\"-257.3\">(None, 32)</text>\n</g>\n<!-- 140343160077648&#45;&gt;140343159631440 -->\n<g class=\"edge\" id=\"edge4\"><title>140343160077648-&gt;140343159631440</title>\n<path d=\"M278,-332.366C278,-324.152 278,-314.658 278,-305.725\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"281.5,-305.607 278,-295.607 274.5,-305.607 281.5,-305.607\" stroke=\"black\"/>\n</g>\n<!-- 140343159805136 -->\n<g class=\"node\" id=\"node6\"><title>140343159805136</title>\n<polygon fill=\"none\" points=\"32,-166.5 32,-212.5 524,-212.5 524,-166.5 32,-166.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198\" y=\"-185.8\">batch_normalization_1: BatchNormalization</text>\n<polyline fill=\"none\" points=\"364,-166.5 364,-212.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"398\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"364,-189.5 432,-189.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"398\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"432,-166.5 432,-212.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"478\" y=\"-197.3\">(None, 32)</text>\n<polyline fill=\"none\" points=\"432,-189.5 524,-189.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"478\" y=\"-174.3\">(None, 32)</text>\n</g>\n<!-- 140343159631440&#45;&gt;140343159805136 -->\n<g class=\"edge\" id=\"edge5\"><title>140343159631440-&gt;140343159805136</title>\n<path d=\"M278,-249.366C278,-241.152 278,-231.658 278,-222.725\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"281.5,-222.607 278,-212.607 274.5,-222.607 281.5,-222.607\" stroke=\"black\"/>\n</g>\n<!-- 140343151107920 -->\n<g class=\"node\" id=\"node7\"><title>140343151107920</title>\n<polygon fill=\"none\" points=\"134,-83.5 134,-129.5 422,-129.5 422,-83.5 134,-83.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198\" y=\"-102.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"262,-83.5 262,-129.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"262,-106.5 330,-106.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"330,-83.5 330,-129.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"376\" y=\"-114.3\">(None, 32)</text>\n<polyline fill=\"none\" points=\"330,-106.5 422,-106.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"376\" y=\"-91.3\">(None, 32)</text>\n</g>\n<!-- 140343159805136&#45;&gt;140343151107920 -->\n<g class=\"edge\" id=\"edge6\"><title>140343159805136-&gt;140343151107920</title>\n<path d=\"M278,-166.366C278,-158.152 278,-148.658 278,-139.725\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"281.5,-139.607 278,-129.607 274.5,-139.607 281.5,-139.607\" stroke=\"black\"/>\n</g>\n<!-- 140343150743440 -->\n<g class=\"node\" id=\"node8\"><title>140343150743440</title>\n<polygon fill=\"none\" points=\"134,-0.5 134,-46.5 422,-46.5 422,-0.5 134,-0.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198\" y=\"-19.8\">dense_2: Dense</text>\n<polyline fill=\"none\" points=\"262,-0.5 262,-46.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"262,-23.5 330,-23.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"330,-0.5 330,-46.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"376\" y=\"-31.3\">(None, 32)</text>\n<polyline fill=\"none\" points=\"330,-23.5 422,-23.5 \" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"376\" y=\"-8.3\">(None, 6)</text>\n</g>\n<!-- 140343151107920&#45;&gt;140343150743440 -->\n<g class=\"edge\" id=\"edge7\"><title>140343151107920-&gt;140343150743440</title>\n<path d=\"M278,-83.3664C278,-75.1516 278,-65.6579 278,-56.7252\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"281.5,-56.6068 278,-46.6068 274.5,-56.6069 281.5,-56.6068\" stroke=\"black\"/>\n</g>\n</g>\n</svg>",
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def isnotebook():\n",
    "    # written by @mtd http://stackoverflow.com/a/39662359\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':  # Jupyter notebook or qtconsole?\n",
    "            return True\n",
    "        elif shell == 'TerminalInteractiveShell':  # Terminal running IPython?\n",
    "            return False\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "\n",
    "\n",
    "img = None\n",
    "if isnotebook():\n",
    "    from keras.utils.vis_utils import model_to_dot\n",
    "    from IPython.display import SVG\n",
    "    img = SVG(model_to_dot(deeptune_model.model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DeepTune ...\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/ipykernel_launcher.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:953: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:675: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 11:28:40.980963: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-12-14 11:28:41.015051: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz\n",
      "2022-12-14 11:28:41.018379: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x64e67f0 executing computations on platform Host. Devices:\n",
      "2022-12-14 11:28:41.018473: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2022-12-14 11:28:43.363364: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 5s 327ms/step - loss: 1.7890 - acc: 0.1250\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.7201 - acc: 0.3125\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6741 - acc: 0.3125\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6487 - acc: 0.3125\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.6283 - acc: 0.3125\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.6157 - acc: 0.3125\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.6017 - acc: 0.3125\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5923 - acc: 0.3125\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5837 - acc: 0.3125\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5764 - acc: 0.3125\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5683 - acc: 0.3125\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5619 - acc: 0.3125\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5553 - acc: 0.3125\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5481 - acc: 0.3125\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5412 - acc: 0.3125\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5347 - acc: 0.3125\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5280 - acc: 0.3125\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5211 - acc: 0.3125\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5149 - acc: 0.3125\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5097 - acc: 0.3125\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5047 - acc: 0.3125\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4996 - acc: 0.3125\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4948 - acc: 0.3125\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4895 - acc: 0.3125\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.4850 - acc: 0.3125\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.4808 - acc: 0.3125\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4767 - acc: 0.3125\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4726 - acc: 0.3750\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4687 - acc: 0.3750\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4648 - acc: 0.3750\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4611 - acc: 0.3750\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4575 - acc: 0.3750\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4541 - acc: 0.3750\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4507 - acc: 0.3750\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4473 - acc: 0.3750\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4440 - acc: 0.3750\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4408 - acc: 0.3750\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4376 - acc: 0.3750\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4345 - acc: 0.3750\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4315 - acc: 0.3750\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4285 - acc: 0.3750\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4257 - acc: 0.3750\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4229 - acc: 0.3750\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4202 - acc: 0.3750\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4176 - acc: 0.3750\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4151 - acc: 0.3750\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4126 - acc: 0.3750\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4102 - acc: 0.3750\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4078 - acc: 0.3750\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4055 - acc: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 68) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 5s 284ms/step - loss: 1.7902 - acc: 0.1250\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.7446 - acc: 0.1875\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.6914 - acc: 0.3750\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.6608 - acc: 0.3750\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.6326 - acc: 0.3750\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.6113 - acc: 0.3750\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.5907 - acc: 0.3750\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5703 - acc: 0.4375\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5539 - acc: 0.4375\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.5399 - acc: 0.4375\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.5270 - acc: 0.4375\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.5159 - acc: 0.4375\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5040 - acc: 0.4375\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 1.4947 - acc: 0.4375\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 1.4855 - acc: 0.4375\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.4770 - acc: 0.4375\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 1.4690 - acc: 0.4375\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 1.4604 - acc: 0.4375\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4523 - acc: 0.4375\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4443 - acc: 0.4375\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4364 - acc: 0.4375\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4289 - acc: 0.4375\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4226 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4158 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4095 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4032 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3971 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3914 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3856 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3802 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3751 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3702 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3655 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3608 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3564 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3521 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3481 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3441 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3407 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3369 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3334 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3302 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3270 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3239 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3210 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3182 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3154 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3127 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3102 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3077 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2% (2 of 68) |                         | Elapsed Time: 0:00:29 ETA:   0:16:19"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 4s 280ms/step - loss: 1.7890 - acc: 0.1250\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.7112 - acc: 0.3125\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.6687 - acc: 0.3125\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.6434 - acc: 0.3125\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.6247 - acc: 0.3125\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.6121 - acc: 0.3125\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.6005 - acc: 0.3125\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.5902 - acc: 0.3125\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.5810 - acc: 0.3125\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.5748 - acc: 0.3125\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.5669 - acc: 0.3125\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.5600 - acc: 0.3125\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.5528 - acc: 0.3125\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 1.5467 - acc: 0.3125\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.5403 - acc: 0.3125\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.5335 - acc: 0.3125\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.5265 - acc: 0.3125\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.5197 - acc: 0.3125\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1.5133 - acc: 0.3125\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.5075 - acc: 0.3125\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.5021 - acc: 0.3125\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 1.4969 - acc: 0.3125\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.4922 - acc: 0.3125\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.4868 - acc: 0.3125\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.4821 - acc: 0.3125\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.4776 - acc: 0.3750\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 1.4732 - acc: 0.3750\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 1.4692 - acc: 0.3750\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.4652 - acc: 0.3750\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 1.4613 - acc: 0.3750\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.4575 - acc: 0.3750\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.4538 - acc: 0.3750\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4503 - acc: 0.3750\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.4469 - acc: 0.3750\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.4436 - acc: 0.3750\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4403 - acc: 0.3750\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.4370 - acc: 0.3750\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4338 - acc: 0.3750\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1.4307 - acc: 0.3750\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.4276 - acc: 0.3750\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.4246 - acc: 0.3750\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.4216 - acc: 0.3750\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.4188 - acc: 0.3750\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4161 - acc: 0.3750\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.4134 - acc: 0.3750\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.4109 - acc: 0.3750\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4085 - acc: 0.3750\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.4061 - acc: 0.3750\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 1.4038 - acc: 0.3750\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 1.4016 - acc: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4% (3 of 68) |#                        | Elapsed Time: 0:01:07 ETA:   0:41:22"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 6s 390ms/step - loss: 1.7997 - acc: 0.1250\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.7167 - acc: 0.1875\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.6589 - acc: 0.4375\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6138 - acc: 0.4375\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5834 - acc: 0.4375\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.5655 - acc: 0.4375\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5506 - acc: 0.4375\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.5359 - acc: 0.4375\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5235 - acc: 0.4375\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.5124 - acc: 0.4375\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.5027 - acc: 0.4375\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4929 - acc: 0.4375\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4832 - acc: 0.4375\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.4742 - acc: 0.4375\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4658 - acc: 0.4375\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4576 - acc: 0.4375\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4494 - acc: 0.4375\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4412 - acc: 0.4375\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4324 - acc: 0.4375\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4245 - acc: 0.4375\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4170 - acc: 0.4375\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4095 - acc: 0.4375\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4024 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3957 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3891 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3825 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3764 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3706 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.3649 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3593 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3544 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3493 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3446 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3403 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3362 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3323 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3287 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3252 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3219 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3188 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3157 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3129 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3103 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3078 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3055 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3033 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3011 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.2991 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.2972 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2954 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5% (4 of 68) |#                        | Elapsed Time: 0:01:42 ETA:   0:36:45"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 7s 422ms/step - loss: 1.7918 - acc: 0.0625\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.7150 - acc: 0.1875\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.6653 - acc: 0.3750\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.6343 - acc: 0.3750\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.6117 - acc: 0.3750\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5995 - acc: 0.3750\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5846 - acc: 0.3750\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5735 - acc: 0.3750\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5616 - acc: 0.3750\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5513 - acc: 0.3750\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5423 - acc: 0.3750\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5336 - acc: 0.3750\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5248 - acc: 0.3750\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5167 - acc: 0.3750\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5088 - acc: 0.3750\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5003 - acc: 0.3125\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4921 - acc: 0.3125\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4844 - acc: 0.3125\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.4765 - acc: 0.3125\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4689 - acc: 0.3125\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4615 - acc: 0.3750\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4545 - acc: 0.3750\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4479 - acc: 0.3750\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4414 - acc: 0.3750\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4351 - acc: 0.3750\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4290 - acc: 0.3750\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.4230 - acc: 0.3750\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4171 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4117 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4063 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4011 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3958 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3908 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3858 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3809 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3763 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3717 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3672 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3629 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3588 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3548 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3509 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3473 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3438 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3408 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3377 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3346 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.3317 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3290 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3264 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7% (5 of 68) |#                        | Elapsed Time: 0:02:16 ETA:   0:35:53"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 6s 366ms/step - loss: 1.7894 - acc: 0.1250\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.7184 - acc: 0.1875\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.6727 - acc: 0.3125\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.6436 - acc: 0.3125\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.6249 - acc: 0.3125\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6092 - acc: 0.3125\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.6005 - acc: 0.3125\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5888 - acc: 0.3125\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5771 - acc: 0.3125\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.5697 - acc: 0.3125\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5615 - acc: 0.3125\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.5536 - acc: 0.3125\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.5447 - acc: 0.3125\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5374 - acc: 0.3125\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5298 - acc: 0.3125\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5224 - acc: 0.3125\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5157 - acc: 0.3125\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5097 - acc: 0.3125\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5030 - acc: 0.3125\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4970 - acc: 0.3125\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4911 - acc: 0.3125\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4854 - acc: 0.3125\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4797 - acc: 0.3125\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4739 - acc: 0.3125\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4687 - acc: 0.3125\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4634 - acc: 0.3125\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4582 - acc: 0.3125\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4532 - acc: 0.3125\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4485 - acc: 0.3750\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4440 - acc: 0.3750\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4396 - acc: 0.3750\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4352 - acc: 0.3750\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4311 - acc: 0.3750\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4271 - acc: 0.3750\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4230 - acc: 0.3750\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4191 - acc: 0.3750\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4153 - acc: 0.3750\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4117 - acc: 0.3750\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4081 - acc: 0.3750\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4043 - acc: 0.3750\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4008 - acc: 0.3750\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3974 - acc: 0.3750\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3941 - acc: 0.3750\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3909 - acc: 0.3750\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3877 - acc: 0.3750\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3845 - acc: 0.3750\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3815 - acc: 0.3750\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3786 - acc: 0.3750\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3758 - acc: 0.3750\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3731 - acc: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8% (6 of 68) |##                       | Elapsed Time: 0:02:46 ETA:   0:31:23"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 6s 386ms/step - loss: 1.7894 - acc: 0.1250\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.7264 - acc: 0.3750\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.6736 - acc: 0.3125\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.6447 - acc: 0.3125\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.6264 - acc: 0.3125\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.6132 - acc: 0.3125\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6003 - acc: 0.3125\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5890 - acc: 0.3125\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5782 - acc: 0.3125\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5705 - acc: 0.3125\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5623 - acc: 0.3125\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5528 - acc: 0.3125\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5448 - acc: 0.3125\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5372 - acc: 0.3125\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5299 - acc: 0.3125\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5236 - acc: 0.3125\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5164 - acc: 0.3125\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5105 - acc: 0.3125\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.5041 - acc: 0.3125\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4980 - acc: 0.3125\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4912 - acc: 0.3125\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4854 - acc: 0.3125\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4797 - acc: 0.3125\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4743 - acc: 0.3125\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4691 - acc: 0.3125\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4641 - acc: 0.3750\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4592 - acc: 0.3750\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4546 - acc: 0.3750\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.4502 - acc: 0.3750\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4459 - acc: 0.3750\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4416 - acc: 0.3750\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4375 - acc: 0.3750\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4334 - acc: 0.3750\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4294 - acc: 0.3750\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4255 - acc: 0.3750\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4215 - acc: 0.3750\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4178 - acc: 0.3750\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4141 - acc: 0.3750\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4105 - acc: 0.3750\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4070 - acc: 0.3750\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4035 - acc: 0.3750\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4001 - acc: 0.3750\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3970 - acc: 0.3750\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3939 - acc: 0.3750\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3909 - acc: 0.3750\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3880 - acc: 0.3750\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3852 - acc: 0.3750\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3826 - acc: 0.3750\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3801 - acc: 0.3750\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3776 - acc: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% (7 of 68) |##                       | Elapsed Time: 0:03:20 ETA:   0:33:52"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 9s 536ms/step - loss: 1.7894 - acc: 0.1250\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.7264 - acc: 0.3750\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.6736 - acc: 0.3125\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.6449 - acc: 0.3125\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.6254 - acc: 0.3125\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6129 - acc: 0.3125\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.5999 - acc: 0.3125\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5889 - acc: 0.3125\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5788 - acc: 0.3125\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5706 - acc: 0.3125\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5623 - acc: 0.3125\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5535 - acc: 0.3125\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 1.5446 - acc: 0.3125\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.5370 - acc: 0.3125\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5297 - acc: 0.3125\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5229 - acc: 0.3125\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5161 - acc: 0.3125\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5096 - acc: 0.3125\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.5034 - acc: 0.3125\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4970 - acc: 0.3125\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4910 - acc: 0.3125\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4851 - acc: 0.3125\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4796 - acc: 0.3125\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4742 - acc: 0.3125\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4690 - acc: 0.3125\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4638 - acc: 0.3125\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4592 - acc: 0.3750\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4544 - acc: 0.3750\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4501 - acc: 0.3750\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4460 - acc: 0.3750\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4417 - acc: 0.3750\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4376 - acc: 0.3750\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4335 - acc: 0.3750\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4296 - acc: 0.3750\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4256 - acc: 0.3750\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4217 - acc: 0.3750\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4178 - acc: 0.3750\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4141 - acc: 0.3750\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4104 - acc: 0.3750\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4067 - acc: 0.3750\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4033 - acc: 0.3750\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3999 - acc: 0.3750\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3966 - acc: 0.3750\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3933 - acc: 0.3750\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3903 - acc: 0.3750\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3873 - acc: 0.3750\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3845 - acc: 0.3750\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3818 - acc: 0.3750\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3793 - acc: 0.3750\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3768 - acc: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11% (8 of 68) |##                       | Elapsed Time: 0:03:57 ETA:   0:37:03"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 7s 451ms/step - loss: 1.7857 - acc: 0.1250\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.6981 - acc: 0.3750\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6399 - acc: 0.3750\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1.6017 - acc: 0.3125\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.5783 - acc: 0.3125\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5605 - acc: 0.3125\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 1.5466 - acc: 0.3125\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.5318 - acc: 0.3125\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5192 - acc: 0.3125\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.5103 - acc: 0.3125\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.5014 - acc: 0.3125\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4929 - acc: 0.3125\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4835 - acc: 0.3125\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4748 - acc: 0.3125\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4661 - acc: 0.3125\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4591 - acc: 0.3125\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4522 - acc: 0.3125\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4452 - acc: 0.3125\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4384 - acc: 0.3125\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4317 - acc: 0.3125\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4254 - acc: 0.3125\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4194 - acc: 0.3125\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4139 - acc: 0.3125\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4084 - acc: 0.3125\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4030 - acc: 0.3125\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3978 - acc: 0.3125\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3927 - acc: 0.3125\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3877 - acc: 0.3125\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3833 - acc: 0.3125\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3788 - acc: 0.3125\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3746 - acc: 0.3125\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3706 - acc: 0.3125\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3668 - acc: 0.3125\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3628 - acc: 0.3125\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3591 - acc: 0.3125\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3556 - acc: 0.3125\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3518 - acc: 0.3750\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3484 - acc: 0.3750\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3450 - acc: 0.3750\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3417 - acc: 0.3750\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3384 - acc: 0.3750\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3352 - acc: 0.3750\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3320 - acc: 0.3750\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3289 - acc: 0.3750\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3257 - acc: 0.3750\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3226 - acc: 0.3750\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3196 - acc: 0.3750\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3165 - acc: 0.3750\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3134 - acc: 0.3750\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3104 - acc: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13% (9 of 68) |###                      | Elapsed Time: 0:04:32 ETA:   0:35:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 7s 461ms/step - loss: 1.7911 - acc: 0.1250\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.7151 - acc: 0.4375\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.6655 - acc: 0.3750\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.6301 - acc: 0.3750\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6071 - acc: 0.3750\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.5909 - acc: 0.3750\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.5776 - acc: 0.3750\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.5652 - acc: 0.3750\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5540 - acc: 0.3125\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.5437 - acc: 0.3125\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5332 - acc: 0.3125\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5244 - acc: 0.3125\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.5155 - acc: 0.3125\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.5067 - acc: 0.3125\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4981 - acc: 0.3125\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4901 - acc: 0.3125\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4824 - acc: 0.3125\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4756 - acc: 0.3125\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4688 - acc: 0.3125\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4619 - acc: 0.3125\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4554 - acc: 0.3750\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4488 - acc: 0.3750\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4427 - acc: 0.3750\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4362 - acc: 0.3750\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4297 - acc: 0.3750\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4241 - acc: 0.3750\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.4186 - acc: 0.3750\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.4130 - acc: 0.3750\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4077 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4027 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3981 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3936 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3892 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3851 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3811 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3771 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3732 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3692 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3652 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3614 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3577 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3542 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3507 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3474 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3441 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3410 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3379 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3350 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3322 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3294 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14% (10 of 68) |###                     | Elapsed Time: 0:05:09 ETA:   0:34:56"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 7s 446ms/step - loss: 1.7910 - acc: 0.1250\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.7306 - acc: 0.4375\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.6784 - acc: 0.3750\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6472 - acc: 0.3750\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.6254 - acc: 0.3750\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.6103 - acc: 0.3750\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5982 - acc: 0.3750\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5876 - acc: 0.3750\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5783 - acc: 0.3750\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.5699 - acc: 0.3750\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5620 - acc: 0.3750\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5538 - acc: 0.3750\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5454 - acc: 0.3750\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5361 - acc: 0.3750\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5285 - acc: 0.3750\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5208 - acc: 0.3750\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5128 - acc: 0.4375\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5051 - acc: 0.4375\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4977 - acc: 0.4375\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4902 - acc: 0.4375\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4828 - acc: 0.4375\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4759 - acc: 0.4375\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4697 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4634 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4572 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4512 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4454 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4399 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4346 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4293 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4246 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4197 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4149 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4103 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4059 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4016 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3975 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3935 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3897 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3860 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3824 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3789 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3755 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3723 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3694 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3665 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.3636 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3609 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3583 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3558 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16% (11 of 68) |###                     | Elapsed Time: 0:05:46 ETA:   0:35:44"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 9s 585ms/step - loss: 1.7910 - acc: 0.1250\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.7208 - acc: 0.4375\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.6707 - acc: 0.3750\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.6408 - acc: 0.3750\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.6206 - acc: 0.3750\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.6051 - acc: 0.3750\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5944 - acc: 0.3750\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5845 - acc: 0.3750\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5752 - acc: 0.3750\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5676 - acc: 0.3750\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5597 - acc: 0.3750\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5510 - acc: 0.3750\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5429 - acc: 0.3750\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5355 - acc: 0.3750\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5284 - acc: 0.3750\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5199 - acc: 0.3750\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5116 - acc: 0.4375\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5043 - acc: 0.4375\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4975 - acc: 0.4375\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4905 - acc: 0.4375\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4833 - acc: 0.4375\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4763 - acc: 0.4375\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4697 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.4638 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4577 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4516 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4460 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4407 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4354 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4301 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4250 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4203 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4157 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4112 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4069 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4028 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3987 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3947 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3909 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3874 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3838 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3805 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3773 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3742 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3711 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3681 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3653 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3626 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3600 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3575 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17% (12 of 68) |####                    | Elapsed Time: 0:06:26 ETA:   0:36:37"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 8s 498ms/step - loss: 1.7918 - acc: 0.0625\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.7146 - acc: 0.1875\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.6647 - acc: 0.3750\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.6339 - acc: 0.3750\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.6129 - acc: 0.3750\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5997 - acc: 0.3750\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5860 - acc: 0.3750\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5756 - acc: 0.3750\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5629 - acc: 0.3750\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5520 - acc: 0.3125\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5430 - acc: 0.3750\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5343 - acc: 0.3750\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5267 - acc: 0.3750\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5178 - acc: 0.3750\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5094 - acc: 0.3750\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5018 - acc: 0.3125\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4937 - acc: 0.3125\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4856 - acc: 0.3125\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4777 - acc: 0.3125\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4700 - acc: 0.3125\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4626 - acc: 0.3125\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4554 - acc: 0.3750\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4486 - acc: 0.3750\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4420 - acc: 0.3750\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4357 - acc: 0.3750\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4294 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4236 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4179 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4124 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4069 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4015 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3962 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3911 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3862 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3813 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3766 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3721 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3676 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3632 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3592 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3553 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3514 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3479 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3445 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3413 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3381 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3351 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3322 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3295 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3267 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19% (13 of 68) |####                    | Elapsed Time: 0:07:00 ETA:   0:31:39"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 12s 736ms/step - loss: 1.7910 - acc: 0.1250\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.7306 - acc: 0.4375\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.6784 - acc: 0.3750\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.6490 - acc: 0.3750\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.6264 - acc: 0.3750\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.6114 - acc: 0.3750\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.5986 - acc: 0.3750\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.5878 - acc: 0.3750\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.5791 - acc: 0.3750\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.5704 - acc: 0.3750\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.5622 - acc: 0.3750\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.5540 - acc: 0.3750\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5446 - acc: 0.3750\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.5356 - acc: 0.3750\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.5288 - acc: 0.3750\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.5200 - acc: 0.4375\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.5123 - acc: 0.4375\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.5047 - acc: 0.4375\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.4968 - acc: 0.4375\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.4896 - acc: 0.4375\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4829 - acc: 0.4375\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4764 - acc: 0.4375\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.4701 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.4640 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4580 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4521 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4465 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.4412 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4361 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4313 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4268 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.4223 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4179 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4135 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4092 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4052 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4012 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3974 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3937 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3901 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3866 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3833 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3800 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3768 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3735 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3704 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3674 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3646 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3618 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3592 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% (14 of 68) |####                    | Elapsed Time: 0:07:52 ETA:   0:46:51"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 10s 631ms/step - loss: 1.7894 - acc: 0.1250\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.7181 - acc: 0.1875\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.6680 - acc: 0.3125\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.6419 - acc: 0.3125\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.6253 - acc: 0.3125\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.6095 - acc: 0.3125\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5988 - acc: 0.3125\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5877 - acc: 0.3125\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5766 - acc: 0.3125\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5698 - acc: 0.3125\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5621 - acc: 0.3125\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5518 - acc: 0.3125\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5443 - acc: 0.3125\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5362 - acc: 0.3125\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5284 - acc: 0.3125\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5220 - acc: 0.3125\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.5156 - acc: 0.3125\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5089 - acc: 0.3125\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.5028 - acc: 0.3125\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4970 - acc: 0.3125\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4913 - acc: 0.3125\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4849 - acc: 0.3125\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4794 - acc: 0.3125\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4731 - acc: 0.3125\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4678 - acc: 0.3125\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4626 - acc: 0.3125\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4575 - acc: 0.3125\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4528 - acc: 0.3750\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4483 - acc: 0.3750\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4437 - acc: 0.3750\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4392 - acc: 0.3750\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4348 - acc: 0.3750\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4306 - acc: 0.3750\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4265 - acc: 0.3750\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4225 - acc: 0.3750\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.4186 - acc: 0.3750\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4147 - acc: 0.3750\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1.4110 - acc: 0.3750\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1.4073 - acc: 0.3750\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 1.4037 - acc: 0.3750\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.4002 - acc: 0.3750\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3968 - acc: 0.3750\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3933 - acc: 0.3750\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3900 - acc: 0.3750\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3868 - acc: 0.3750\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3836 - acc: 0.3750\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3806 - acc: 0.3750\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3777 - acc: 0.3750\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3749 - acc: 0.3750\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3723 - acc: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22% (15 of 68) |#####                   | Elapsed Time: 0:08:37 ETA:   0:39:31"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 17s 1s/step - loss: 1.7911 - acc: 0.1250\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.7149 - acc: 0.4375\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.6659 - acc: 0.3750\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6303 - acc: 0.3750\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1.6076 - acc: 0.3750\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.5916 - acc: 0.3750\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5783 - acc: 0.3750\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5668 - acc: 0.3750\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5551 - acc: 0.3750\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5449 - acc: 0.3125\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5344 - acc: 0.3125\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.5262 - acc: 0.3125\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.5173 - acc: 0.3125\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 1.5081 - acc: 0.3125\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4997 - acc: 0.3125\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4916 - acc: 0.3125\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4838 - acc: 0.3125\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4766 - acc: 0.3125\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4698 - acc: 0.3125\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4629 - acc: 0.3750\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4563 - acc: 0.3750\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4499 - acc: 0.3750\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4433 - acc: 0.3750\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4368 - acc: 0.3750\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4307 - acc: 0.3750\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4249 - acc: 0.3750\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4191 - acc: 0.3750\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4137 - acc: 0.3750\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4086 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4035 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3985 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3940 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3897 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3856 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3814 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3774 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3733 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3693 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3653 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3615 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3577 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3541 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3506 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3472 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3440 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3409 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3378 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3349 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.3321 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3293 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23% (16 of 68) |#####                   | Elapsed Time: 0:09:26 ETA:   0:42:28"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 9s 558ms/step - loss: 1.7832 - acc: 0.1250\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.7278 - acc: 0.0625\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.6953 - acc: 0.3125\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.6689 - acc: 0.3125\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.6497 - acc: 0.3125\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.6435 - acc: 0.2500\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.6338 - acc: 0.2500\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.6247 - acc: 0.2500\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.6162 - acc: 0.2500\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6090 - acc: 0.2500\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.6025 - acc: 0.2500\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5967 - acc: 0.2500\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5909 - acc: 0.2500\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5854 - acc: 0.2500\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5803 - acc: 0.2500\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5750 - acc: 0.2500\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5698 - acc: 0.2500\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5649 - acc: 0.2500\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5601 - acc: 0.2500\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5556 - acc: 0.3125\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5513 - acc: 0.3125\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5469 - acc: 0.3125\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5425 - acc: 0.3125\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.5382 - acc: 0.2500\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5341 - acc: 0.2500\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.5300 - acc: 0.2500\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.5261 - acc: 0.2500\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5222 - acc: 0.2500\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.5183 - acc: 0.3125\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.5145 - acc: 0.3125\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.5108 - acc: 0.3125\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5070 - acc: 0.3125\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.5034 - acc: 0.3125\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.4999 - acc: 0.3125\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.4963 - acc: 0.3125\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4927 - acc: 0.3125\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4890 - acc: 0.3125\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4854 - acc: 0.3125\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4818 - acc: 0.3125\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4784 - acc: 0.3125\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4749 - acc: 0.3125\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4716 - acc: 0.3125\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4684 - acc: 0.3125\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4654 - acc: 0.3125\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4625 - acc: 0.3125\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4599 - acc: 0.3125\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4575 - acc: 0.3125\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4553 - acc: 0.3125\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4532 - acc: 0.3125\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.4512 - acc: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25% (17 of 68) |######                  | Elapsed Time: 0:10:07 ETA:   0:34:33/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/ipykernel_launcher.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 10s 631ms/step - loss: 1.7810 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.6667 - acc: 0.2500\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6032 - acc: 0.4375\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5738 - acc: 0.4375\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.5541 - acc: 0.4375\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5386 - acc: 0.4375\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5258 - acc: 0.4375\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5145 - acc: 0.4375\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5044 - acc: 0.4375\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4954 - acc: 0.4375\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4867 - acc: 0.4375\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4784 - acc: 0.4375\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4707 - acc: 0.4375\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4630 - acc: 0.4375\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4550 - acc: 0.4375\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4472 - acc: 0.4375\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4403 - acc: 0.4375\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4333 - acc: 0.4375\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4261 - acc: 0.4375\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4196 - acc: 0.4375\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4133 - acc: 0.4375\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4071 - acc: 0.4375\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4011 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3953 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3897 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3843 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3792 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3743 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3695 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3649 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3606 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3564 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3524 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3485 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3449 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3414 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3380 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3348 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3317 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3287 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3259 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3231 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3206 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3181 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3158 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3136 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3115 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3095 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3076 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3059 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26% (18 of 68) |######                  | Elapsed Time: 0:10:45 ETA:   0:32:20"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 9s 582ms/step - loss: 1.7703 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.6490 - acc: 0.3750\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5754 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5385 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5138 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4967 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4825 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4702 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4586 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4494 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4398 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4298 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4212 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4121 - acc: 0.5000\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4037 - acc: 0.5000\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3950 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3862 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3776 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3693 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3618 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3538 - acc: 0.5000\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3461 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3387 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3318 - acc: 0.5000\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3252 - acc: 0.5000\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3188 - acc: 0.5000\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3129 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3071 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3015 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2963 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2912 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2863 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.2816 - acc: 0.5000\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2770 - acc: 0.5000\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2726 - acc: 0.5000\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.2686 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2646 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2608 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2572 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2537 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2506 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2475 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2446 - acc: 0.5000\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2419 - acc: 0.5000\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2393 - acc: 0.5000\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.2369 - acc: 0.5000\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.2347 - acc: 0.5000\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.2325 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2305 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.2286 - acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27% (19 of 68) |######                  | Elapsed Time: 0:11:23 ETA:   0:30:48"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 9s 553ms/step - loss: 1.7716 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6469 - acc: 0.5000\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5805 - acc: 0.4375\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5488 - acc: 0.4375\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5231 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5051 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4877 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4724 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4588 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4458 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4334 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4208 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4110 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4016 - acc: 0.5000\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3925 - acc: 0.5000\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3836 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3748 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3661 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.3569 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3473 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3380 - acc: 0.5000\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3288 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3197 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3114 - acc: 0.5000\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3041 - acc: 0.5000\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2973 - acc: 0.5000\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2912 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2856 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2802 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2750 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2701 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2654 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2609 - acc: 0.5000\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2566 - acc: 0.5000\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2525 - acc: 0.5000\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2487 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2451 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2418 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.2386 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2357 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2329 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2303 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2278 - acc: 0.5000\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2255 - acc: 0.5000\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2233 - acc: 0.5000\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2212 - acc: 0.5000\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2194 - acc: 0.5000\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2177 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2160 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2145 - acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29% (20 of 68) |#######                 | Elapsed Time: 0:12:00 ETA:   0:29:43"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 11s 677ms/step - loss: 1.7810 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6663 - acc: 0.2500\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.6081 - acc: 0.4375\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5768 - acc: 0.4375\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5546 - acc: 0.4375\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5386 - acc: 0.4375\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5263 - acc: 0.4375\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5153 - acc: 0.4375\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5055 - acc: 0.4375\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4970 - acc: 0.4375\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4883 - acc: 0.4375\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4803 - acc: 0.4375\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4730 - acc: 0.4375\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4661 - acc: 0.4375\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4593 - acc: 0.4375\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4525 - acc: 0.4375\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4456 - acc: 0.4375\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4381 - acc: 0.4375\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4310 - acc: 0.4375\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4245 - acc: 0.4375\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4176 - acc: 0.4375\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4108 - acc: 0.4375\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4044 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3981 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3920 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3861 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3804 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.3751 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3700 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3651 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3605 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3561 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3519 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3478 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3440 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3404 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3370 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3337 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3306 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3276 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3249 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3222 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3197 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3173 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3149 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3127 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3105 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3085 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3066 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3049 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% (21 of 68) |#######                 | Elapsed Time: 0:12:40 ETA:   0:31:06"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 10s 623ms/step - loss: 1.7735 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6588 - acc: 0.4375\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5818 - acc: 0.4375\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5474 - acc: 0.4375\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5262 - acc: 0.4375\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5110 - acc: 0.4375\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4990 - acc: 0.4375\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4882 - acc: 0.4375\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4785 - acc: 0.4375\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4699 - acc: 0.4375\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4620 - acc: 0.4375\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4542 - acc: 0.4375\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.4469 - acc: 0.4375\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4398 - acc: 0.4375\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4328 - acc: 0.4375\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4262 - acc: 0.4375\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4195 - acc: 0.4375\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4127 - acc: 0.4375\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4063 - acc: 0.4375\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4000 - acc: 0.4375\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3939 - acc: 0.4375\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3880 - acc: 0.4375\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3821 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3764 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3711 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3659 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3613 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3564 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3520 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3478 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.3438 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3400 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3363 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3329 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.3297 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3267 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3238 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3211 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3185 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3161 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.3138 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.3117 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3097 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3079 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3062 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3046 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3030 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3016 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3003 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2990 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32% (22 of 68) |#######                 | Elapsed Time: 0:13:25 ETA:   0:34:39"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 19s 1s/step - loss: 1.7718 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.6390 - acc: 0.5000\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5455 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5034 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4762 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4544 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4335 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.4158 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 1.4005 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3861 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3719 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3574 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3444 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3311 - acc: 0.5000\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.3191 - acc: 0.5000\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.3079 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.2975 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2877 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.2782 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2691 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.2602 - acc: 0.5000\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.2522 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.2446 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2375 - acc: 0.5000\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.2306 - acc: 0.5000\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.2240 - acc: 0.5000\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.2178 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.2121 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.2066 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 1.2014 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1.1965 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.1917 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.1874 - acc: 0.5000\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.1833 - acc: 0.5000\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1793 - acc: 0.5000\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 1.1756 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.1720 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.1687 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.1657 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1628 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.1601 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1576 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1552 - acc: 0.5000\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1530 - acc: 0.5000\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.1509 - acc: 0.5000\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.1489 - acc: 0.5000\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.1470 - acc: 0.5000\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.1453 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.1437 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.1422 - acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33% (23 of 68) |########                | Elapsed Time: 0:14:31 ETA:   0:49:06"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 15s 929ms/step - loss: 1.7735 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.6589 - acc: 0.4375\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5818 - acc: 0.4375\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5472 - acc: 0.4375\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5257 - acc: 0.4375\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5111 - acc: 0.3125\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4995 - acc: 0.4375\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4886 - acc: 0.4375\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4785 - acc: 0.4375\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4700 - acc: 0.4375\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4621 - acc: 0.4375\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4547 - acc: 0.4375\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4473 - acc: 0.4375\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4402 - acc: 0.4375\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4332 - acc: 0.4375\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4263 - acc: 0.4375\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4196 - acc: 0.4375\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4130 - acc: 0.4375\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4062 - acc: 0.4375\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3995 - acc: 0.4375\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3935 - acc: 0.4375\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3877 - acc: 0.4375\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3819 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3763 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3708 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3656 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3607 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3560 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3515 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3473 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3433 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3396 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3359 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1.3326 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3294 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3263 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3235 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3208 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3183 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3159 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3137 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3116 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3097 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3078 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3062 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3046 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3030 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3016 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3003 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2990 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35% (24 of 68) |########                | Elapsed Time: 0:15:21 ETA:   0:37:09"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 12s 777ms/step - loss: 1.7716 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.6605 - acc: 0.5000\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5812 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5461 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5250 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5091 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4960 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4848 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4744 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4647 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4561 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4474 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4394 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4318 - acc: 0.5000\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4244 - acc: 0.5000\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4172 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4099 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4024 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3954 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3885 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3818 - acc: 0.5000\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3754 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3692 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3632 - acc: 0.5000\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3574 - acc: 0.5000\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3519 - acc: 0.5000\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3466 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3414 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3362 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3312 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3263 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3215 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3169 - acc: 0.5000\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3122 - acc: 0.5000\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3076 - acc: 0.5000\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3032 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2990 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2949 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2909 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2869 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2831 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2794 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2759 - acc: 0.5000\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2724 - acc: 0.5000\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.2690 - acc: 0.5000\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2658 - acc: 0.5000\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.2627 - acc: 0.5000\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.2597 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2568 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2540 - acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36% (25 of 68) |########                | Elapsed Time: 0:16:10 ETA:   0:35:15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 14s 901ms/step - loss: 1.7734 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.6421 - acc: 0.5000\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5685 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5367 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5145 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4954 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4812 - acc: 0.3125\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4681 - acc: 0.3125\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4568 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4461 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4355 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4250 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4148 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4051 - acc: 0.5000\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3957 - acc: 0.5000\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3865 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3773 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3686 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3603 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.3522 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3428 - acc: 0.5000\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3337 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3241 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3148 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3062 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2979 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2899 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2823 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2752 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2684 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2620 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2557 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2498 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.2443 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2389 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.2339 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.2291 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2245 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2201 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2158 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2117 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2077 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2039 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2003 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.1968 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1934 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1902 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1871 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.1842 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.1814 - acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38% (26 of 68) |#########               | Elapsed Time: 0:17:03 ETA:   0:37:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 17s 1s/step - loss: 1.7735 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6405 - acc: 0.4375\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5723 - acc: 0.4375\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5418 - acc: 0.4375\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5208 - acc: 0.4375\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.5068 - acc: 0.3125\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4943 - acc: 0.4375\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4837 - acc: 0.4375\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4747 - acc: 0.4375\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4664 - acc: 0.4375\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4586 - acc: 0.4375\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4509 - acc: 0.4375\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4434 - acc: 0.4375\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4364 - acc: 0.4375\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4296 - acc: 0.4375\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4228 - acc: 0.4375\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4160 - acc: 0.4375\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4094 - acc: 0.4375\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4031 - acc: 0.4375\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3970 - acc: 0.4375\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3914 - acc: 0.4375\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3859 - acc: 0.4375\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3806 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3756 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3706 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3655 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3607 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3561 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3517 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3475 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3437 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3401 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3366 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.3332 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3301 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3271 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3243 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3217 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3192 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.3168 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3146 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3125 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3106 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.3087 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 1.3070 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 1.3053 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.3037 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3023 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3008 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2995 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39% (27 of 68) |#########               | Elapsed Time: 0:18:02 ETA:   0:40:02"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 10s 629ms/step - loss: 1.7742 - acc: 0.1250\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6429 - acc: 0.5000\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5704 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5373 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5176 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5020 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4888 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4772 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4672 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4585 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4502 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4420 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4340 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4266 - acc: 0.5000\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4192 - acc: 0.5000\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4119 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4048 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3979 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3911 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3847 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3785 - acc: 0.5000\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3727 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3673 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3620 - acc: 0.5000\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3568 - acc: 0.5000\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3516 - acc: 0.5000\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3465 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3414 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3368 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3319 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3274 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3232 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3191 - acc: 0.5000\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3150 - acc: 0.5000\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3111 - acc: 0.5000\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3074 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3039 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3007 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2976 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2945 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2915 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2886 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2859 - acc: 0.5000\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.2833 - acc: 0.5000\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2807 - acc: 0.5000\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2781 - acc: 0.5000\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2756 - acc: 0.5000\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2732 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2709 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.2686 - acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41% (28 of 68) |#########               | Elapsed Time: 0:18:48 ETA:   0:30:39"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 19s 1s/step - loss: 1.7742 - acc: 0.1250\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6617 - acc: 0.5000\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.5792 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 1.5442 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 1.5226 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5063 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4934 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4817 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4718 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4632 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4546 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4464 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4386 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4313 - acc: 0.5000\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4241 - acc: 0.5000\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4171 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4102 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4033 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3962 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.3886 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3812 - acc: 0.5000\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3742 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3677 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3616 - acc: 0.5000\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.3559 - acc: 0.5000\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3505 - acc: 0.5000\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3454 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3404 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3354 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3306 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3260 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3215 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3171 - acc: 0.5000\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3130 - acc: 0.5000\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3091 - acc: 0.5000\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3054 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3020 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2987 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2955 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.2925 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.2897 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1.2868 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 1.2841 - acc: 0.5000\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.2814 - acc: 0.5000\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.2787 - acc: 0.5000\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 1.2761 - acc: 0.5000\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.2735 - acc: 0.5000\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.2710 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.2687 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.2664 - acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42% (29 of 68) |##########              | Elapsed Time: 0:20:03 ETA:   0:48:31"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 19s 1s/step - loss: 1.7735 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.6403 - acc: 0.4375\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.5776 - acc: 0.4375\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.5444 - acc: 0.4375\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.5235 - acc: 0.3125\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5090 - acc: 0.3125\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4968 - acc: 0.4375\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4859 - acc: 0.4375\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4761 - acc: 0.4375\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.4675 - acc: 0.4375\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.4593 - acc: 0.4375\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.4514 - acc: 0.4375\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.4443 - acc: 0.4375\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.4371 - acc: 0.4375\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.4301 - acc: 0.4375\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.4232 - acc: 0.4375\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4166 - acc: 0.4375\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4100 - acc: 0.4375\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.4037 - acc: 0.4375\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.3977 - acc: 0.4375\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.3919 - acc: 0.4375\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.3863 - acc: 0.4375\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 1.3810 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 1.3759 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 1.3710 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 1.3662 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 1.3617 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 1.3573 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.3531 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.3492 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.3454 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.3417 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.3382 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.3349 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 1.3318 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.3288 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.3260 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 1.3234 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.3209 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.3185 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 1.3162 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.3140 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.3120 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.3100 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1.3082 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 1.3064 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.3047 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.3031 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1.3015 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.2999 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44% (30 of 68) |##########              | Elapsed Time: 0:21:26 ETA:   0:52:56"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 17s 1s/step - loss: 1.7716 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6411 - acc: 0.5000\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5729 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.5402 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.5206 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.5051 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4927 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.4812 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.4710 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4613 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.4526 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.4445 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4371 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4298 - acc: 0.5000\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.4224 - acc: 0.5000\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4151 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4079 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4007 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3937 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3869 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3801 - acc: 0.5000\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3734 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3668 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3605 - acc: 0.5000\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3542 - acc: 0.5000\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.3481 - acc: 0.5000\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.3422 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3366 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3309 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3254 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3201 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3152 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3103 - acc: 0.5000\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3053 - acc: 0.5000\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3004 - acc: 0.5000\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.2958 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2913 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.2868 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.2826 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.2786 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.2748 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.2710 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2675 - acc: 0.5000\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2642 - acc: 0.5000\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2610 - acc: 0.5000\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.2580 - acc: 0.5000\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2551 - acc: 0.5000\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.2523 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2497 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.2472 - acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45% (31 of 68) |##########              | Elapsed Time: 0:22:35 ETA:   0:42:42"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 17s 1s/step - loss: 1.7742 - acc: 0.1250\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.6616 - acc: 0.5000\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5852 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5490 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1.5253 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.5086 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 1.4959 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4838 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4734 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4644 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4561 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4478 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.4402 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.4326 - acc: 0.5000\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4250 - acc: 0.5000\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4175 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4100 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4028 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3959 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3890 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3821 - acc: 0.5000\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3753 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3685 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.3619 - acc: 0.5000\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.3560 - acc: 0.5000\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3506 - acc: 0.5000\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3453 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3401 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3350 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3301 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3253 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3207 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3162 - acc: 0.5000\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.3118 - acc: 0.5000\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.3077 - acc: 0.5000\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3039 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3003 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.2969 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.2936 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.2904 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.2874 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.2844 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2816 - acc: 0.5000\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.2788 - acc: 0.5000\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.2762 - acc: 0.5000\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.2735 - acc: 0.5000\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.2710 - acc: 0.5000\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.2685 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1.2661 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.2638 - acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47% (32 of 68) |###########             | Elapsed Time: 0:23:42 ETA:   0:39:39"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 22s 1s/step - loss: 1.7735 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.6401 - acc: 0.4375\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5725 - acc: 0.4375\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5415 - acc: 0.4375\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5205 - acc: 0.4375\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5066 - acc: 0.3125\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4944 - acc: 0.4375\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4838 - acc: 0.4375\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4746 - acc: 0.4375\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.4660 - acc: 0.4375\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4576 - acc: 0.4375\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4499 - acc: 0.4375\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4425 - acc: 0.4375\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4355 - acc: 0.4375\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4286 - acc: 0.4375\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.4217 - acc: 0.4375\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4149 - acc: 0.4375\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4082 - acc: 0.4375\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.4022 - acc: 0.4375\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3963 - acc: 0.4375\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3906 - acc: 0.4375\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3851 - acc: 0.4375\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.3798 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.3748 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3699 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3653 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3608 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3564 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3523 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3484 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3447 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3411 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3377 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3345 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3314 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.3284 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3256 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3230 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3205 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3181 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3158 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3137 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3117 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3097 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3079 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3062 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3045 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3029 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3013 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2998 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48% (33 of 68) |###########             | Elapsed Time: 0:24:58 ETA:   0:44:25"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 22s 1s/step - loss: 1.7729 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.6467 - acc: 0.4375\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.5929 - acc: 0.4375\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.5613 - acc: 0.4375\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5436 - acc: 0.4375\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5309 - acc: 0.4375\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.5199 - acc: 0.4375\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5112 - acc: 0.4375\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5032 - acc: 0.4375\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4959 - acc: 0.4375\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 1.4892 - acc: 0.4375\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4831 - acc: 0.4375\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4766 - acc: 0.4375\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.4706 - acc: 0.4375\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.4648 - acc: 0.4375\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4593 - acc: 0.4375\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4541 - acc: 0.4375\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4491 - acc: 0.4375\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4444 - acc: 0.4375\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4398 - acc: 0.4375\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.4355 - acc: 0.4375\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.4313 - acc: 0.4375\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.4273 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4233 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4194 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4156 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4118 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4081 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4044 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4008 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3972 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3937 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3903 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3870 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3837 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3805 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3775 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3745 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3716 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3690 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3665 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3643 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3622 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.3603 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3586 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3571 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3556 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3541 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3527 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3514 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% (34 of 68) |############            | Elapsed Time: 0:26:14 ETA:   0:43:00/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/ipykernel_launcher.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 21s 1s/step - loss: 1.7957 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.7612 - acc: 0.2500\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.7016 - acc: 0.4375\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.6641 - acc: 0.4375\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.6476 - acc: 0.3125\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6314 - acc: 0.3125\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6152 - acc: 0.3125\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.5996 - acc: 0.3125\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.5862 - acc: 0.4375\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.5771 - acc: 0.4375\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.5682 - acc: 0.4375\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5583 - acc: 0.4375\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5493 - acc: 0.4375\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.5397 - acc: 0.4375\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.5318 - acc: 0.4375\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.5234 - acc: 0.4375\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5143 - acc: 0.4375\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.5065 - acc: 0.4375\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4986 - acc: 0.4375\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.4910 - acc: 0.4375\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4833 - acc: 0.4375\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.4749 - acc: 0.4375\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.4664 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4585 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4506 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.4432 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 1.4355 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.4279 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4206 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.4136 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4066 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.3995 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.3931 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3869 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3810 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.3754 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3702 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3653 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3607 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3564 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3522 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3483 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3447 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3414 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3383 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3353 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3324 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3297 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3272 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3247 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51% (35 of 68) |############            | Elapsed Time: 0:27:35 ETA:   0:44:42"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 19s 1s/step - loss: 1.7930 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.7543 - acc: 0.3125\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.7097 - acc: 0.3750\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.6921 - acc: 0.3750\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.6771 - acc: 0.3750\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.6632 - acc: 0.3750\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.6513 - acc: 0.3750\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.6424 - acc: 0.3750\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.6346 - acc: 0.3750\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.6257 - acc: 0.3750\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6182 - acc: 0.3750\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.6107 - acc: 0.3750\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6043 - acc: 0.3750\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5977 - acc: 0.3750\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5907 - acc: 0.3750\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5840 - acc: 0.3750\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5795 - acc: 0.3750\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5739 - acc: 0.3750\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5684 - acc: 0.3750\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5625 - acc: 0.3750\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5562 - acc: 0.3750\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5505 - acc: 0.3750\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5454 - acc: 0.3750\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5400 - acc: 0.3750\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5342 - acc: 0.3750\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5285 - acc: 0.3750\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5222 - acc: 0.3750\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5164 - acc: 0.3750\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5110 - acc: 0.3750\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5056 - acc: 0.3750\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5002 - acc: 0.3750\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4949 - acc: 0.3750\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4897 - acc: 0.3750\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4843 - acc: 0.3750\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4792 - acc: 0.3750\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4740 - acc: 0.3750\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4686 - acc: 0.3750\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4632 - acc: 0.3750\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4579 - acc: 0.3750\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4529 - acc: 0.3750\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4477 - acc: 0.3750\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4425 - acc: 0.3750\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4376 - acc: 0.3750\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4327 - acc: 0.3750\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4279 - acc: 0.3750\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4232 - acc: 0.3750\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4187 - acc: 0.3750\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4146 - acc: 0.3750\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4106 - acc: 0.3750\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4068 - acc: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52% (36 of 68) |############            | Elapsed Time: 0:28:40 ETA:   0:34:35"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 14s 901ms/step - loss: 1.8051 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.7712 - acc: 0.0625\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6882 - acc: 0.3125\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.6465 - acc: 0.3125\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.6211 - acc: 0.3125\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.6024 - acc: 0.3125\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5846 - acc: 0.3750\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5718 - acc: 0.3750\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.5611 - acc: 0.3750\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.5508 - acc: 0.3750\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.5422 - acc: 0.3750\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.5327 - acc: 0.3750\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5252 - acc: 0.3750\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5185 - acc: 0.3750\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5114 - acc: 0.3750\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5037 - acc: 0.3750\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4950 - acc: 0.3750\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4860 - acc: 0.3750\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4781 - acc: 0.3750\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4697 - acc: 0.3750\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4615 - acc: 0.3750\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4541 - acc: 0.3750\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4458 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4370 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4296 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4225 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4146 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4074 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.4005 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3940 - acc: 0.3750\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3873 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3806 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3745 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3685 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3627 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3571 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3517 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3465 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3414 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3364 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3316 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3271 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3228 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3189 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3154 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3121 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3090 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3059 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3029 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3000 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54% (37 of 68) |#############           | Elapsed Time: 0:29:38 ETA:   0:30:08"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 16s 1s/step - loss: 1.7930 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.7475 - acc: 0.3125\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.7079 - acc: 0.3750\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.7022 - acc: 0.3750\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6829 - acc: 0.3750\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.6626 - acc: 0.3750\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.6535 - acc: 0.3750\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.6455 - acc: 0.3750\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.6369 - acc: 0.3750\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.6289 - acc: 0.3750\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6209 - acc: 0.3750\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.6138 - acc: 0.3750\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6066 - acc: 0.3750\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.6000 - acc: 0.3750\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5936 - acc: 0.3750\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5871 - acc: 0.3750\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5807 - acc: 0.3750\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5745 - acc: 0.3750\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.5689 - acc: 0.3750\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.5629 - acc: 0.3750\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5570 - acc: 0.3750\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5503 - acc: 0.3750\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5440 - acc: 0.3750\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5380 - acc: 0.3750\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5318 - acc: 0.3750\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5253 - acc: 0.3750\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5193 - acc: 0.3750\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5128 - acc: 0.3750\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5063 - acc: 0.3750\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5003 - acc: 0.3750\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4941 - acc: 0.3750\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4882 - acc: 0.3750\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4818 - acc: 0.3750\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4758 - acc: 0.3750\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4702 - acc: 0.3750\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4645 - acc: 0.3750\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4587 - acc: 0.3750\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4531 - acc: 0.3750\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4476 - acc: 0.3750\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4424 - acc: 0.3750\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4374 - acc: 0.3750\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4325 - acc: 0.3750\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4279 - acc: 0.3750\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4235 - acc: 0.3750\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4192 - acc: 0.3750\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4153 - acc: 0.3750\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4115 - acc: 0.3750\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4081 - acc: 0.3750\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4047 - acc: 0.3750\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4016 - acc: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55% (38 of 68) |#############           | Elapsed Time: 0:30:38 ETA:   0:29:41"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 21s 1s/step - loss: 1.7961 - acc: 0.1250\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.7788 - acc: 0.0625\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.7228 - acc: 0.3125\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.7017 - acc: 0.3125\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.6801 - acc: 0.3125\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.6554 - acc: 0.3125\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6348 - acc: 0.3750\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.6240 - acc: 0.3750\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.6147 - acc: 0.3750\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6055 - acc: 0.3750\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5961 - acc: 0.4375\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5880 - acc: 0.4375\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5803 - acc: 0.4375\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5726 - acc: 0.4375\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5654 - acc: 0.4375\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5579 - acc: 0.4375\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5506 - acc: 0.4375\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5434 - acc: 0.4375\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5362 - acc: 0.4375\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5286 - acc: 0.4375\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5211 - acc: 0.4375\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5135 - acc: 0.4375\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5068 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5000 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4926 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4859 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4796 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4736 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4678 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4619 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4561 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4503 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4446 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4392 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4337 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4283 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4230 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4179 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4129 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4082 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4035 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3990 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3948 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3907 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3867 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3829 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3792 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3757 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3723 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3691 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57% (39 of 68) |#############           | Elapsed Time: 0:31:44 ETA:   0:32:06"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 18s 1s/step - loss: 1.7953 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.7613 - acc: 0.0625\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.7035 - acc: 0.3125\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6630 - acc: 0.4375\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6323 - acc: 0.4375\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.6071 - acc: 0.3125\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5875 - acc: 0.3125\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5727 - acc: 0.4375\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5607 - acc: 0.4375\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5512 - acc: 0.4375\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5422 - acc: 0.4375\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5335 - acc: 0.4375\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5250 - acc: 0.4375\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5170 - acc: 0.4375\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5092 - acc: 0.4375\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5020 - acc: 0.4375\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4959 - acc: 0.4375\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4876 - acc: 0.4375\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4807 - acc: 0.4375\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4744 - acc: 0.4375\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4681 - acc: 0.4375\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4614 - acc: 0.4375\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4543 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4474 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4404 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4335 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4267 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4199 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4129 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.4061 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3996 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3933 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3873 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3814 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3757 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3702 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3649 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3596 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3544 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3497 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3454 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3413 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3373 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3335 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3298 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3263 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3231 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3201 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.3173 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3146 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58% (40 of 68) |##############          | Elapsed Time: 0:32:48 ETA:   0:29:53"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 20s 1s/step - loss: 1.7961 - acc: 0.1250\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.7791 - acc: 0.0625\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.7159 - acc: 0.3750\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6968 - acc: 0.3750\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.6689 - acc: 0.3750\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.6425 - acc: 0.4375\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.6269 - acc: 0.4375\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.6116 - acc: 0.4375\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.6013 - acc: 0.3750\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5921 - acc: 0.3750\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.5830 - acc: 0.4375\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5747 - acc: 0.4375\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5660 - acc: 0.4375\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5571 - acc: 0.4375\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5496 - acc: 0.4375\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5420 - acc: 0.4375\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.5345 - acc: 0.4375\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5262 - acc: 0.4375\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5180 - acc: 0.4375\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5096 - acc: 0.4375\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.5014 - acc: 0.4375\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4939 - acc: 0.4375\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4867 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4800 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4737 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4671 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4613 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4554 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4494 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4435 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4375 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4321 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4266 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4213 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4161 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.4110 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4060 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4012 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3967 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3922 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3879 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3838 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3799 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3763 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3729 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3696 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3664 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3634 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3607 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3581 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% (41 of 68) |##############          | Elapsed Time: 0:33:55 ETA:   0:30:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 20s 1s/step - loss: 1.7937 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.7733 - acc: 0.0625\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.7006 - acc: 0.3750\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.6596 - acc: 0.3125\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 1.6343 - acc: 0.3125\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.6147 - acc: 0.3750\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.5947 - acc: 0.4375\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.5777 - acc: 0.4375\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.5648 - acc: 0.4375\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5536 - acc: 0.4375\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.5441 - acc: 0.4375\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.5349 - acc: 0.4375\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.5261 - acc: 0.4375\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5174 - acc: 0.4375\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5092 - acc: 0.4375\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5002 - acc: 0.4375\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4911 - acc: 0.4375\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4830 - acc: 0.4375\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4756 - acc: 0.4375\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4685 - acc: 0.4375\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4612 - acc: 0.4375\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4538 - acc: 0.4375\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4464 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4393 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4323 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4256 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4194 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4135 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4075 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4015 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3957 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3902 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3846 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3792 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3741 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3691 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3642 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3595 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3550 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3505 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3465 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3424 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3384 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3350 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3314 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3280 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3249 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3219 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3190 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3163 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61% (42 of 68) |##############          | Elapsed Time: 0:35:08 ETA:   0:31:47"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 13s 831ms/step - loss: 1.7953 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.7528 - acc: 0.0625\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6956 - acc: 0.3125\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6557 - acc: 0.4375\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6227 - acc: 0.3125\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5995 - acc: 0.3125\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5826 - acc: 0.3125\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5684 - acc: 0.4375\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5558 - acc: 0.4375\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5465 - acc: 0.4375\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5381 - acc: 0.4375\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5300 - acc: 0.4375\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5214 - acc: 0.4375\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5132 - acc: 0.4375\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5054 - acc: 0.4375\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4978 - acc: 0.4375\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4906 - acc: 0.4375\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4837 - acc: 0.4375\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4770 - acc: 0.4375\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4707 - acc: 0.4375\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4644 - acc: 0.4375\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4581 - acc: 0.4375\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4517 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4455 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4391 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4325 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4261 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4198 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4132 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4069 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4006 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3944 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3884 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3827 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3773 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3722 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3673 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3625 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3578 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3533 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3488 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3446 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3405 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3366 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3331 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3298 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3265 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3234 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3205 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3178 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63% (43 of 68) |###############         | Elapsed Time: 0:35:55 ETA:   0:19:36"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 12s 756ms/step - loss: 1.7954 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.7683 - acc: 0.0625\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.7204 - acc: 0.3125\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.7006 - acc: 0.3125\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6816 - acc: 0.2500\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6629 - acc: 0.3125\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6502 - acc: 0.3125\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6401 - acc: 0.3125\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.6297 - acc: 0.3125\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6201 - acc: 0.3125\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6105 - acc: 0.3125\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.6020 - acc: 0.3125\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5936 - acc: 0.3125\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5864 - acc: 0.3125\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5791 - acc: 0.3750\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5727 - acc: 0.3750\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5657 - acc: 0.3750\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5586 - acc: 0.3750\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5524 - acc: 0.3750\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5461 - acc: 0.3750\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5394 - acc: 0.3750\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5340 - acc: 0.3750\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5275 - acc: 0.3750\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5205 - acc: 0.3750\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5145 - acc: 0.3750\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5087 - acc: 0.3750\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5024 - acc: 0.3750\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4963 - acc: 0.3750\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4903 - acc: 0.3750\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4845 - acc: 0.3750\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4787 - acc: 0.3750\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4728 - acc: 0.3750\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4668 - acc: 0.3750\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4608 - acc: 0.3750\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4549 - acc: 0.3750\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4493 - acc: 0.3750\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4437 - acc: 0.3750\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4383 - acc: 0.3750\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4333 - acc: 0.3750\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4280 - acc: 0.3750\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4232 - acc: 0.3750\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4185 - acc: 0.3750\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4138 - acc: 0.3750\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4094 - acc: 0.3750\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4052 - acc: 0.3750\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4011 - acc: 0.3750\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3973 - acc: 0.3750\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3935 - acc: 0.3750\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3899 - acc: 0.3750\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3864 - acc: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64% (44 of 68) |###############         | Elapsed Time: 0:36:39 ETA:   0:17:29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 12s 777ms/step - loss: 1.7954 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.7677 - acc: 0.0625\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.7198 - acc: 0.3125\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.7016 - acc: 0.3125\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.6821 - acc: 0.2500\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6647 - acc: 0.2500\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6503 - acc: 0.3125\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6396 - acc: 0.3125\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.6315 - acc: 0.3125\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6219 - acc: 0.3125\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6114 - acc: 0.3125\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.6020 - acc: 0.3125\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5937 - acc: 0.3125\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5861 - acc: 0.3750\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5794 - acc: 0.3750\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5732 - acc: 0.3750\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5670 - acc: 0.3750\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5602 - acc: 0.3750\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5535 - acc: 0.3750\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5466 - acc: 0.3750\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5396 - acc: 0.3750\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5335 - acc: 0.3750\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5273 - acc: 0.3750\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5206 - acc: 0.3125\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5148 - acc: 0.3750\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5086 - acc: 0.3750\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5029 - acc: 0.3750\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4969 - acc: 0.3750\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4904 - acc: 0.3750\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4844 - acc: 0.3750\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4786 - acc: 0.3750\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4730 - acc: 0.3750\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4673 - acc: 0.3750\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4616 - acc: 0.3750\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4557 - acc: 0.3750\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4500 - acc: 0.3750\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4443 - acc: 0.3750\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4389 - acc: 0.3750\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4336 - acc: 0.3750\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4285 - acc: 0.3750\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4236 - acc: 0.3750\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4190 - acc: 0.3750\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4144 - acc: 0.3750\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4100 - acc: 0.3750\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4058 - acc: 0.3750\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4017 - acc: 0.3750\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3978 - acc: 0.3750\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3940 - acc: 0.3750\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3904 - acc: 0.3750\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3870 - acc: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66% (45 of 68) |###############         | Elapsed Time: 0:37:24 ETA:   0:17:21"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 12s 781ms/step - loss: 1.7961 - acc: 0.1250\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.7792 - acc: 0.0625\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.7162 - acc: 0.3750\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.6972 - acc: 0.3750\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.6699 - acc: 0.3125\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.6421 - acc: 0.4375\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.6274 - acc: 0.4375\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.6129 - acc: 0.4375\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6012 - acc: 0.4375\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5923 - acc: 0.4375\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5845 - acc: 0.3750\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5765 - acc: 0.4375\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5676 - acc: 0.4375\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5584 - acc: 0.4375\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5498 - acc: 0.4375\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5416 - acc: 0.4375\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5348 - acc: 0.4375\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5274 - acc: 0.4375\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5195 - acc: 0.4375\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5125 - acc: 0.4375\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5048 - acc: 0.4375\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4962 - acc: 0.4375\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4893 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4827 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4758 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4694 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4632 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4572 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4513 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4455 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4396 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4339 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4282 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4228 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4176 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4126 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4077 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4028 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3981 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3935 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3893 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3852 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3813 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3776 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3741 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3708 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3676 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3645 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3617 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3589 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67% (46 of 68) |################        | Elapsed Time: 0:38:11 ETA:   0:17:12"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 14s 870ms/step - loss: 1.7937 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.7736 - acc: 0.0625\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.7011 - acc: 0.3750\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.6587 - acc: 0.3125\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.6339 - acc: 0.3125\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6154 - acc: 0.3750\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.5959 - acc: 0.4375\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5786 - acc: 0.4375\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5653 - acc: 0.4375\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5541 - acc: 0.4375\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5445 - acc: 0.4375\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5351 - acc: 0.4375\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5263 - acc: 0.4375\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5175 - acc: 0.4375\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5093 - acc: 0.4375\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4999 - acc: 0.4375\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4914 - acc: 0.4375\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4835 - acc: 0.4375\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4762 - acc: 0.4375\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4687 - acc: 0.4375\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4614 - acc: 0.4375\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4540 - acc: 0.4375\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4466 - acc: 0.4375\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4396 - acc: 0.4375\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4330 - acc: 0.4375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4262 - acc: 0.4375\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4197 - acc: 0.4375\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4137 - acc: 0.4375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4076 - acc: 0.4375\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4017 - acc: 0.4375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3956 - acc: 0.4375\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3897 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3844 - acc: 0.4375\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3790 - acc: 0.4375\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3736 - acc: 0.4375\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3684 - acc: 0.4375\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3633 - acc: 0.4375\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3584 - acc: 0.4375\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3539 - acc: 0.4375\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3495 - acc: 0.4375\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3452 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3412 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3374 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3337 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3304 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3271 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3240 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3211 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3184 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3158 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69% (47 of 68) |################        | Elapsed Time: 0:39:06 ETA:   0:19:12"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 13s 796ms/step - loss: 1.7900 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.7707 - acc: 0.0625\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.6898 - acc: 0.3750\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.6648 - acc: 0.3750\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.6294 - acc: 0.3125\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6083 - acc: 0.3125\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5933 - acc: 0.3125\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5808 - acc: 0.3125\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5679 - acc: 0.3125\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5549 - acc: 0.3125\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5440 - acc: 0.3125\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5341 - acc: 0.3125\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5252 - acc: 0.3125\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5165 - acc: 0.3125\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5080 - acc: 0.3125\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4996 - acc: 0.3125\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4913 - acc: 0.3125\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4833 - acc: 0.3125\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4756 - acc: 0.3750\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4686 - acc: 0.3125\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4614 - acc: 0.3750\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4540 - acc: 0.3750\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4472 - acc: 0.3750\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4411 - acc: 0.3750\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4346 - acc: 0.3750\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4280 - acc: 0.3750\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4212 - acc: 0.3750\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4148 - acc: 0.3750\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4088 - acc: 0.3750\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4023 - acc: 0.3750\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3957 - acc: 0.3750\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3893 - acc: 0.3750\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3832 - acc: 0.3750\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3769 - acc: 0.3750\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3704 - acc: 0.3750\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3639 - acc: 0.3750\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3576 - acc: 0.3750\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3514 - acc: 0.3750\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3450 - acc: 0.3750\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3391 - acc: 0.3750\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3333 - acc: 0.4375\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3274 - acc: 0.4375\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3216 - acc: 0.4375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3159 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3105 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3051 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2998 - acc: 0.4375\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2948 - acc: 0.4375\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2900 - acc: 0.4375\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.2853 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% (48 of 68) |################        | Elapsed Time: 0:39:51 ETA:   0:14:59"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 13s 825ms/step - loss: 1.7954 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.7682 - acc: 0.1250\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.7191 - acc: 0.3125\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.7021 - acc: 0.3125\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.6830 - acc: 0.2500\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.6654 - acc: 0.2500\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.6501 - acc: 0.3125\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6392 - acc: 0.3125\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.6311 - acc: 0.3125\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.6217 - acc: 0.3125\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6121 - acc: 0.3125\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.6028 - acc: 0.3125\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5942 - acc: 0.3125\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5871 - acc: 0.3750\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5813 - acc: 0.3750\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5749 - acc: 0.3750\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5685 - acc: 0.3750\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5616 - acc: 0.3750\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5546 - acc: 0.3750\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5474 - acc: 0.3750\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5406 - acc: 0.3750\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5348 - acc: 0.3125\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5287 - acc: 0.3125\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5232 - acc: 0.3125\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5171 - acc: 0.3125\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5101 - acc: 0.3125\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5045 - acc: 0.3125\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4990 - acc: 0.3750\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4926 - acc: 0.3750\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4864 - acc: 0.3750\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4811 - acc: 0.3750\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4754 - acc: 0.3750\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4693 - acc: 0.3750\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4633 - acc: 0.3750\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4578 - acc: 0.3750\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4520 - acc: 0.3750\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4463 - acc: 0.3750\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4410 - acc: 0.3750\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4358 - acc: 0.3750\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4304 - acc: 0.3750\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4252 - acc: 0.3750\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4206 - acc: 0.3750\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4160 - acc: 0.3750\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4116 - acc: 0.3750\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4073 - acc: 0.3750\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4031 - acc: 0.3750\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3991 - acc: 0.3750\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3952 - acc: 0.3750\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3916 - acc: 0.3750\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3881 - acc: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72% (49 of 68) |#################       | Elapsed Time: 0:40:38 ETA:   0:14:49"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 13s 826ms/step - loss: 1.7954 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.7682 - acc: 0.1250\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.7194 - acc: 0.3125\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.7015 - acc: 0.3125\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.6823 - acc: 0.2500\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6643 - acc: 0.2500\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.6497 - acc: 0.3125\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.6396 - acc: 0.3125\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6315 - acc: 0.3125\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.6226 - acc: 0.3125\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.6134 - acc: 0.3125\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.6038 - acc: 0.3125\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5951 - acc: 0.3125\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5877 - acc: 0.3750\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5815 - acc: 0.3750\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5753 - acc: 0.3750\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5690 - acc: 0.3750\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5625 - acc: 0.3750\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5557 - acc: 0.3750\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5487 - acc: 0.3750\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5418 - acc: 0.3750\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5354 - acc: 0.3750\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5290 - acc: 0.3125\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5228 - acc: 0.3125\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5169 - acc: 0.3125\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5110 - acc: 0.3125\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5046 - acc: 0.3750\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4985 - acc: 0.3750\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4927 - acc: 0.3750\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4872 - acc: 0.3750\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4813 - acc: 0.3750\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4753 - acc: 0.3750\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4700 - acc: 0.3750\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4645 - acc: 0.3750\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4588 - acc: 0.3750\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4531 - acc: 0.3750\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4473 - acc: 0.3750\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4419 - acc: 0.3750\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4369 - acc: 0.3750\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4318 - acc: 0.3750\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4266 - acc: 0.3750\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4216 - acc: 0.3750\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4170 - acc: 0.3750\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4125 - acc: 0.3750\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4081 - acc: 0.3750\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4038 - acc: 0.3750\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3998 - acc: 0.3750\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3959 - acc: 0.3750\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3924 - acc: 0.3750\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3888 - acc: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73% (50 of 68) |#################       | Elapsed Time: 0:41:26 ETA:   0:14:21"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 17s 1s/step - loss: 1.7850 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.7921 - acc: 0.0625\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.7300 - acc: 0.0625\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.7051 - acc: 0.3125\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6913 - acc: 0.3125\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.6786 - acc: 0.3125\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6632 - acc: 0.3125\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6531 - acc: 0.3125\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6431 - acc: 0.3125\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.6349 - acc: 0.3125\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.6271 - acc: 0.3125\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6178 - acc: 0.3125\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6093 - acc: 0.3125\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.6017 - acc: 0.3125\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5949 - acc: 0.3125\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5882 - acc: 0.3125\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5817 - acc: 0.3125\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5761 - acc: 0.3750\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5710 - acc: 0.3750\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5658 - acc: 0.3750\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5603 - acc: 0.3750\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5550 - acc: 0.3750\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5500 - acc: 0.3750\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5455 - acc: 0.3750\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5408 - acc: 0.3750\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5362 - acc: 0.3750\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5317 - acc: 0.3750\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5273 - acc: 0.3750\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5231 - acc: 0.3750\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5190 - acc: 0.3750\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.5149 - acc: 0.3750\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5107 - acc: 0.3750\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5067 - acc: 0.3750\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5027 - acc: 0.3750\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4990 - acc: 0.3750\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4953 - acc: 0.3750\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4917 - acc: 0.3750\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4881 - acc: 0.3750\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4846 - acc: 0.3750\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4811 - acc: 0.3750\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4778 - acc: 0.3750\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4746 - acc: 0.3750\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4716 - acc: 0.3750\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4687 - acc: 0.3750\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4661 - acc: 0.3750\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4637 - acc: 0.3750\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4614 - acc: 0.3750\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4594 - acc: 0.3750\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4574 - acc: 0.3750\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4554 - acc: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75% (51 of 68) |##################      | Elapsed Time: 0:42:19 ETA:   0:15:03/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/ipykernel_launcher.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 14s 892ms/step - loss: 1.7718 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.6712 - acc: 0.4375\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5958 - acc: 0.5625\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5501 - acc: 0.5625\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5161 - acc: 0.5625\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4871 - acc: 0.5625\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4648 - acc: 0.5625\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4482 - acc: 0.5625\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.4324 - acc: 0.5625\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4199 - acc: 0.5625\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4078 - acc: 0.5625\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3964 - acc: 0.5625\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3854 - acc: 0.5625\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.3745 - acc: 0.5625\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3648 - acc: 0.5625\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3551 - acc: 0.5625\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3454 - acc: 0.5625\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3361 - acc: 0.5625\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3267 - acc: 0.5625\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3171 - acc: 0.5625\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3080 - acc: 0.5625\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2993 - acc: 0.5625\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.2910 - acc: 0.5625\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2826 - acc: 0.5625\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2745 - acc: 0.5625\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.2668 - acc: 0.5625\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.2595 - acc: 0.5625\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.2524 - acc: 0.5625\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2455 - acc: 0.5625\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2388 - acc: 0.5625\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2322 - acc: 0.5625\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2260 - acc: 0.5625\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2200 - acc: 0.5625\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.2142 - acc: 0.5625\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2086 - acc: 0.5625\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2032 - acc: 0.5625\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.1979 - acc: 0.5625\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1929 - acc: 0.5625\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.1880 - acc: 0.5625\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.1834 - acc: 0.5625\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.1789 - acc: 0.5625\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.1747 - acc: 0.5625\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.1707 - acc: 0.5625\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.1669 - acc: 0.5625\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.1633 - acc: 0.5625\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.1600 - acc: 0.5625\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1568 - acc: 0.5625\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.1538 - acc: 0.5625\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1510 - acc: 0.5625\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.1484 - acc: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76% (52 of 68) |##################      | Elapsed Time: 0:43:07 ETA:   0:12:55"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 15s 935ms/step - loss: 1.7700 - acc: 0.2500\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.6690 - acc: 0.3125\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.6035 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5611 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5320 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5083 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4908 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4737 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4596 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4480 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4372 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4259 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4138 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4030 - acc: 0.5000\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3926 - acc: 0.5000\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3820 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3727 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3644 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3560 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3479 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3400 - acc: 0.5000\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3329 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3262 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3198 - acc: 0.5000\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3135 - acc: 0.5000\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3075 - acc: 0.5000\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3018 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2963 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2911 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2860 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2812 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2765 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2721 - acc: 0.5000\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2679 - acc: 0.5000\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.2638 - acc: 0.5000\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2600 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.2563 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2529 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2495 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.2464 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.2434 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2406 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2379 - acc: 0.5000\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2354 - acc: 0.5000\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2330 - acc: 0.5000\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2307 - acc: 0.5000\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2286 - acc: 0.5000\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2266 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2247 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2230 - acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77% (53 of 68) |##################      | Elapsed Time: 0:44:02 ETA:   0:13:47"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 15s 949ms/step - loss: 1.7579 - acc: 0.2500\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.6004 - acc: 0.4375\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5181 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4749 - acc: 0.5625\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4466 - acc: 0.5625\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4257 - acc: 0.5625\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4086 - acc: 0.5625\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3936 - acc: 0.5625\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3813 - acc: 0.5625\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3706 - acc: 0.5625\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3607 - acc: 0.5625\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3518 - acc: 0.5625\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3436 - acc: 0.5625\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3353 - acc: 0.5625\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3271 - acc: 0.5625\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3192 - acc: 0.5625\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3112 - acc: 0.5625\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3035 - acc: 0.5625\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.2955 - acc: 0.5625\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.2878 - acc: 0.5625\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2806 - acc: 0.5625\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2737 - acc: 0.5625\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2671 - acc: 0.5625\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2607 - acc: 0.5625\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2544 - acc: 0.5625\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2483 - acc: 0.5625\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2425 - acc: 0.5625\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2368 - acc: 0.5625\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2314 - acc: 0.5625\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2261 - acc: 0.5625\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2209 - acc: 0.5625\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.2159 - acc: 0.5625\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2111 - acc: 0.5625\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2064 - acc: 0.5625\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.2018 - acc: 0.5625\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1973 - acc: 0.5625\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.1930 - acc: 0.5625\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.1888 - acc: 0.5625\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.1846 - acc: 0.5625\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.1806 - acc: 0.5625\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.1768 - acc: 0.5625\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.1730 - acc: 0.5625\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.1694 - acc: 0.5625\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1659 - acc: 0.5625\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1626 - acc: 0.5625\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.1596 - acc: 0.5625\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1567 - acc: 0.5625\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1541 - acc: 0.5625\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1516 - acc: 0.5625\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1493 - acc: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79% (54 of 68) |###################     | Elapsed Time: 0:44:57 ETA:   0:12:42"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 17s 1s/step - loss: 1.7700 - acc: 0.2500\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.6690 - acc: 0.3125\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.6035 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5611 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5321 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5092 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4915 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4745 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4601 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4488 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4376 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4264 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4122 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4019 - acc: 0.5000\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3915 - acc: 0.5000\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3813 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3719 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3635 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3553 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3474 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3397 - acc: 0.5000\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3325 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3259 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3194 - acc: 0.5000\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3133 - acc: 0.5000\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3073 - acc: 0.5000\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3017 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2962 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2910 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2859 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2811 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2764 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2720 - acc: 0.5000\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2678 - acc: 0.5000\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2637 - acc: 0.5000\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2599 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2563 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2528 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2495 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2463 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2433 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2405 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2378 - acc: 0.5000\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2353 - acc: 0.5000\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2328 - acc: 0.5000\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2306 - acc: 0.5000\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2285 - acc: 0.5000\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2264 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2246 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2228 - acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% (55 of 68) |###################     | Elapsed Time: 0:45:52 ETA:   0:11:51"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 21s 1s/step - loss: 1.7625 - acc: 0.2500\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6382 - acc: 0.4375\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5647 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5237 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4971 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4766 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4576 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4427 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4306 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4205 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4102 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4000 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3923 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3835 - acc: 0.5000\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3750 - acc: 0.5000\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3665 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3587 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3516 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3447 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3380 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3317 - acc: 0.5000\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3257 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3197 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3137 - acc: 0.5000\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3078 - acc: 0.5000\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3023 - acc: 0.5000\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2970 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2917 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2867 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2820 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2774 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2730 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2689 - acc: 0.5000\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2650 - acc: 0.5000\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.2613 - acc: 0.5000\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2577 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2543 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2511 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2481 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2453 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2426 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2401 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2377 - acc: 0.5000\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2355 - acc: 0.5000\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2334 - acc: 0.5000\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2315 - acc: 0.5000\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2296 - acc: 0.5000\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2279 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2263 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2248 - acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82% (56 of 68) |###################     | Elapsed Time: 0:46:55 ETA:   0:12:39"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 17s 1s/step - loss: 1.7624 - acc: 0.2500\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.6302 - acc: 0.5000\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5491 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5054 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4732 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4471 - acc: 0.5625\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4227 - acc: 0.5625\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4039 - acc: 0.5625\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3863 - acc: 0.5625\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3699 - acc: 0.5625\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3561 - acc: 0.5625\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3432 - acc: 0.5625\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3310 - acc: 0.5625\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3195 - acc: 0.5625\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3085 - acc: 0.5625\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2972 - acc: 0.5625\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2863 - acc: 0.5625\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2758 - acc: 0.5625\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2651 - acc: 0.5625\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2538 - acc: 0.5625\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2431 - acc: 0.5625\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2331 - acc: 0.5625\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2232 - acc: 0.5625\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2143 - acc: 0.5625\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2058 - acc: 0.5625\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1979 - acc: 0.5625\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.1905 - acc: 0.5625\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1835 - acc: 0.5625\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1767 - acc: 0.5625\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1704 - acc: 0.5625\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1642 - acc: 0.5625\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1583 - acc: 0.5625\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1527 - acc: 0.5625\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1473 - acc: 0.5625\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1420 - acc: 0.5625\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1370 - acc: 0.5625\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1323 - acc: 0.5625\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1277 - acc: 0.5625\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1233 - acc: 0.5625\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1192 - acc: 0.5625\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1152 - acc: 0.5625\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.1114 - acc: 0.5625\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.1077 - acc: 0.5625\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1042 - acc: 0.5625\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1009 - acc: 0.5625\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.0977 - acc: 0.5625\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.0947 - acc: 0.5625\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.0918 - acc: 0.5625\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.0890 - acc: 0.5625\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.0864 - acc: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83% (57 of 68) |####################    | Elapsed Time: 0:47:57 ETA:   0:11:24"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 18s 1s/step - loss: 1.7625 - acc: 0.2500\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.6381 - acc: 0.4375\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5644 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5233 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4956 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4740 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4549 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4411 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4292 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4183 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4075 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3987 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3896 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3807 - acc: 0.5000\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3724 - acc: 0.5000\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3644 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3570 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3498 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3429 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3365 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3301 - acc: 0.5000\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3238 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3178 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3121 - acc: 0.5000\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3063 - acc: 0.5000\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3007 - acc: 0.5000\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2955 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2906 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2857 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2809 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2763 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2721 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2680 - acc: 0.5000\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2641 - acc: 0.5000\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2604 - acc: 0.5000\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2569 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2535 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2504 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2474 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2446 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2420 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2395 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2372 - acc: 0.5000\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2350 - acc: 0.5000\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2330 - acc: 0.5000\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2310 - acc: 0.5000\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2292 - acc: 0.5000\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2275 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2260 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2245 - acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85% (58 of 68) |####################    | Elapsed Time: 0:48:58 ETA:   0:10:05"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 17s 1s/step - loss: 1.7632 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.6383 - acc: 0.5000\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5570 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5144 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4855 - acc: 0.5625\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4598 - acc: 0.5625\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4413 - acc: 0.5625\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4240 - acc: 0.5625\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4092 - acc: 0.5625\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3964 - acc: 0.5625\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3862 - acc: 0.5625\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3751 - acc: 0.5625\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3654 - acc: 0.5625\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3550 - acc: 0.5625\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3454 - acc: 0.5625\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3340 - acc: 0.5625\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3226 - acc: 0.5625\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3125 - acc: 0.5625\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3037 - acc: 0.5625\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2955 - acc: 0.5625\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2877 - acc: 0.5625\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2800 - acc: 0.5625\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2731 - acc: 0.5625\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2665 - acc: 0.5625\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2603 - acc: 0.5625\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2543 - acc: 0.5625\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2484 - acc: 0.5625\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2426 - acc: 0.5625\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2371 - acc: 0.5625\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2318 - acc: 0.5625\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2267 - acc: 0.5625\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2218 - acc: 0.5625\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2173 - acc: 0.5625\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2131 - acc: 0.5625\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2090 - acc: 0.5625\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2052 - acc: 0.5625\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2015 - acc: 0.5625\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1982 - acc: 0.5625\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1950 - acc: 0.5625\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.1920 - acc: 0.5625\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.1892 - acc: 0.5625\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1866 - acc: 0.5625\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1842 - acc: 0.5625\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1819 - acc: 0.5625\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1799 - acc: 0.5625\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.1780 - acc: 0.5625\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1763 - acc: 0.5625\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1747 - acc: 0.5625\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1732 - acc: 0.5625\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1718 - acc: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86% (59 of 68) |####################    | Elapsed Time: 0:49:57 ETA:   0:08:53"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 17s 1s/step - loss: 1.7608 - acc: 0.2500\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.6122 - acc: 0.5000\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5143 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4674 - acc: 0.5625\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4331 - acc: 0.5625\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4049 - acc: 0.5625\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3799 - acc: 0.5625\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3593 - acc: 0.5625\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3420 - acc: 0.5625\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3269 - acc: 0.5625\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3137 - acc: 0.5625\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3020 - acc: 0.5625\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2909 - acc: 0.5625\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2808 - acc: 0.5625\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2694 - acc: 0.5625\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2587 - acc: 0.5625\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2488 - acc: 0.5625\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2397 - acc: 0.5625\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2304 - acc: 0.5625\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2215 - acc: 0.5625\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2132 - acc: 0.5625\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2052 - acc: 0.5625\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1974 - acc: 0.5625\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1902 - acc: 0.5625\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.1829 - acc: 0.5625\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1758 - acc: 0.5625\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1691 - acc: 0.5625\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1627 - acc: 0.5625\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1565 - acc: 0.5625\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1505 - acc: 0.5625\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1448 - acc: 0.5625\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1393 - acc: 0.5625\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1340 - acc: 0.5625\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1289 - acc: 0.5625\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1241 - acc: 0.5625\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1194 - acc: 0.5625\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.1149 - acc: 0.5625\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.1106 - acc: 0.5625\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1064 - acc: 0.5625\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1025 - acc: 0.5625\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.0987 - acc: 0.5625\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.0951 - acc: 0.5625\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.0917 - acc: 0.5625\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.0885 - acc: 0.5625\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.0855 - acc: 0.5625\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.0827 - acc: 0.5625\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.0800 - acc: 0.5625\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.0775 - acc: 0.5625\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.0751 - acc: 0.5625\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.0728 - acc: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88% (60 of 68) |#####################   | Elapsed Time: 0:50:59 ETA:   0:08:15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 18s 1s/step - loss: 1.7625 - acc: 0.2500\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.6387 - acc: 0.4375\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5653 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5245 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4973 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4764 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4571 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4419 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4299 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4194 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4087 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3994 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3910 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3824 - acc: 0.5000\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3739 - acc: 0.5000\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3654 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3578 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3509 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3441 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3373 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3310 - acc: 0.5000\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3248 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3188 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3127 - acc: 0.5000\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3070 - acc: 0.5000\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3017 - acc: 0.5000\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2965 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2913 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2865 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2818 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2772 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2729 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2687 - acc: 0.5000\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2648 - acc: 0.5000\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2611 - acc: 0.5000\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2576 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2542 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2510 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2480 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2451 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2425 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2400 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2377 - acc: 0.5000\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2355 - acc: 0.5000\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2334 - acc: 0.5000\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2314 - acc: 0.5000\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2296 - acc: 0.5000\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2279 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2263 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2248 - acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89% (61 of 68) |#####################   | Elapsed Time: 0:52:00 ETA:   0:07:08"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 19s 1s/step - loss: 1.7625 - acc: 0.2500\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.6382 - acc: 0.4375\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5650 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.5240 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4971 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4757 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4568 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4420 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4301 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4199 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4096 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3998 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3916 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3834 - acc: 0.5000\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3748 - acc: 0.5000\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3663 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3587 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3515 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3445 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3379 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3317 - acc: 0.5000\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3256 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3196 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3136 - acc: 0.5000\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3077 - acc: 0.5000\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3022 - acc: 0.5000\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2970 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2918 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2867 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2819 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2775 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2732 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2690 - acc: 0.5000\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2650 - acc: 0.5000\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2613 - acc: 0.5000\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2578 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2544 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2512 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2482 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2453 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2426 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2401 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2377 - acc: 0.5000\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2355 - acc: 0.5000\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2334 - acc: 0.5000\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2315 - acc: 0.5000\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2296 - acc: 0.5000\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2279 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2263 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2248 - acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91% (62 of 68) |#####################   | Elapsed Time: 0:53:04 ETA:   0:06:20"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 21s 1s/step - loss: 1.7632 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.6388 - acc: 0.5000\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5561 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5131 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4849 - acc: 0.5625\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4610 - acc: 0.5625\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4420 - acc: 0.5625\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4243 - acc: 0.5625\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4078 - acc: 0.5625\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3953 - acc: 0.5625\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3838 - acc: 0.5625\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3741 - acc: 0.5625\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3644 - acc: 0.5625\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.3535 - acc: 0.5625\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3425 - acc: 0.5625\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3333 - acc: 0.5625\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3243 - acc: 0.5625\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3157 - acc: 0.5625\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3074 - acc: 0.5625\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2997 - acc: 0.5625\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2927 - acc: 0.5625\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2860 - acc: 0.5625\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2791 - acc: 0.5625\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2724 - acc: 0.5625\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2658 - acc: 0.5625\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2598 - acc: 0.5625\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2540 - acc: 0.5625\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2483 - acc: 0.5625\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2428 - acc: 0.5625\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2373 - acc: 0.5625\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2322 - acc: 0.5625\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2274 - acc: 0.5625\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2227 - acc: 0.5625\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2181 - acc: 0.5625\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2138 - acc: 0.5625\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2098 - acc: 0.5625\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2059 - acc: 0.5625\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2022 - acc: 0.5625\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1987 - acc: 0.5625\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1956 - acc: 0.5625\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.1927 - acc: 0.5625\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.1900 - acc: 0.5625\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1875 - acc: 0.5625\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.1852 - acc: 0.5625\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1830 - acc: 0.5625\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1809 - acc: 0.5625\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.1791 - acc: 0.5625\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.1773 - acc: 0.5625\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.1757 - acc: 0.5625\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.1742 - acc: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92% (63 of 68) |######################  | Elapsed Time: 0:54:20 ETA:   0:06:21"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 23s 1s/step - loss: 1.7625 - acc: 0.2500\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6383 - acc: 0.4375\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.5622 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5204 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4931 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4714 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.4530 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4387 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4264 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4147 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4042 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3955 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3867 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3780 - acc: 0.5000\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3699 - acc: 0.5000\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3622 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3547 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3474 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3405 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3341 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3280 - acc: 0.5000\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3218 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3158 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3099 - acc: 0.5000\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3043 - acc: 0.5000\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2988 - acc: 0.5000\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2935 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2884 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2835 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2788 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2742 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.2699 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2658 - acc: 0.5000\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.2619 - acc: 0.5000\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2582 - acc: 0.5000\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2547 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2514 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.2483 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2453 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2426 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2399 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2375 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2352 - acc: 0.5000\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.2330 - acc: 0.5000\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2309 - acc: 0.5000\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.2290 - acc: 0.5000\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2273 - acc: 0.5000\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2256 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.2240 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2226 - acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94% (64 of 68) |######################  | Elapsed Time: 0:55:34 ETA:   0:04:54"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 19s 1s/step - loss: 1.7606 - acc: 0.2500\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.6383 - acc: 0.5000\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5571 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5104 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4753 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4524 - acc: 0.5625\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4285 - acc: 0.5625\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4106 - acc: 0.5625\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3940 - acc: 0.5625\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3783 - acc: 0.5625\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3641 - acc: 0.5625\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3515 - acc: 0.5625\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3399 - acc: 0.5625\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3288 - acc: 0.5625\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3182 - acc: 0.5625\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3080 - acc: 0.5625\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2978 - acc: 0.5625\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2876 - acc: 0.5625\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2775 - acc: 0.5625\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2663 - acc: 0.5625\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2559 - acc: 0.5625\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2457 - acc: 0.5625\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2355 - acc: 0.5625\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2260 - acc: 0.5625\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2175 - acc: 0.5625\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2097 - acc: 0.5625\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2020 - acc: 0.5625\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1946 - acc: 0.5625\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1873 - acc: 0.5625\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1801 - acc: 0.5625\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1732 - acc: 0.5625\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1667 - acc: 0.5625\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1605 - acc: 0.5625\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1545 - acc: 0.5625\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1487 - acc: 0.5625\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1431 - acc: 0.5625\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1380 - acc: 0.5625\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.1330 - acc: 0.5625\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1282 - acc: 0.5625\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1235 - acc: 0.5625\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1192 - acc: 0.5625\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1150 - acc: 0.5625\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1113 - acc: 0.5625\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1076 - acc: 0.5625\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1042 - acc: 0.5625\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1007 - acc: 0.5625\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.0975 - acc: 0.5625\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.0945 - acc: 0.5625\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.0917 - acc: 0.5625\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.0889 - acc: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95% (65 of 68) |######################  | Elapsed Time: 0:56:40 ETA:   0:03:19"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 22s 1s/step - loss: 1.7632 - acc: 0.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.6386 - acc: 0.5000\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5571 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5144 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4853 - acc: 0.5625\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4598 - acc: 0.5625\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4413 - acc: 0.5625\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4240 - acc: 0.5625\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4092 - acc: 0.5625\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3971 - acc: 0.5625\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3858 - acc: 0.5625\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3751 - acc: 0.5625\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3659 - acc: 0.5625\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3567 - acc: 0.5625\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3462 - acc: 0.5625\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3365 - acc: 0.5625\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3251 - acc: 0.5625\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3144 - acc: 0.5625\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3049 - acc: 0.5625\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2965 - acc: 0.5625\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2883 - acc: 0.5625\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2807 - acc: 0.5625\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2735 - acc: 0.5625\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2667 - acc: 0.5625\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2604 - acc: 0.5625\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2543 - acc: 0.5625\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2484 - acc: 0.5625\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2428 - acc: 0.5625\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2374 - acc: 0.5625\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2322 - acc: 0.5625\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2272 - acc: 0.5625\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2224 - acc: 0.5625\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2179 - acc: 0.5625\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2137 - acc: 0.5625\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2097 - acc: 0.5625\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2059 - acc: 0.5625\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2023 - acc: 0.5625\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1990 - acc: 0.5625\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.1958 - acc: 0.5625\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.1929 - acc: 0.5625\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.1901 - acc: 0.5625\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1875 - acc: 0.5625\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1851 - acc: 0.5625\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1830 - acc: 0.5625\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.1810 - acc: 0.5625\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1791 - acc: 0.5625\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.1774 - acc: 0.5625\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.1758 - acc: 0.5625\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.1743 - acc: 0.5625\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1729 - acc: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97% (66 of 68) |####################### | Elapsed Time: 0:57:52 ETA:   0:02:24"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 25s 2s/step - loss: 1.7625 - acc: 0.2500\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6378 - acc: 0.4375\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5623 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5204 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4927 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4705 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4525 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4372 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4251 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4139 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4037 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3944 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3858 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3772 - acc: 0.5000\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3692 - acc: 0.5000\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3617 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3544 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3474 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3406 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3343 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3281 - acc: 0.5000\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3221 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3161 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3102 - acc: 0.5000\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3046 - acc: 0.5000\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2992 - acc: 0.5000\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2939 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2889 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2841 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2794 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2750 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2708 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2667 - acc: 0.5000\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2628 - acc: 0.5000\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2591 - acc: 0.5000\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.2556 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.2523 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2492 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2462 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2433 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2407 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2376 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2348 - acc: 0.5000\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.2322 - acc: 0.5000\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2299 - acc: 0.5000\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2278 - acc: 0.5000\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2260 - acc: 0.5000\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2242 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2226 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2212 - acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98% (67 of 68) |####################### | Elapsed Time: 0:59:03 ETA:   0:01:10"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 20s 1s/step - loss: 1.7626 - acc: 0.2500\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6641 - acc: 0.4375\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5855 - acc: 0.4375\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5352 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5051 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4836 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4676 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4546 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4426 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4321 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4218 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4115 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4008 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3916 - acc: 0.5000\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3830 - acc: 0.5000\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3750 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3679 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3611 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3547 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3489 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3431 - acc: 0.5000\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3375 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3321 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3269 - acc: 0.5000\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3220 - acc: 0.5000\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3174 - acc: 0.5000\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3131 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3090 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3050 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3012 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2976 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2942 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2909 - acc: 0.5000\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2878 - acc: 0.5000\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2848 - acc: 0.5000\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2820 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2794 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2769 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2746 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2725 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2705 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2687 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2670 - acc: 0.5000\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2654 - acc: 0.5000\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2640 - acc: 0.5000\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2628 - acc: 0.5000\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2616 - acc: 0.5000\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2605 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2596 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2587 - acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (68 of 68) |########################| Elapsed Time: 1:00:13 ETA:  00:00:00/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speedup</th>\n",
       "      <th>Oracle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platform</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AMD Radeon HD 5900</th>\n",
       "      <td>1.115193</td>\n",
       "      <td>0.719313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMD Tahiti 7970</th>\n",
       "      <td>1.008560</td>\n",
       "      <td>0.758116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVIDIA GTX 480</th>\n",
       "      <td>0.996761</td>\n",
       "      <td>0.842822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVIDIA Tesla K20c</th>\n",
       "      <td>0.990788</td>\n",
       "      <td>0.874626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Speedup    Oracle\n",
       "Platform                              \n",
       "AMD Radeon HD 5900  1.115193  0.719313\n",
       "AMD Tahiti 7970     1.008560  0.758116\n",
       "NVIDIA GTX 480      0.996761  0.842822\n",
       "NVIDIA Tesla K20c   0.990788  0.874626"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Evaluating DeepTune ...\", file=sys.stderr)\n",
    "deeptune = evaluate(DeepTune())\n",
    "deeptune.groupby('Platform')['Platform', 'Speedup', 'Oracle'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. DeepTune-TL\n",
    "\n",
    "As described in Section 4.3. of the paper, we use *Transfer Learning* to leverage information gained from one optimization problem for another. To do this, we simply initialize the language model with the weights learned for Case Study A. See '*Case Study A.ipynb*' for the code to produce these weights. Apart from initializing the weights from the other optimization task, the model remains unchanged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DeepTune_TL(DeepTune):\n",
    "    __name__ = \"DeepTune-TL\"\n",
    "    __basename__ = \"deeptune_tl\"\n",
    "\n",
    "    # starting_weights = \"../data/case-study-b/case-study-a-weights.h5\"\n",
    "    starting_weights = \"../data/case-study-b/case-study-a-weights.tf\"\n",
    "\n",
    "    def init(self, *args, **kwargs):\n",
    "        super(DeepTune_TL, self).init(*args, **kwargs)\n",
    "        self.model.load_weights(self.starting_weights, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DeepTune-TL ...\n",
      "/home/elandg/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/ipykernel_launcher.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimension 0 in both shapes must be equal, but are 129 and 132. Shapes are [129,64] and [132,64]. for 'Assign' (op: 'Assign') with input shapes: [129,64], [132,64].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1864\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1865\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimension 0 in both shapes must be equal, but are 129 and 132. Shapes are [129,64] and [132,64]. for 'Assign' (op: 'Assign') with input shapes: [129,64], [132,64].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3666/1820007527.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating DeepTune-TL ...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdeeptune_tl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDeepTune_TL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdeeptune_tl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Platform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Platform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Speedup'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Oracle'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3666/982606446.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0;31m# create a new model and train it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                     model.train(cascading_features=np.concatenate(X_cc[train_index]),\n\u001b[1;32m     56\u001b[0m                                 \u001b[0mcascading_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_cc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3666/3429388510.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDeepTune_TL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarting_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   2618\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2620\u001b[0;31m             \u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2621\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2622\u001b[0m             \u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group_by_name\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m   3203\u001b[0m                 weight_value_tuples.append((symbolic_weights[i],\n\u001b[1;32m   3204\u001b[0m                                             weight_values[i]))\n\u001b[0;32m-> 3205\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2240\u001b[0m                 assign_placeholder = tf.placeholder(tf_dtype,\n\u001b[1;32m   2241\u001b[0m                                                     shape=value.shape)\n\u001b[0;32m-> 2242\u001b[0;31m                 \u001b[0massign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2243\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m   1950\u001b[0m     \"\"\"\n\u001b[1;32m   1951\u001b[0m     assign = state_ops.assign(self._variable, value, use_locking=use_locking,\n\u001b[0;32m-> 1952\u001b[0;31m                               name=name)\n\u001b[0m\u001b[1;32m   1953\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/ops/state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m     return gen_state_ops.assign(\n\u001b[1;32m    226\u001b[0m         \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    228\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/ops/gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m     64\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m     65\u001b[0m         \u001b[0;34m\"Assign\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                   use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m     67\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3614\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3615\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3616\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3617\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3618\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2025\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   2026\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 2027\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   2028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension 0 in both shapes must be equal, but are 129 and 132. Shapes are [129,64] and [132,64]. for 'Assign' (op: 'Assign') with input shapes: [129,64], [132,64]."
     ]
    }
   ],
   "source": [
    "print(\"Evaluating DeepTune-TL ...\", file=sys.stderr)\n",
    "deeptune_tl = evaluate(DeepTune_TL())\n",
    "deeptune_tl.groupby('Platform')['Platform', 'Speedup', 'Oracle'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Average Speedup and Oracle of each model across all platforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DeepTune</th>\n",
       "      <th>DeepTune-TL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Speedup</th>\n",
       "      <td>1.295947</td>\n",
       "      <td>1.199496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oracle</th>\n",
       "      <td>0.862704</td>\n",
       "      <td>0.818337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DeepTune  DeepTune-TL\n",
       "Speedup  1.295947     1.199496\n",
       "Oracle   0.862704     0.818337"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.array([\n",
    "    # magni[['Speedup', 'Oracle']].mean(),\n",
    "    deeptune[['Speedup', 'Oracle']].mean(),\n",
    "    deeptune_tl[['Speedup', 'Oracle']].mean(),\n",
    "]).T\n",
    "\n",
    "pd.DataFrame(d, columns=[\"DeepTune\", \"DeepTune-TL\"], index=[\"Speedup\", \"Oracle\"])\n",
    "# pd.DataFrame(d, columns=[\"Magni et al.\", \"DeepTune\", \"DeepTune-TL\"], index=[\"Speedup\", \"Oracle\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation\n",
    "\n",
    "### 4.1. Speedups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DeepTune</th>\n",
       "      <th>DeepTune-TL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AMD Radeon HD 5900</th>\n",
       "      <td>1.676411</td>\n",
       "      <td>1.676411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMD Tahiti 7970</th>\n",
       "      <td>1.385804</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVIDIA GTX 480</th>\n",
       "      <td>1.121572</td>\n",
       "      <td>1.121572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVIDIA Tesla K20c</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>1.295947</td>\n",
       "      <td>1.199496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DeepTune  DeepTune-TL\n",
       "AMD Radeon HD 5900  1.676411     1.676411\n",
       "AMD Tahiti 7970     1.385804     1.000000\n",
       "NVIDIA GTX 480      1.121572     1.121572\n",
       "NVIDIA Tesla K20c   1.000000     1.000000\n",
       "Average             1.295947     1.199496"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "# d.append(np.append(magni.groupby(['Platform'])['Speedup'].mean().values,\n",
    "#                    magni['Speedup'].mean()))\n",
    "d.append(np.append(deeptune.groupby(['Platform'])['Speedup'].mean().values,\n",
    "                   deeptune['Speedup'].mean()))\n",
    "d.append(np.append(deeptune_tl.groupby(['Platform'])['Speedup'].mean().values,\n",
    "                   deeptune_tl['Speedup'].mean()))\n",
    "# d = np.array(d).T.reshape(5, 3)\n",
    "d = np.array(d).T.reshape(5, 2)\n",
    "\n",
    "# pd.DataFrame(d, columns=['Magni et al.', 'DeepTune', 'DeepTune-TL'],\n",
    "#              index=['AMD Radeon HD 5900', 'AMD Tahiti 7970', \n",
    "#                     'NVIDIA GTX 480', 'NVIDIA Tesla K20c', 'Average'])\n",
    "\n",
    "pd.DataFrame(d, columns=['DeepTune', 'DeepTune-TL'],\n",
    "             index=['AMD Radeon HD 5900', 'AMD Tahiti 7970', \n",
    "                    'NVIDIA GTX 480', 'NVIDIA Tesla K20c', 'Average'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 8 of the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Neither the `x` nor `y` variable appears to be numeric.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_793/1686921353.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcubehelix_palette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.85\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdark\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Kernel\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Speedup\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplatform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mbarplot\u001b[0;34m(data, x, y, hue, order, hue_order, estimator, errorbar, n_boot, units, seed, orient, color, palette, saturation, width, errcolor, errwidth, capsize, dodge, ci, ax, **kwargs)\u001b[0m\n\u001b[1;32m   2755\u001b[0m                           \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrorbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2756\u001b[0m                           \u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2757\u001b[0;31m                           width, errcolor, errwidth, capsize, dodge)\n\u001b[0m\u001b[1;32m   2758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2759\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0max\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, hue, data, order, hue_order, estimator, errorbar, n_boot, units, seed, orient, color, palette, saturation, width, errcolor, errwidth, capsize, dodge)\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;34m\"\"\"Initialize the plotter.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         self.establish_variables(x, y, hue, data, orient,\n\u001b[0;32m-> 1531\u001b[0;31m                                  order, hue_order, units)\n\u001b[0m\u001b[1;32m   1532\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestablish_colors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_statistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrorbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mestablish_variables\u001b[0;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0;31m# Figure out the plotting orientation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             orient = infer_orient(\n\u001b[0;32m--> 545\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m             )\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eecs583-paper-end2end-dl/env/lib/python3.7/site-packages/seaborn/_oldcore.py\u001b[0m in \u001b[0;36minfer_orient\u001b[0;34m(x, y, orient, require_numeric)\u001b[0m\n\u001b[1;32m   1630\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mrequire_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"numeric\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m         \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Neither the `x` nor `y` variable appears to be numeric.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1632\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Neither the `x` nor `y` variable appears to be numeric."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 768x528 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if isnotebook():\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    from matplotlib.ticker import FormatStrFormatter\n",
    "    from labm8 import viz\n",
    "\n",
    "    # Plotting configuration\n",
    "    %matplotlib inline\n",
    "    sns.set(style=\"ticks\", color_codes=True)\n",
    "    plt.style.use([\"seaborn-white\", \"seaborn-paper\"])\n",
    "    matplotlib.rcParams['figure.dpi'] = 120\n",
    "\n",
    "    for i, platform in enumerate([\"AMD Radeon HD 5900\", \"AMD Tahiti 7970\", \"NVIDIA GTX 480\", \"NVIDIA Tesla K20c\"]):\n",
    "\n",
    "        def get_speedups(df, platform):\n",
    "            \"\"\" get % accuracies for platform, aggregated by benchmark suite \"\"\"\n",
    "            r = df[df[\"Platform\"] == platform]\n",
    "            d = pd.DataFrame(r[\"Speedup\"].values, columns=['Speedup'], index=r['Kernel'])\n",
    "            avg = pd.Series([d.mean(),], index=[\"Speedup\"], name=\"Average\")\n",
    "            return d.append(avg)\n",
    "\n",
    "        # Aggregate data\n",
    "        # models, results = (Magni, DeepTune, DeepTune_TL), (magni, deeptune, deeptune_tl)\n",
    "        models, results = (DeepTune, DeepTune_TL), (deeptune, deeptune_tl)\n",
    "        dfs = [get_speedups(r, platform) for r in results]\n",
    "\n",
    "        speedups    = np.concatenate([dfs[i]['Speedup'].values for i in range(len(dfs))])\n",
    "        kernels     = np.concatenate([dfs[i].index.values for i in range(len(dfs))])\n",
    "        model_names = np.concatenate([np.array([m().__name__] * len(dfs[0])) for m in models])\n",
    "\n",
    "        df = pd.DataFrame([{\"Kernel\": k, \"Speedup\": s - 1, \"Model\": m}\n",
    "                           for k, s, m in zip(kernels, speedups, model_names)])\n",
    "\n",
    "        # Plot\n",
    "        palette = sns.cubehelix_palette(2, rot=.5, light=.85, dark=.35)\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        ax = sns.barplot(x=\"Kernel\", y=\"Speedup\", hue=\"Model\", palette=palette, data=df)\n",
    "        plt.title(platform)\n",
    "\n",
    "        # y axis\n",
    "        plt.axhline(y=0, color=\"k\", lw=.5)\n",
    "        plt.ylim((-1, 1.5))\n",
    "        ax.set_yticklabels([\"{:.1f}x\".format(float(i) + 1.0) for i in ax.get_yticks()])  # negative offset\n",
    "        if i % 2:\n",
    "            plt.ylabel(\"\")  \n",
    "        else:\n",
    "            plt.ylabel(\"Speedup\")\n",
    "\n",
    "        # x axis\n",
    "        plt.setp(ax.get_xticklabels(), rotation=90)  # rotate x ticks\n",
    "        plt.xlabel(\"\")\n",
    "        plt.axvline(x=plt.xlim()[1] - 1, color=\"k\", lw=1, linestyle=\"--\")  # average line\n",
    "\n",
    "        # legend\n",
    "        ax.get_legend().set_title(\"\")\n",
    "        plt.legend(loc='upper left', ncol=1)    \n",
    "        ax.get_legend().draw_frame(True)\n",
    "\n",
    "    viz.finalise(figsize=(9, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geometric means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geometric mean of DeepTune 1.27x\n",
      "Geometric mean of DeepTune-TL 1.17x\n"
     ]
    }
   ],
   "source": [
    "from labm8 import math as labmath\n",
    "\n",
    "# magni_geomean = labmath.geomean(magni['Speedup'].values)\n",
    "deeptune_geomean = labmath.geomean(deeptune['Speedup'].values)\n",
    "deeptune_tl_geomean = labmath.geomean(deeptune_tl['Speedup'].values)\n",
    "\n",
    "# print(f\"Geometric mean of Magni et al. {magni_geomean:.2f}x\")\n",
    "print(f\"Geometric mean of DeepTune {deeptune_geomean:.2f}x\")\n",
    "print(f\"Geometric mean of DeepTune-TL {deeptune_tl_geomean:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Influence of Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer Learning improved performance on 0 of the 4 platforms\n",
      "The greatest per-platform performance improvement was 0.0% on AMD Radeon HD 5900\n"
     ]
    }
   ],
   "source": [
    "dt_platform_speedups = deeptune.groupby(\"Platform\").mean()[\"Speedup\"].iteritems()\n",
    "dt_tl_platform_speedups = deeptune_tl.groupby(\"Platform\").mean()[\"Speedup\"].iteritems()\n",
    "\n",
    "num_improvements = 0\n",
    "tl_speedups = []\n",
    "for (platform, speedup), (_, speedup_tl) in zip(dt_platform_speedups, dt_tl_platform_speedups):\n",
    "    if speedup_tl > speedup:\n",
    "        num_improvements += 1\n",
    "    tl_speedup = (speedup_tl / speedup) - 1\n",
    "    tl_speedups.append({\"Platform\": platform, \"TL-speedup\": tl_speedup})\n",
    "\n",
    "max_tl_speedup = max(tl_speedups, key=lambda x: x[\"TL-speedup\"])\n",
    "print(f\"Transfer Learning improved performance on {num_improvements} of the 4 platforms\")\n",
    "print(\"The greatest per-platform performance improvement was \"\n",
    "      f\"{max_tl_speedup['TL-speedup']:.1%} on {max_tl_speedup['Platform']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Comparison to State-of-the-art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepTune outperforms state-of-the-art by 0%\n",
      "DeepTune-TL outperforms state-of-the-art by -7%\n"
     ]
    }
   ],
   "source": [
    "deeptune_speedup = deeptune[\"Speedup\"].mean()\n",
    "deeptune_tl_speedup = deeptune_tl[\"Speedup\"].mean()\n",
    "# magni_speedup = magni[\"Speedup\"].mean()\n",
    "\n",
    "# performance_improvement = (deeptune_speedup / magni_speedup) - 1\n",
    "# performance_improvement_tl = (deeptune_tl_speedup / magni_speedup) - 1\n",
    "\n",
    "performance_improvement = (deeptune_speedup / deeptune_speedup) - 1\n",
    "performance_improvement_tl = (deeptune_tl_speedup / deeptune_speedup) - 1\n",
    "\n",
    "print(f\"DeepTune outperforms state-of-the-art by {performance_improvement:.0%}\")\n",
    "print(f\"DeepTune-TL outperforms state-of-the-art by {performance_improvement_tl:.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepTune-TL matched or improved performance of state-of-the-art in 3 of 4 cases (75.0%)\n"
     ]
    }
   ],
   "source": [
    "num_cases = len(deeptune_tl)\n",
    "# num_better = sum(1 for d, m in zip(deeptune_tl[\"Speedup\"], magni[\"Speedup\"]) if d >= m)\n",
    "num_better = sum(1 for d, m in zip(deeptune_tl[\"Speedup\"], deeptune[\"Speedup\"]) if d >= m)\n",
    "ratio_better = num_better / num_cases\n",
    "print(\"DeepTune-TL matched or improved performance of state-of-the-art in \"\n",
    "      f\"{num_better} of {num_cases} cases ({ratio_better:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of experiments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "cbac100c1e935252d359d825fd3ac71dfe3b9a8ec214ef04a342f5b5ae0ac34d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
